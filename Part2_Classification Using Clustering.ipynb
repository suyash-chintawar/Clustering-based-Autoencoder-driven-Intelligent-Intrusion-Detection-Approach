{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "Lxmd0Jd82_Tb",
        "h1DDG4FdXdqX",
        "oGHZSgLVBgt4",
        "o70c_nEZT3cP",
        "j6B7rVSeBnQH",
        "5-bdDd5YJ3Ba",
        "k6sgvJtGLw5j",
        "A7qVVwUOL1Rs",
        "_mflRCsKN9rm",
        "9-ozWSaLUGjn",
        "QLscoX4KUMVr",
        "jUWbZDEDiWCp",
        "CPynXPhQic6W",
        "Vi1EP7LWinDO",
        "91KiF4aPUbK5",
        "tdYa8loRlL5w",
        "C_7F670FDbjk",
        "0nB8R8isb3c8",
        "nH0Iw9Tgb3c_",
        "HIZlsxbIb3c_",
        "jSRKqp0hb3dD",
        "z-SsndIeb3dG",
        "9YCb1RtGb3dJ",
        "ts1FK_OE3BAi",
        "pV9EjBasb3dO",
        "Pul729BBb3dO",
        "9jZ0XWRu1qqf",
        "0bvfGtt_11RM",
        "Xu6odIX317UM",
        "L2ev-sFZVh-k",
        "hq63nUHhVXDk",
        "nQJazz0VVXDl"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# importing required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pickle # saving and loading trained model\n",
        "from os import path\n",
        "\n",
        "# importing required libraries for normalizing data\n",
        "from sklearn import preprocessing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# importing library for plotting\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# importing library for support vector machine classifier\n",
        "from sklearn.svm import SVC\n",
        "# importing library for K-neares-neighbor classifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "# importing library for Linear Discriminant Analysis Model\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "# importing library for Quadratic Discriminant Analysis Model\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import accuracy_score # for calculating accuracy of model\n",
        "from sklearn.model_selection import train_test_split # for splitting the dataset for training and testing\n",
        "from sklearn.metrics import classification_report # for generating a classification report of model\n",
        "\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "\n",
        "from keras.layers import Dense # importing dense layer\n",
        "from keras.models import Sequential #importing Sequential layer\n",
        "from keras.models import model_from_json # saving and loading trained model\n",
        "\n",
        "from keras.layers import LSTM\n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "\n",
        "# representation of model layers\n",
        "from keras.utils.vis_utils import plot_model"
      ],
      "metadata": {
        "id": "yx3wga7sV_8Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering (Multiclass)\n"
      ],
      "metadata": {
        "id": "Lxmd0Jd82_Tb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating clusters"
      ],
      "metadata": {
        "id": "h1DDG4FdXdqX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 'https://drive.google.com/uc?id=1zeFp5_JRm_Qy6b91XVIM99O0PTnpWaF5&confirm=t'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uGkF2bqVkZj",
        "outputId": "4636e176-fe84-4474-b819-88f879bdad0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1zeFp5_JRm_Qy6b91XVIM99O0PTnpWaF5&confirm=t\n",
            "To: /content/multi_data.csv\n",
            "100% 36.6M/36.6M [00:01<00:00, 32.5MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('multi_data.csv')\n",
        "data = data.drop(['Unnamed: 0'],axis=1)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "9e7B8z6v2-Vx",
        "outputId": "9ff6f7e7-4911-4ce7-a1c5-26f3cfe8bb48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count  logged_in  srv_serror_rate  serror_rate  \\\n",
              "0      -0.615658  -0.864470        -0.514055    -0.516891   \n",
              "1      -0.473366  -0.864470        -0.514055    -0.516891   \n",
              "2       0.949553  -0.864470         1.985588     1.984040   \n",
              "3      -0.576851   1.156779        -0.014126    -0.016705   \n",
              "4      -0.253460   1.156779        -0.514055    -0.516891   \n",
              "...          ...        ...              ...          ...   \n",
              "102209  1.001295  -0.864470        -0.514055    -0.516891   \n",
              "102210  0.044059  -0.864470        -0.514055    -0.516891   \n",
              "102211 -0.628593   1.156779        -0.514055    -0.516891   \n",
              "102212 -0.615658   1.156779        -0.514055    -0.516891   \n",
              "102213 -0.589786  -0.864470        -0.514055    -0.516891   \n",
              "\n",
              "        dst_host_serror_rate  dst_host_same_srv_rate  \\\n",
              "0                  -0.513194               -0.959621   \n",
              "1                  -0.513194               -1.335998   \n",
              "2                   2.005094               -1.114600   \n",
              "3                  -0.437645                0.877982   \n",
              "4                  -0.513194                0.877982   \n",
              "...                      ...                     ...   \n",
              "102209             -0.513194               -1.181019   \n",
              "102210             -0.513194                0.877982   \n",
              "102211             -0.488011                0.258068   \n",
              "102212             -0.488011                0.877982   \n",
              "102213             -0.513194                0.855842   \n",
              "\n",
              "        dst_host_srv_serror_rate  dst_host_srv_count  same_srv_rate  \\\n",
              "0                      -0.503145           -0.967411       0.657887   \n",
              "1                      -0.503145           -1.177300      -1.620628   \n",
              "2                       2.016338           -0.958665      -1.694928   \n",
              "3                      -0.477950            1.044027       0.657887   \n",
              "4                      -0.503145            1.044027       0.657887   \n",
              "...                          ...                 ...            ...   \n",
              "102209                 -0.503145           -1.028628      -1.472029   \n",
              "102210                 -0.503145            1.044027       0.657887   \n",
              "102211                 -0.503145            0.047054       0.657887   \n",
              "102212                 -0.503145            1.044027       0.657887   \n",
              "102213                 -0.503145            1.017791       0.657887   \n",
              "\n",
              "        protocol_type_icmp  ...  flag_S2  flag_S3  flag_SF  flag_SH  \\\n",
              "0                        0  ...        0        0        1        0   \n",
              "1                        0  ...        0        0        1        0   \n",
              "2                        0  ...        0        0        0        0   \n",
              "3                        0  ...        0        0        1        0   \n",
              "4                        0  ...        0        0        1        0   \n",
              "...                    ...  ...      ...      ...      ...      ...   \n",
              "102209                   0  ...        0        0        0        0   \n",
              "102210                   1  ...        0        0        1        0   \n",
              "102211                   0  ...        0        0        1        0   \n",
              "102212                   0  ...        0        0        1        0   \n",
              "102213                   0  ...        0        0        1        0   \n",
              "\n",
              "        intrusion  Dos  Probe  R2L  normal   label  \n",
              "0               3    0      0    0       1  normal  \n",
              "1               3    0      0    0       1  normal  \n",
              "2               0    1      0    0       0     Dos  \n",
              "3               3    0      0    0       1  normal  \n",
              "4               3    0      0    0       1  normal  \n",
              "...           ...  ...    ...  ...     ...     ...  \n",
              "102209          0    1      0    0       0     Dos  \n",
              "102210          0    1      0    0       0     Dos  \n",
              "102211          3    0      0    0       1  normal  \n",
              "102212          3    0      0    0       1  normal  \n",
              "102213          3    0      0    0       1  normal  \n",
              "\n",
              "[102214 rows x 95 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ad41a1c5-82ec-4cfc-8000-a4d897898c42\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>Dos</th>\n",
              "      <th>Probe</th>\n",
              "      <th>R2L</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.959621</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.473366</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.620628</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.576851</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.014126</td>\n",
              "      <td>-0.016705</td>\n",
              "      <td>-0.437645</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.253460</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102209</th>\n",
              "      <td>1.001295</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.181019</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.028628</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102210</th>\n",
              "      <td>0.044059</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102211</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>0.258068</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>0.047054</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102212</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102213</th>\n",
              "      <td>-0.589786</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.855842</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.017791</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102214 rows × 95 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ad41a1c5-82ec-4cfc-8000-a4d897898c42')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ad41a1c5-82ec-4cfc-8000-a4d897898c42 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ad41a1c5-82ec-4cfc-8000-a4d897898c42');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "X = data.iloc[:,:89].values\n",
        "model = KMeans(n_clusters=4)\n",
        "model.fit(X)\n",
        "clusterNos = model.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uiHPmRUL6cJh",
        "outputId": "ed3177a8-820d-4c09-85ad-7c79f0b0fbaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clusterNos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F9LIrO2v7Ev_",
        "outputId": "8f71a0ad-9e15-41b9-a6ca-e94ef90207ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 1, ..., 2, 2, 0], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['clusterNo'] = clusterNos.tolist()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "CMhT_XaO7HMb",
        "outputId": "2d0d13b8-576a-4542-a0ac-0f665c238163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count  logged_in  srv_serror_rate  serror_rate  \\\n",
              "0      -0.615658  -0.864470        -0.514055    -0.516891   \n",
              "1      -0.473366  -0.864470        -0.514055    -0.516891   \n",
              "2       0.949553  -0.864470         1.985588     1.984040   \n",
              "3      -0.576851   1.156779        -0.014126    -0.016705   \n",
              "4      -0.253460   1.156779        -0.514055    -0.516891   \n",
              "...          ...        ...              ...          ...   \n",
              "102209  1.001295  -0.864470        -0.514055    -0.516891   \n",
              "102210  0.044059  -0.864470        -0.514055    -0.516891   \n",
              "102211 -0.628593   1.156779        -0.514055    -0.516891   \n",
              "102212 -0.615658   1.156779        -0.514055    -0.516891   \n",
              "102213 -0.589786  -0.864470        -0.514055    -0.516891   \n",
              "\n",
              "        dst_host_serror_rate  dst_host_same_srv_rate  \\\n",
              "0                  -0.513194               -0.959621   \n",
              "1                  -0.513194               -1.335998   \n",
              "2                   2.005094               -1.114600   \n",
              "3                  -0.437645                0.877982   \n",
              "4                  -0.513194                0.877982   \n",
              "...                      ...                     ...   \n",
              "102209             -0.513194               -1.181019   \n",
              "102210             -0.513194                0.877982   \n",
              "102211             -0.488011                0.258068   \n",
              "102212             -0.488011                0.877982   \n",
              "102213             -0.513194                0.855842   \n",
              "\n",
              "        dst_host_srv_serror_rate  dst_host_srv_count  same_srv_rate  \\\n",
              "0                      -0.503145           -0.967411       0.657887   \n",
              "1                      -0.503145           -1.177300      -1.620628   \n",
              "2                       2.016338           -0.958665      -1.694928   \n",
              "3                      -0.477950            1.044027       0.657887   \n",
              "4                      -0.503145            1.044027       0.657887   \n",
              "...                          ...                 ...            ...   \n",
              "102209                 -0.503145           -1.028628      -1.472029   \n",
              "102210                 -0.503145            1.044027       0.657887   \n",
              "102211                 -0.503145            0.047054       0.657887   \n",
              "102212                 -0.503145            1.044027       0.657887   \n",
              "102213                 -0.503145            1.017791       0.657887   \n",
              "\n",
              "        protocol_type_icmp  ...  flag_S3  flag_SF  flag_SH  intrusion  Dos  \\\n",
              "0                        0  ...        0        1        0          3    0   \n",
              "1                        0  ...        0        1        0          3    0   \n",
              "2                        0  ...        0        0        0          0    1   \n",
              "3                        0  ...        0        1        0          3    0   \n",
              "4                        0  ...        0        1        0          3    0   \n",
              "...                    ...  ...      ...      ...      ...        ...  ...   \n",
              "102209                   0  ...        0        0        0          0    1   \n",
              "102210                   1  ...        0        1        0          0    1   \n",
              "102211                   0  ...        0        1        0          3    0   \n",
              "102212                   0  ...        0        1        0          3    0   \n",
              "102213                   0  ...        0        1        0          3    0   \n",
              "\n",
              "        Probe  R2L  normal   label  clusterNo  \n",
              "0           0    0       1  normal          3  \n",
              "1           0    0       1  normal          3  \n",
              "2           0    0       0     Dos          1  \n",
              "3           0    0       1  normal          2  \n",
              "4           0    0       1  normal          2  \n",
              "...       ...  ...     ...     ...        ...  \n",
              "102209      0    0       0     Dos          3  \n",
              "102210      0    0       0     Dos          0  \n",
              "102211      0    0       1  normal          2  \n",
              "102212      0    0       1  normal          2  \n",
              "102213      0    0       1  normal          0  \n",
              "\n",
              "[102214 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-38c0b8f0-b1d7-40ae-8904-2e1548f1469d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>Dos</th>\n",
              "      <th>Probe</th>\n",
              "      <th>R2L</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.959621</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.473366</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.620628</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.576851</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.014126</td>\n",
              "      <td>-0.016705</td>\n",
              "      <td>-0.437645</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.253460</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102209</th>\n",
              "      <td>1.001295</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.181019</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.028628</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102210</th>\n",
              "      <td>0.044059</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102211</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>0.258068</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>0.047054</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102212</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102213</th>\n",
              "      <td>-0.589786</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.855842</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.017791</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102214 rows × 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-38c0b8f0-b1d7-40ae-8904-2e1548f1469d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-38c0b8f0-b1d7-40ae-8904-2e1548f1469d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-38c0b8f0-b1d7-40ae-8904-2e1548f1469d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data.iloc[:88091]\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "52RDw3b62-I0",
        "outputId": "69fb29a7-4a1d-402a-dde7-ab3bc85a9797"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          count  logged_in  srv_serror_rate  serror_rate  \\\n",
              "0     -0.615658  -0.864470        -0.514055    -0.516891   \n",
              "1     -0.473366  -0.864470        -0.514055    -0.516891   \n",
              "2      0.949553  -0.864470         1.985588     1.984040   \n",
              "3     -0.576851   1.156779        -0.014126    -0.016705   \n",
              "4     -0.253460   1.156779        -0.514055    -0.516891   \n",
              "...         ...        ...              ...          ...   \n",
              "88086 -0.602722   1.156779        -0.289087     0.308416   \n",
              "88087  1.738626  -0.864470         1.985588     1.984040   \n",
              "88088 -0.615658  -0.864470        -0.514055    -0.516891   \n",
              "88089  1.221201  -0.864470         1.985588     1.984040   \n",
              "88090 -0.628593   1.156779        -0.514055    -0.516891   \n",
              "\n",
              "       dst_host_serror_rate  dst_host_same_srv_rate  dst_host_srv_serror_rate  \\\n",
              "0                 -0.513194               -0.959621                 -0.503145   \n",
              "1                 -0.513194               -1.335998                 -0.503145   \n",
              "2                  2.005094               -1.114600                  2.016338   \n",
              "3                 -0.437645                0.877982                 -0.477950   \n",
              "4                 -0.513194                0.877982                 -0.503145   \n",
              "...                     ...                     ...                       ...   \n",
              "88086              0.317841                0.877982                 -0.503145   \n",
              "88087              2.005094               -1.114600                  2.016338   \n",
              "88088             -0.513194                0.789423                 -0.503145   \n",
              "88089              2.005094               -1.269578                  2.016338   \n",
              "88090             -0.513194               -0.671804                 -0.503145   \n",
              "\n",
              "       dst_host_srv_count  same_srv_rate  protocol_type_icmp  ...  flag_S3  \\\n",
              "0               -0.967411       0.657887                   0  ...        0   \n",
              "1               -1.177300      -1.620628                   0  ...        0   \n",
              "2               -0.958665      -1.694928                   0  ...        0   \n",
              "3                1.044027       0.657887                   0  ...        0   \n",
              "4                1.044027       0.657887                   0  ...        0   \n",
              "...                   ...            ...                 ...  ...      ...   \n",
              "88086            1.044027       0.657887                   0  ...        0   \n",
              "88087           -0.967411      -1.472029                   0  ...        0   \n",
              "88088            0.947828       0.657887                   0  ...        0   \n",
              "88089           -1.116082      -1.670161                   0  ...        0   \n",
              "88090           -0.512651       0.657887                   0  ...        0   \n",
              "\n",
              "       flag_SF  flag_SH  intrusion  Dos  Probe  R2L  normal   label  clusterNo  \n",
              "0            1        0          3    0      0    0       1  normal          3  \n",
              "1            1        0          3    0      0    0       1  normal          3  \n",
              "2            0        0          0    1      0    0       0     Dos          1  \n",
              "3            1        0          3    0      0    0       1  normal          2  \n",
              "4            1        0          3    0      0    0       1  normal          2  \n",
              "...        ...      ...        ...  ...    ...  ...     ...     ...        ...  \n",
              "88086        1        0          3    0      0    0       1  normal          2  \n",
              "88087        0        0          0    1      0    0       0     Dos          1  \n",
              "88088        1        0          3    0      0    0       1  normal          0  \n",
              "88089        0        0          0    1      0    0       0     Dos          1  \n",
              "88090        1        0          3    0      0    0       1  normal          2  \n",
              "\n",
              "[88091 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-deb9048b-01ab-4da7-83f4-21d24aeb80af\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>Dos</th>\n",
              "      <th>Probe</th>\n",
              "      <th>R2L</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.959621</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.473366</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.620628</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.576851</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.014126</td>\n",
              "      <td>-0.016705</td>\n",
              "      <td>-0.437645</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.253460</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88086</th>\n",
              "      <td>-0.602722</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.289087</td>\n",
              "      <td>0.308416</td>\n",
              "      <td>0.317841</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88087</th>\n",
              "      <td>1.738626</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88088</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.789423</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>0.947828</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88089</th>\n",
              "      <td>1.221201</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.269578</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-1.116082</td>\n",
              "      <td>-1.670161</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88090</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.671804</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.512651</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88091 rows × 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-deb9048b-01ab-4da7-83f4-21d24aeb80af')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-deb9048b-01ab-4da7-83f4-21d24aeb80af button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-deb9048b-01ab-4da7-83f4-21d24aeb80af');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data.iloc[88091:]\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "t9utCyQg3-TW",
        "outputId": "3cef798c-0fe0-4f07-d5e1-185650a6e8e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count  logged_in  srv_serror_rate  serror_rate  \\\n",
              "88091   2.320729  -0.864470        -0.514055    -0.516891   \n",
              "88092   1.117716  -0.864470        -0.514055    -0.516891   \n",
              "88093  -0.628593   1.156779        -0.514055    -0.516891   \n",
              "88094  -0.628593  -0.864470        -0.514055    -0.516891   \n",
              "88095  -0.214653   1.156779        -0.514055    -0.516891   \n",
              "...          ...        ...              ...          ...   \n",
              "102209  1.001295  -0.864470        -0.514055    -0.516891   \n",
              "102210  0.044059  -0.864470        -0.514055    -0.516891   \n",
              "102211 -0.628593   1.156779        -0.514055    -0.516891   \n",
              "102212 -0.615658   1.156779        -0.514055    -0.516891   \n",
              "102213 -0.589786  -0.864470        -0.514055    -0.516891   \n",
              "\n",
              "        dst_host_serror_rate  dst_host_same_srv_rate  \\\n",
              "88091              -0.513194               -1.247439   \n",
              "88092              -0.513194               -1.335998   \n",
              "88093              -0.513194               -1.092460   \n",
              "88094              -0.488011                0.877982   \n",
              "88095              -0.513194                0.877982   \n",
              "...                      ...                     ...   \n",
              "102209             -0.513194               -1.181019   \n",
              "102210             -0.513194                0.877982   \n",
              "102211             -0.488011                0.258068   \n",
              "102212             -0.488011                0.877982   \n",
              "102213             -0.513194                0.855842   \n",
              "\n",
              "        dst_host_srv_serror_rate  dst_host_srv_count  same_srv_rate  \\\n",
              "88091                  -0.503145           -1.098591      -1.719694   \n",
              "88092                  -0.503145           -1.177300      -1.793994   \n",
              "88093                  -0.503145           -0.941174       0.657887   \n",
              "88094                  -0.477950            1.044027       0.657887   \n",
              "88095                  -0.503145            1.044027       0.657887   \n",
              "...                          ...                 ...            ...   \n",
              "102209                 -0.503145           -1.028628      -1.472029   \n",
              "102210                 -0.503145            1.044027       0.657887   \n",
              "102211                 -0.503145            0.047054       0.657887   \n",
              "102212                 -0.503145            1.044027       0.657887   \n",
              "102213                 -0.503145            1.017791       0.657887   \n",
              "\n",
              "        protocol_type_icmp  ...  flag_S3  flag_SF  flag_SH  intrusion  Dos  \\\n",
              "88091                    0  ...        0        0        0          0    1   \n",
              "88092                    0  ...        0        0        0          0    1   \n",
              "88093                    0  ...        0        1        0          3    0   \n",
              "88094                    0  ...        0        1        0          2    0   \n",
              "88095                    0  ...        0        1        0          3    0   \n",
              "...                    ...  ...      ...      ...      ...        ...  ...   \n",
              "102209                   0  ...        0        0        0          0    1   \n",
              "102210                   1  ...        0        1        0          0    1   \n",
              "102211                   0  ...        0        1        0          3    0   \n",
              "102212                   0  ...        0        1        0          3    0   \n",
              "102213                   0  ...        0        1        0          3    0   \n",
              "\n",
              "        Probe  R2L  normal   label  clusterNo  \n",
              "88091       0    0       0     Dos          3  \n",
              "88092       0    0       0     Dos          3  \n",
              "88093       0    0       1  normal          3  \n",
              "88094       0    1       0     R2L          0  \n",
              "88095       0    0       1  normal          2  \n",
              "...       ...  ...     ...     ...        ...  \n",
              "102209      0    0       0     Dos          3  \n",
              "102210      0    0       0     Dos          0  \n",
              "102211      0    0       1  normal          2  \n",
              "102212      0    0       1  normal          2  \n",
              "102213      0    0       1  normal          0  \n",
              "\n",
              "[14123 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5907376-412d-46c0-82aa-356f9ecbaa51\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>Dos</th>\n",
              "      <th>Probe</th>\n",
              "      <th>R2L</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>88091</th>\n",
              "      <td>2.320729</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.247439</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.098591</td>\n",
              "      <td>-1.719694</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88092</th>\n",
              "      <td>1.117716</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.793994</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88093</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.092460</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.941174</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88094</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>R2L</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88095</th>\n",
              "      <td>-0.214653</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102209</th>\n",
              "      <td>1.001295</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-1.181019</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-1.028628</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102210</th>\n",
              "      <td>0.044059</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102211</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>0.258068</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>0.047054</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102212</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102213</th>\n",
              "      <td>-0.589786</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>0.855842</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.017791</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14123 rows × 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5907376-412d-46c0-82aa-356f9ecbaa51')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5907376-412d-46c0-82aa-356f9ecbaa51 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5907376-412d-46c0-82aa-356f9ecbaa51');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UniqueClusters = train_data.clusterNo.unique()\n",
        "DataFrameDict = {cls : pd.DataFrame() for cls in UniqueClusters}\n",
        "for key in DataFrameDict.keys():\n",
        "    DataFrameDict[key] = train_data[:][train_data.clusterNo == key]"
      ],
      "metadata": {
        "id": "Xbi2vgrg7uHV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrameDict[0].to_csv('clusters/train1.csv')\n",
        "DataFrameDict[1].to_csv('clusters/train2.csv')\n",
        "DataFrameDict[2].to_csv('clusters/train3.csv')\n",
        "DataFrameDict[3].to_csv('clusters/train4.csv')"
      ],
      "metadata": {
        "id": "jBCLYo3u-RxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UniqueClusters = test_data.clusterNo.unique()\n",
        "DataFrameDict = {cls : pd.DataFrame() for cls in UniqueClusters}\n",
        "for key in DataFrameDict.keys():\n",
        "    DataFrameDict[key] = test_data[:][test_data.clusterNo == key]"
      ],
      "metadata": {
        "id": "WRjpO1Ez-ckc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrameDict[0].to_csv('clusters/test1.csv')\n",
        "DataFrameDict[1].to_csv('clusters/test2.csv')\n",
        "DataFrameDict[2].to_csv('clusters/test3.csv')\n",
        "DataFrameDict[3].to_csv('clusters/test4.csv')"
      ],
      "metadata": {
        "id": "41nwOMOt_alw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r clusters.zip clusters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Op3VN8w_joM",
        "outputId": "2713794e-5c83-4f66-e4ef-66d980d54d4b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: clusters/ (stored 0%)\n",
            "  adding: clusters/train1.csv (deflated 94%)\n",
            "  adding: clusters/test2.csv (deflated 96%)\n",
            "  adding: clusters/test4.csv (deflated 94%)\n",
            "  adding: clusters/train4.csv (deflated 94%)\n",
            "  adding: clusters/train3.csv (deflated 94%)\n",
            "  adding: clusters/test3.csv (deflated 95%)\n",
            "  adding: clusters/train2.csv (deflated 97%)\n",
            "  adding: clusters/test1.csv (deflated 93%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models on clusters"
      ],
      "metadata": {
        "id": "oGHZSgLVBgt4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 'https://drive.google.com/uc?id=15YALTSWfG9hYiksGvOdV50zG3rWN5Joy&confirm=t'"
      ],
      "metadata": {
        "id": "F60AM5G-AKr1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e015f24f-4941-451e-f896-5cb45a471988"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=15YALTSWfG9hYiksGvOdV50zG3rWN5Joy&confirm=t\n",
            "To: /content/clusters.zip\n",
            "\r  0% 0.00/1.81M [00:00<?, ?B/s]\r100% 1.81M/1.81M [00:00<00:00, 162MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf clusters\n",
        "!unzip clusters.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vWxyRKG6BEBQ",
        "outputId": "2e06a6cf-56fc-4fe2-ddf9-800cccc96257"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  clusters.zip\n",
            "   creating: clusteres/\n",
            "  inflating: clusteres/train1.csv    \n",
            "  inflating: clusteres/test2.csv     \n",
            "  inflating: clusteres/test4.csv     \n",
            "  inflating: clusteres/train4.csv    \n",
            "  inflating: clusteres/train3.csv    \n",
            "  inflating: clusteres/test3.csv     \n",
            "  inflating: clusteres/train2.csv    \n",
            "  inflating: clusteres/test1.csv     \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auto encoder"
      ],
      "metadata": {
        "id": "o70c_nEZT3cP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 1"
      ],
      "metadata": {
        "id": "j6B7rVSeBnQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train1.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test1.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "r-RwMze0Bd6k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x77DOQeMO9eY",
        "outputId": "d8568e7a-077d-4380-8fc3-68e2b2f94517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dos       18313\n",
              "Probe       369\n",
              "normal       72\n",
              "R2L           6\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count1 = len(test.index)"
      ],
      "metadata": {
        "id": "pdQqLrifLnZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6EkzvVbCTti",
        "outputId": "791005fc-b389-4466-ee99-effed5b15e2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      count  logged_in  srv_serror_rate  serror_rate  dst_host_serror_rate  \\\n",
              "0  0.949553   -0.86447         1.985588      1.98404              2.005094   \n",
              "1  1.505785   -0.86447         1.985588      1.98404              2.005094   \n",
              "2  0.871939   -0.86447         1.985588      1.98404              2.005094   \n",
              "3  1.078909   -0.86447         1.985588      1.98404              2.005094   \n",
              "4  0.600291   -0.86447         1.985588      1.98404              2.005094   \n",
              "\n",
              "   dst_host_same_srv_rate  dst_host_srv_serror_rate  dst_host_srv_count  \\\n",
              "0               -1.114600                  2.016338           -0.958665   \n",
              "1               -1.247439                  2.016338           -1.107337   \n",
              "2               -1.203159                  2.016338           -1.054864   \n",
              "3               -1.225299                  2.016338           -1.072355   \n",
              "4               -1.313858                  2.016338           -1.168554   \n",
              "\n",
              "   same_srv_rate  protocol_type_icmp  ...  flag_S3  flag_SF  flag_SH  \\\n",
              "0      -1.694928                   0  ...        0        0        0   \n",
              "1      -1.694928                   0  ...        0        0        0   \n",
              "2      -1.472029                   0  ...        0        0        0   \n",
              "3      -1.670161                   0  ...        0        0        0   \n",
              "4      -1.397730                   0  ...        0        0        0   \n",
              "\n",
              "   intrusion  Dos  Probe  R2L  normal  label  clusterNo  \n",
              "0          0    1      0    0       0    Dos          0  \n",
              "1          0    1      0    0       0    Dos          0  \n",
              "2          0    1      0    0       0    Dos          0  \n",
              "3          0    1      0    0       0    Dos          0  \n",
              "4          0    1      0    0       0    Dos          0  \n",
              "\n",
              "[5 rows x 96 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-51698d0e-b475-498c-94ea-3ec5f8c4cb4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>Dos</th>\n",
              "      <th>Probe</th>\n",
              "      <th>R2L</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.505785</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.247439</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-1.107337</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.871939</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.203159</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-1.054864</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.078909</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.225299</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-1.072355</td>\n",
              "      <td>-1.670161</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.600291</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>-1.313858</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-1.168554</td>\n",
              "      <td>-1.397730</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Dos</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 96 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-51698d0e-b475-498c-94ea-3ec5f8c4cb4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-51698d0e-b475-498c-94ea-3ec5f8c4cb4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-51698d0e-b475-498c-94ea-3ec5f8c4cb4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = train.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtLURVNBEbUE",
        "outputId": "f10ef301-f37a-40ba-ad17-7c0a62a88871"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_11 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpNPEYphCWRw",
        "outputId": "3f69d100-8b1a-43fb-d636-ce090b9cbf04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 11ms/step - loss: 0.2768 - accuracy: 0.6941 - val_loss: 0.2974 - val_accuracy: 0.6458\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2506 - accuracy: 0.9655 - val_loss: 0.2735 - val_accuracy: 0.5994\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2406 - accuracy: 0.1079 - val_loss: 0.2728 - val_accuracy: 0.2699\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2402 - accuracy: 0.4981 - val_loss: 0.2726 - val_accuracy: 0.4289\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2401 - accuracy: 0.5334 - val_loss: 0.2724 - val_accuracy: 0.4410\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2401 - accuracy: 0.5799 - val_loss: 0.2723 - val_accuracy: 0.4313\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.6391 - val_loss: 0.2721 - val_accuracy: 0.5102\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.7012 - val_loss: 0.2720 - val_accuracy: 0.5633\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.7443 - val_loss: 0.2720 - val_accuracy: 0.5771\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.7733 - val_loss: 0.2719 - val_accuracy: 0.5783\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.7761 - val_loss: 0.2719 - val_accuracy: 0.5940\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.7900 - val_loss: 0.2718 - val_accuracy: 0.5964\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.8089 - val_loss: 0.2718 - val_accuracy: 0.5723\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2400 - accuracy: 0.7908 - val_loss: 0.2718 - val_accuracy: 0.5976\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.8058 - val_loss: 0.2718 - val_accuracy: 0.6157\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.8369 - val_loss: 0.2717 - val_accuracy: 0.6259\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.8389 - val_loss: 0.2717 - val_accuracy: 0.6223\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.8405 - val_loss: 0.2717 - val_accuracy: 0.6259\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.8463 - val_loss: 0.2717 - val_accuracy: 0.6301\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.8467 - val_loss: 0.2717 - val_accuracy: 0.6301\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.8504 - val_loss: 0.2716 - val_accuracy: 0.6295\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.8636 - val_loss: 0.2716 - val_accuracy: 0.6295\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.8785 - val_loss: 0.2716 - val_accuracy: 0.6386\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.8846 - val_loss: 0.2716 - val_accuracy: 0.6331\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9027 - val_loss: 0.2716 - val_accuracy: 0.6410\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9167 - val_loss: 0.2716 - val_accuracy: 0.6428\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9187 - val_loss: 0.2716 - val_accuracy: 0.6404\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9236 - val_loss: 0.2716 - val_accuracy: 0.6090\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9361 - val_loss: 0.2716 - val_accuracy: 0.6404\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9370 - val_loss: 0.2716 - val_accuracy: 0.6410\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9428 - val_loss: 0.2716 - val_accuracy: 0.6392\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9424 - val_loss: 0.2716 - val_accuracy: 0.6410\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9477 - val_loss: 0.2715 - val_accuracy: 0.6404\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.9482 - val_loss: 0.2715 - val_accuracy: 0.6410\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9517 - val_loss: 0.2715 - val_accuracy: 0.6386\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9520 - val_loss: 0.2715 - val_accuracy: 0.6398\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9548 - val_loss: 0.2715 - val_accuracy: 0.6428\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9570 - val_loss: 0.2715 - val_accuracy: 0.6398\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2399 - accuracy: 0.9593 - val_loss: 0.2715 - val_accuracy: 0.6343\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9593 - val_loss: 0.2715 - val_accuracy: 0.6349\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9599 - val_loss: 0.2715 - val_accuracy: 0.6349\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9626 - val_loss: 0.2715 - val_accuracy: 0.6386\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9621 - val_loss: 0.2715 - val_accuracy: 0.6380\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9644 - val_loss: 0.2715 - val_accuracy: 0.6392\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2399 - accuracy: 0.9654 - val_loss: 0.2715 - val_accuracy: 0.6373\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9649 - val_loss: 0.2715 - val_accuracy: 0.6301\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2399 - accuracy: 0.9660 - val_loss: 0.2715 - val_accuracy: 0.6380\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9673 - val_loss: 0.2715 - val_accuracy: 0.6343\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9678 - val_loss: 0.2715 - val_accuracy: 0.6355\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9678 - val_loss: 0.2715 - val_accuracy: 0.6361\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9676 - val_loss: 0.2715 - val_accuracy: 0.6392\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9697 - val_loss: 0.2715 - val_accuracy: 0.6337\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9702 - val_loss: 0.2715 - val_accuracy: 0.6337\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9720 - val_loss: 0.2715 - val_accuracy: 0.6367\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9726 - val_loss: 0.2715 - val_accuracy: 0.6380\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2399 - accuracy: 0.9721 - val_loss: 0.2715 - val_accuracy: 0.6331\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9749 - val_loss: 0.2715 - val_accuracy: 0.6392\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9749 - val_loss: 0.2715 - val_accuracy: 0.6307\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9731 - val_loss: 0.2715 - val_accuracy: 0.6386\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9761 - val_loss: 0.2715 - val_accuracy: 0.6301\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9742 - val_loss: 0.2715 - val_accuracy: 0.6349\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9761 - val_loss: 0.2715 - val_accuracy: 0.6343\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9759 - val_loss: 0.2715 - val_accuracy: 0.6319\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9749 - val_loss: 0.2715 - val_accuracy: 0.6319\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9769 - val_loss: 0.2715 - val_accuracy: 0.6355\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9769 - val_loss: 0.2715 - val_accuracy: 0.6355\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9767 - val_loss: 0.2715 - val_accuracy: 0.6319\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9776 - val_loss: 0.2715 - val_accuracy: 0.6361\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9776 - val_loss: 0.2715 - val_accuracy: 0.6343\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9781 - val_loss: 0.2715 - val_accuracy: 0.6355\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9770 - val_loss: 0.2715 - val_accuracy: 0.6331\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9779 - val_loss: 0.2715 - val_accuracy: 0.6349\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9779 - val_loss: 0.2715 - val_accuracy: 0.6355\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9793 - val_loss: 0.2715 - val_accuracy: 0.6367\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9795 - val_loss: 0.2715 - val_accuracy: 0.6367\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9812 - val_loss: 0.2715 - val_accuracy: 0.6331\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9795 - val_loss: 0.2715 - val_accuracy: 0.6343\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9814 - val_loss: 0.2715 - val_accuracy: 0.6367\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9820 - val_loss: 0.2715 - val_accuracy: 0.6361\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9802 - val_loss: 0.2715 - val_accuracy: 0.6283\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9807 - val_loss: 0.2715 - val_accuracy: 0.6373\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.9827 - val_loss: 0.2715 - val_accuracy: 0.6271\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9809 - val_loss: 0.2715 - val_accuracy: 0.6361\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9821 - val_loss: 0.2715 - val_accuracy: 0.6343\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 0s 8ms/step - loss: 0.2399 - accuracy: 0.9824 - val_loss: 0.2715 - val_accuracy: 0.6283\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9829 - val_loss: 0.2715 - val_accuracy: 0.6355\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9831 - val_loss: 0.2715 - val_accuracy: 0.6319\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9842 - val_loss: 0.2715 - val_accuracy: 0.6271\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9840 - val_loss: 0.2715 - val_accuracy: 0.6283\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9838 - val_loss: 0.2715 - val_accuracy: 0.6337\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9843 - val_loss: 0.2715 - val_accuracy: 0.6277\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9838 - val_loss: 0.2715 - val_accuracy: 0.6349\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9843 - val_loss: 0.2715 - val_accuracy: 0.6289\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9850 - val_loss: 0.2715 - val_accuracy: 0.6361\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9842 - val_loss: 0.2715 - val_accuracy: 0.6247\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9864 - val_loss: 0.2715 - val_accuracy: 0.6277\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9862 - val_loss: 0.2715 - val_accuracy: 0.6325\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9852 - val_loss: 0.2715 - val_accuracy: 0.6380\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9861 - val_loss: 0.2715 - val_accuracy: 0.6253\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9856 - val_loss: 0.2715 - val_accuracy: 0.6253\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(50, activation=\"sigmoid\")(i_layer)                 \n",
        "#output layer\n",
        "o_layer = Dense(4, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "latent_weights_50 = autoencoder.layers[1].get_weights()\n",
        "ae_classifier.layers[1].set_weights(latent_weights_50)\n",
        "ae_classifier.layers[1].trainable = False\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tzZTsiK6GsrQ",
        "outputId": "11e0fee0-b152-4123-b08d-87cad04054a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 2ms/step\n",
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_12 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,704\n",
            "Trainable params: 204\n",
            "Non-trainable params: 4,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97xHdHN9DB3B",
        "outputId": "7815eaba-fbaf-48e3-d574-6a83f6d2084d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 1s 189ms/step - loss: 0.1902 - accuracy: 7.5301e-04 - val_loss: 0.1807 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.1814 - accuracy: 7.5301e-04 - val_loss: 0.1718 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1730 - accuracy: 7.5301e-04 - val_loss: 0.1632 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1648 - accuracy: 7.5301e-04 - val_loss: 0.1549 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1569 - accuracy: 0.0143 - val_loss: 0.1469 - val_accuracy: 0.9398\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1493 - accuracy: 0.9119 - val_loss: 0.1393 - val_accuracy: 0.9488\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.1420 - accuracy: 0.9172 - val_loss: 0.1320 - val_accuracy: 0.9488\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1352 - accuracy: 0.9172 - val_loss: 0.1250 - val_accuracy: 0.9488\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.1286 - accuracy: 0.9172 - val_loss: 0.1184 - val_accuracy: 0.9488\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1224 - accuracy: 0.9172 - val_loss: 0.1121 - val_accuracy: 0.9488\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1165 - accuracy: 0.9172 - val_loss: 0.1062 - val_accuracy: 0.9488\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.1110 - accuracy: 0.9172 - val_loss: 0.1007 - val_accuracy: 0.9488\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.1058 - accuracy: 0.9172 - val_loss: 0.0954 - val_accuracy: 0.9488\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.1010 - accuracy: 0.9172 - val_loss: 0.0905 - val_accuracy: 0.9488\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0964 - accuracy: 0.9172 - val_loss: 0.0860 - val_accuracy: 0.9488\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0922 - accuracy: 0.9172 - val_loss: 0.0817 - val_accuracy: 0.9488\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0883 - accuracy: 0.9172 - val_loss: 0.0777 - val_accuracy: 0.9488\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0846 - accuracy: 0.9172 - val_loss: 0.0741 - val_accuracy: 0.9488\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0813 - accuracy: 0.9172 - val_loss: 0.0707 - val_accuracy: 0.9488\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0781 - accuracy: 0.9172 - val_loss: 0.0675 - val_accuracy: 0.9488\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0753 - accuracy: 0.9172 - val_loss: 0.0646 - val_accuracy: 0.9488\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0727 - accuracy: 0.9172 - val_loss: 0.0620 - val_accuracy: 0.9488\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0702 - accuracy: 0.9172 - val_loss: 0.0595 - val_accuracy: 0.9488\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0680 - accuracy: 0.9172 - val_loss: 0.0572 - val_accuracy: 0.9488\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0660 - accuracy: 0.9172 - val_loss: 0.0552 - val_accuracy: 0.9488\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0641 - accuracy: 0.9172 - val_loss: 0.0532 - val_accuracy: 0.9488\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0624 - accuracy: 0.9172 - val_loss: 0.0515 - val_accuracy: 0.9488\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0608 - accuracy: 0.9172 - val_loss: 0.0499 - val_accuracy: 0.9488\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0594 - accuracy: 0.9172 - val_loss: 0.0484 - val_accuracy: 0.9488\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0581 - accuracy: 0.9172 - val_loss: 0.0470 - val_accuracy: 0.9488\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0569 - accuracy: 0.9172 - val_loss: 0.0458 - val_accuracy: 0.9488\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0557 - accuracy: 0.9172 - val_loss: 0.0446 - val_accuracy: 0.9488\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0547 - accuracy: 0.9172 - val_loss: 0.0436 - val_accuracy: 0.9488\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0538 - accuracy: 0.9172 - val_loss: 0.0426 - val_accuracy: 0.9488\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0529 - accuracy: 0.9172 - val_loss: 0.0417 - val_accuracy: 0.9488\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0521 - accuracy: 0.9172 - val_loss: 0.0408 - val_accuracy: 0.9488\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0514 - accuracy: 0.9172 - val_loss: 0.0400 - val_accuracy: 0.9488\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0507 - accuracy: 0.9172 - val_loss: 0.0393 - val_accuracy: 0.9488\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0501 - accuracy: 0.9172 - val_loss: 0.0386 - val_accuracy: 0.9488\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0495 - accuracy: 0.9172 - val_loss: 0.0380 - val_accuracy: 0.9488\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0489 - accuracy: 0.9172 - val_loss: 0.0374 - val_accuracy: 0.9488\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0484 - accuracy: 0.9172 - val_loss: 0.0369 - val_accuracy: 0.9488\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0480 - accuracy: 0.9172 - val_loss: 0.0364 - val_accuracy: 0.9488\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0475 - accuracy: 0.9172 - val_loss: 0.0359 - val_accuracy: 0.9488\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0471 - accuracy: 0.9172 - val_loss: 0.0354 - val_accuracy: 0.9488\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0467 - accuracy: 0.9172 - val_loss: 0.0350 - val_accuracy: 0.9488\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0464 - accuracy: 0.9172 - val_loss: 0.0346 - val_accuracy: 0.9488\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0460 - accuracy: 0.9172 - val_loss: 0.0343 - val_accuracy: 0.9488\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0457 - accuracy: 0.9172 - val_loss: 0.0339 - val_accuracy: 0.9488\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0454 - accuracy: 0.9172 - val_loss: 0.0336 - val_accuracy: 0.9488\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0451 - accuracy: 0.9172 - val_loss: 0.0333 - val_accuracy: 0.9488\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0449 - accuracy: 0.9172 - val_loss: 0.0330 - val_accuracy: 0.9488\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0446 - accuracy: 0.9172 - val_loss: 0.0327 - val_accuracy: 0.9488\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0444 - accuracy: 0.9172 - val_loss: 0.0324 - val_accuracy: 0.9488\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0441 - accuracy: 0.9172 - val_loss: 0.0322 - val_accuracy: 0.9488\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0439 - accuracy: 0.9172 - val_loss: 0.0319 - val_accuracy: 0.9488\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0437 - accuracy: 0.9172 - val_loss: 0.0317 - val_accuracy: 0.9488\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0435 - accuracy: 0.9172 - val_loss: 0.0315 - val_accuracy: 0.9488\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0434 - accuracy: 0.9172 - val_loss: 0.0313 - val_accuracy: 0.9488\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0432 - accuracy: 0.9172 - val_loss: 0.0311 - val_accuracy: 0.9488\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0430 - accuracy: 0.9172 - val_loss: 0.0309 - val_accuracy: 0.9488\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0429 - accuracy: 0.9172 - val_loss: 0.0307 - val_accuracy: 0.9488\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0427 - accuracy: 0.9172 - val_loss: 0.0306 - val_accuracy: 0.9488\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0426 - accuracy: 0.9172 - val_loss: 0.0304 - val_accuracy: 0.9488\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0425 - accuracy: 0.9172 - val_loss: 0.0302 - val_accuracy: 0.9488\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0423 - accuracy: 0.9172 - val_loss: 0.0301 - val_accuracy: 0.9488\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0422 - accuracy: 0.9172 - val_loss: 0.0300 - val_accuracy: 0.9488\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0421 - accuracy: 0.9172 - val_loss: 0.0298 - val_accuracy: 0.9488\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0420 - accuracy: 0.9172 - val_loss: 0.0297 - val_accuracy: 0.9488\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0419 - accuracy: 0.9172 - val_loss: 0.0296 - val_accuracy: 0.9488\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0418 - accuracy: 0.9172 - val_loss: 0.0294 - val_accuracy: 0.9488\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0417 - accuracy: 0.9172 - val_loss: 0.0293 - val_accuracy: 0.9488\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0416 - accuracy: 0.9172 - val_loss: 0.0292 - val_accuracy: 0.9488\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0415 - accuracy: 0.9172 - val_loss: 0.0291 - val_accuracy: 0.9488\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0414 - accuracy: 0.9172 - val_loss: 0.0290 - val_accuracy: 0.9488\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0413 - accuracy: 0.9172 - val_loss: 0.0289 - val_accuracy: 0.9488\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0412 - accuracy: 0.9172 - val_loss: 0.0288 - val_accuracy: 0.9488\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0411 - accuracy: 0.9172 - val_loss: 0.0287 - val_accuracy: 0.9488\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0411 - accuracy: 0.9172 - val_loss: 0.0286 - val_accuracy: 0.9488\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0410 - accuracy: 0.9172 - val_loss: 0.0285 - val_accuracy: 0.9488\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0409 - accuracy: 0.9172 - val_loss: 0.0284 - val_accuracy: 0.9488\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0408 - accuracy: 0.9172 - val_loss: 0.0284 - val_accuracy: 0.9488\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0408 - accuracy: 0.9172 - val_loss: 0.0283 - val_accuracy: 0.9488\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0407 - accuracy: 0.9172 - val_loss: 0.0282 - val_accuracy: 0.9488\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0407 - accuracy: 0.9172 - val_loss: 0.0281 - val_accuracy: 0.9488\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0406 - accuracy: 0.9172 - val_loss: 0.0281 - val_accuracy: 0.9488\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0405 - accuracy: 0.9172 - val_loss: 0.0280 - val_accuracy: 0.9488\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0405 - accuracy: 0.9172 - val_loss: 0.0279 - val_accuracy: 0.9488\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0404 - accuracy: 0.9172 - val_loss: 0.0279 - val_accuracy: 0.9488\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0404 - accuracy: 0.9172 - val_loss: 0.0278 - val_accuracy: 0.9488\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0403 - accuracy: 0.9172 - val_loss: 0.0277 - val_accuracy: 0.9488\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0403 - accuracy: 0.9172 - val_loss: 0.0277 - val_accuracy: 0.9488\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0402 - accuracy: 0.9172 - val_loss: 0.0276 - val_accuracy: 0.9488\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0402 - accuracy: 0.9172 - val_loss: 0.0276 - val_accuracy: 0.9488\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0401 - accuracy: 0.9172 - val_loss: 0.0275 - val_accuracy: 0.9488\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0401 - accuracy: 0.9172 - val_loss: 0.0274 - val_accuracy: 0.9488\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0401 - accuracy: 0.9172 - val_loss: 0.0274 - val_accuracy: 0.9488\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0400 - accuracy: 0.9172 - val_loss: 0.0273 - val_accuracy: 0.9488\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0400 - accuracy: 0.9172 - val_loss: 0.0273 - val_accuracy: 0.9488\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0399 - accuracy: 0.9172 - val_loss: 0.0272 - val_accuracy: 0.9488\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0399 - accuracy: 0.9172 - val_loss: 0.0272 - val_accuracy: 0.9488\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0399 - accuracy: 0.9172 - val_loss: 0.0272 - val_accuracy: 0.9488\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0398 - accuracy: 0.9172 - val_loss: 0.0271 - val_accuracy: 0.9488\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0398 - accuracy: 0.9172 - val_loss: 0.0271 - val_accuracy: 0.9488\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0398 - accuracy: 0.9172 - val_loss: 0.0270 - val_accuracy: 0.9488\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0397 - accuracy: 0.9172 - val_loss: 0.0270 - val_accuracy: 0.9488\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 83ms/step - loss: 0.0397 - accuracy: 0.9172 - val_loss: 0.0269 - val_accuracy: 0.9488\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0397 - accuracy: 0.9172 - val_loss: 0.0269 - val_accuracy: 0.9488\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0396 - accuracy: 0.9172 - val_loss: 0.0269 - val_accuracy: 0.9488\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0396 - accuracy: 0.9172 - val_loss: 0.0268 - val_accuracy: 0.9488\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0396 - accuracy: 0.9172 - val_loss: 0.0268 - val_accuracy: 0.9488\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0396 - accuracy: 0.9172 - val_loss: 0.0268 - val_accuracy: 0.9488\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 76ms/step - loss: 0.0395 - accuracy: 0.9172 - val_loss: 0.0267 - val_accuracy: 0.9488\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0395 - accuracy: 0.9172 - val_loss: 0.0267 - val_accuracy: 0.9488\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0395 - accuracy: 0.9172 - val_loss: 0.0267 - val_accuracy: 0.9488\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0395 - accuracy: 0.9172 - val_loss: 0.0266 - val_accuracy: 0.9488\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0394 - accuracy: 0.9172 - val_loss: 0.0266 - val_accuracy: 0.9488\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0394 - accuracy: 0.9172 - val_loss: 0.0266 - val_accuracy: 0.9488\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0394 - accuracy: 0.9172 - val_loss: 0.0266 - val_accuracy: 0.9488\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 71ms/step - loss: 0.0394 - accuracy: 0.9172 - val_loss: 0.0265 - val_accuracy: 0.9488\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0393 - accuracy: 0.9172 - val_loss: 0.0265 - val_accuracy: 0.9488\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0393 - accuracy: 0.9172 - val_loss: 0.0265 - val_accuracy: 0.9488\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.0393 - accuracy: 0.9172 - val_loss: 0.0264 - val_accuracy: 0.9488\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0393 - accuracy: 0.9172 - val_loss: 0.0264 - val_accuracy: 0.9488\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0393 - accuracy: 0.9172 - val_loss: 0.0264 - val_accuracy: 0.9488\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0392 - accuracy: 0.9172 - val_loss: 0.0264 - val_accuracy: 0.9488\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0392 - accuracy: 0.9172 - val_loss: 0.0263 - val_accuracy: 0.9488\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 79ms/step - loss: 0.0392 - accuracy: 0.9172 - val_loss: 0.0263 - val_accuracy: 0.9488\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0392 - accuracy: 0.9172 - val_loss: 0.0263 - val_accuracy: 0.9488\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0392 - accuracy: 0.9172 - val_loss: 0.0263 - val_accuracy: 0.9488\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0392 - accuracy: 0.9172 - val_loss: 0.0263 - val_accuracy: 0.9488\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0391 - accuracy: 0.9172 - val_loss: 0.0262 - val_accuracy: 0.9488\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0391 - accuracy: 0.9172 - val_loss: 0.0262 - val_accuracy: 0.9488\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0391 - accuracy: 0.9172 - val_loss: 0.0262 - val_accuracy: 0.9488\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0391 - accuracy: 0.9172 - val_loss: 0.0262 - val_accuracy: 0.9488\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0391 - accuracy: 0.9172 - val_loss: 0.0261 - val_accuracy: 0.9488\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0391 - accuracy: 0.9172 - val_loss: 0.0261 - val_accuracy: 0.9488\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0390 - accuracy: 0.9172 - val_loss: 0.0261 - val_accuracy: 0.9488\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0390 - accuracy: 0.9172 - val_loss: 0.0261 - val_accuracy: 0.9488\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0390 - accuracy: 0.9172 - val_loss: 0.0261 - val_accuracy: 0.9488\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0390 - accuracy: 0.9172 - val_loss: 0.0261 - val_accuracy: 0.9488\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0390 - accuracy: 0.9172 - val_loss: 0.0260 - val_accuracy: 0.9488\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0390 - accuracy: 0.9172 - val_loss: 0.0260 - val_accuracy: 0.9488\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0390 - accuracy: 0.9172 - val_loss: 0.0260 - val_accuracy: 0.9488\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0260 - val_accuracy: 0.9488\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0260 - val_accuracy: 0.9488\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0260 - val_accuracy: 0.9488\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0259 - val_accuracy: 0.9488\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0259 - val_accuracy: 0.9488\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0259 - val_accuracy: 0.9488\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0259 - val_accuracy: 0.9488\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0259 - val_accuracy: 0.9488\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0389 - accuracy: 0.9172 - val_loss: 0.0259 - val_accuracy: 0.9488\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0259 - val_accuracy: 0.9488\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0258 - val_accuracy: 0.9488\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0258 - val_accuracy: 0.9488\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0258 - val_accuracy: 0.9488\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0258 - val_accuracy: 0.9488\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0258 - val_accuracy: 0.9488\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0258 - val_accuracy: 0.9488\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0258 - val_accuracy: 0.9488\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0388 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0257 - val_accuracy: 0.9488\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0387 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 35ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0256 - val_accuracy: 0.9488\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0386 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0255 - val_accuracy: 0.9488\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0254 - val_accuracy: 0.9488\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0254 - val_accuracy: 0.9488\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0254 - val_accuracy: 0.9488\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0254 - val_accuracy: 0.9488\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0254 - val_accuracy: 0.9488\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0254 - val_accuracy: 0.9488\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 36ms/step - loss: 0.0385 - accuracy: 0.9172 - val_loss: 0.0254 - val_accuracy: 0.9488\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84tgKpNdH5sq",
        "outputId": "e228ef56-c518-49e6-f91c-99f3fd48c8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0356 - accuracy: 0.9235\n",
            "Test results - Loss: 0.035553090274333954 - Accuracy: 92.34939813613892%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy1_1 = test_results[1]\n",
        "y_pred1_1 = np.argmax(ae_classifier.predict(X_test),axis=1)\n",
        "y_test1 = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "IUQlMQPIDLX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "052771d7-e98b-46e9-d0ce-7be5b888a950"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 2"
      ],
      "metadata": {
        "id": "5-bdDd5YJ3Ba"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train2.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test2.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "aL9vkVx3Da4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iMes1lg8PIZh",
        "outputId": "219174af-3c94-40a9-85ba-b2b6c04beaf1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "normal    36815\n",
              "R2L         475\n",
              "Probe        15\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count2 = len(test.index)"
      ],
      "metadata": {
        "id": "9A6wIUbQLtgg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = train.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPv-IiyAKDwy",
        "outputId": "3ed441ea-11d7-4d0c-c0fb-a6adab1c2888"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_12\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_13 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_29 (Dense)            (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nk2q9sxAKI5u",
        "outputId": "299bc08d-efe3-4636-91ec-86ca4cf961d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0813 - accuracy: 0.0336 - val_loss: 0.0682 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0683 - accuracy: 0.8626 - val_loss: 0.0654 - val_accuracy: 0.9966\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0676 - accuracy: 0.9913 - val_loss: 0.0648 - val_accuracy: 0.9982\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9929 - val_loss: 0.0646 - val_accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9934 - val_loss: 0.0646 - val_accuracy: 0.9982\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9934 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9935 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9935 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9935 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9952 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9963 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9961 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9961 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9961 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9961 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9961 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9961 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 23/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 25/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 26/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9962 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 27/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9963 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 29/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 30/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 31/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 32/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 33/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 34/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 35/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 36/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 37/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 38/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 39/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 40/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 41/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 42/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 43/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 44/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 45/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 46/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 47/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 48/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 49/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 50/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 51/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 52/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 53/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 54/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 55/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 56/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 57/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 58/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 59/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 60/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 61/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 62/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 63/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 64/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 65/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 66/100\n",
            "75/75 [==============================] - 2s 29ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 67/100\n",
            "75/75 [==============================] - 1s 11ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 68/100\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 69/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 70/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 71/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 72/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 73/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 74/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 75/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 76/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 77/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 78/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 79/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 80/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 81/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 82/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 83/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 84/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 85/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 86/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 87/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 88/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 89/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 90/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 91/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 92/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 93/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 94/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 95/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 96/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 97/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 98/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 99/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 100/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9964 - val_loss: 0.0644 - val_accuracy: 0.9982\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(50, activation=\"sigmoid\")(i_layer)   \n",
        "#fvector = Dense(24, activation='tanh')(fvector)                 \n",
        "#doutput layer\n",
        "o_layer = Dense(4, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "latent_weights_50 = autoencoder.layers[1].get_weights()\n",
        "ae_classifier.layers[1].set_weights(latent_weights_50)\n",
        "ae_classifier.layers[1].trainable = False\n",
        "\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SPFLUY67KKfj",
        "outputId": "5c238497-e101-462d-da8e-0c273c00b39d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 1ms/step\n",
            "Model: \"model_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_14 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_30 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_31 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,704\n",
            "Trainable params: 204\n",
            "Non-trainable params: 4,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o0otSVrTKWBE",
        "outputId": "39040717-83e4-44d5-c6e8-3e70ff0a4b65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 1s 40ms/step - loss: 0.1985 - accuracy: 0.7725 - val_loss: 0.1807 - val_accuracy: 0.7797\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1744 - accuracy: 0.7725 - val_loss: 0.1594 - val_accuracy: 0.7797\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1546 - accuracy: 0.7725 - val_loss: 0.1423 - val_accuracy: 0.7797\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1391 - accuracy: 0.7725 - val_loss: 0.1292 - val_accuracy: 0.7797\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1273 - accuracy: 0.7725 - val_loss: 0.1194 - val_accuracy: 0.7797\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1185 - accuracy: 0.7725 - val_loss: 0.1122 - val_accuracy: 0.7797\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1121 - accuracy: 0.7725 - val_loss: 0.1069 - val_accuracy: 0.7797\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1073 - accuracy: 0.7725 - val_loss: 0.1029 - val_accuracy: 0.7797\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1037 - accuracy: 0.7725 - val_loss: 0.1000 - val_accuracy: 0.7797\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1010 - accuracy: 0.7725 - val_loss: 0.0976 - val_accuracy: 0.7797\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0989 - accuracy: 0.7725 - val_loss: 0.0958 - val_accuracy: 0.7797\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0972 - accuracy: 0.7725 - val_loss: 0.0943 - val_accuracy: 0.7797\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0958 - accuracy: 0.7725 - val_loss: 0.0931 - val_accuracy: 0.7797\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0947 - accuracy: 0.7725 - val_loss: 0.0921 - val_accuracy: 0.7797\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0937 - accuracy: 0.7725 - val_loss: 0.0912 - val_accuracy: 0.7797\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0928 - accuracy: 0.7725 - val_loss: 0.0904 - val_accuracy: 0.7797\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0921 - accuracy: 0.7725 - val_loss: 0.0897 - val_accuracy: 0.7797\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0914 - accuracy: 0.7725 - val_loss: 0.0891 - val_accuracy: 0.7797\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0908 - accuracy: 0.7725 - val_loss: 0.0886 - val_accuracy: 0.7797\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0903 - accuracy: 0.7725 - val_loss: 0.0882 - val_accuracy: 0.7797\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0899 - accuracy: 0.7725 - val_loss: 0.0878 - val_accuracy: 0.7797\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0895 - accuracy: 0.7725 - val_loss: 0.0874 - val_accuracy: 0.7797\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0890 - accuracy: 0.7725 - val_loss: 0.0869 - val_accuracy: 0.7797\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0886 - accuracy: 0.7725 - val_loss: 0.0865 - val_accuracy: 0.7797\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0882 - accuracy: 0.7725 - val_loss: 0.0861 - val_accuracy: 0.7797\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0879 - accuracy: 0.7725 - val_loss: 0.0858 - val_accuracy: 0.7797\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0875 - accuracy: 0.7725 - val_loss: 0.0855 - val_accuracy: 0.7797\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0872 - accuracy: 0.7725 - val_loss: 0.0852 - val_accuracy: 0.7797\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0869 - accuracy: 0.7725 - val_loss: 0.0849 - val_accuracy: 0.7797\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0866 - accuracy: 0.7725 - val_loss: 0.0846 - val_accuracy: 0.7797\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0863 - accuracy: 0.7725 - val_loss: 0.0843 - val_accuracy: 0.7797\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0860 - accuracy: 0.7725 - val_loss: 0.0840 - val_accuracy: 0.7797\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0857 - accuracy: 0.7725 - val_loss: 0.0838 - val_accuracy: 0.7797\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0855 - accuracy: 0.7725 - val_loss: 0.0836 - val_accuracy: 0.7797\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0852 - accuracy: 0.7725 - val_loss: 0.0832 - val_accuracy: 0.7797\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0849 - accuracy: 0.7725 - val_loss: 0.0830 - val_accuracy: 0.7797\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0847 - accuracy: 0.7725 - val_loss: 0.0827 - val_accuracy: 0.7797\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0845 - accuracy: 0.7725 - val_loss: 0.0825 - val_accuracy: 0.7797\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0843 - accuracy: 0.7725 - val_loss: 0.0822 - val_accuracy: 0.7797\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0840 - accuracy: 0.7725 - val_loss: 0.0820 - val_accuracy: 0.7797\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0837 - accuracy: 0.7725 - val_loss: 0.0818 - val_accuracy: 0.7797\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0835 - accuracy: 0.7725 - val_loss: 0.0815 - val_accuracy: 0.7797\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0832 - accuracy: 0.7725 - val_loss: 0.0812 - val_accuracy: 0.7797\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0830 - accuracy: 0.7725 - val_loss: 0.0810 - val_accuracy: 0.7797\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0827 - accuracy: 0.7725 - val_loss: 0.0807 - val_accuracy: 0.7797\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0825 - accuracy: 0.7725 - val_loss: 0.0805 - val_accuracy: 0.7797\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0822 - accuracy: 0.7725 - val_loss: 0.0802 - val_accuracy: 0.7797\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0819 - accuracy: 0.7725 - val_loss: 0.0800 - val_accuracy: 0.7797\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0817 - accuracy: 0.7725 - val_loss: 0.0798 - val_accuracy: 0.7797\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0815 - accuracy: 0.7725 - val_loss: 0.0796 - val_accuracy: 0.7797\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0812 - accuracy: 0.7725 - val_loss: 0.0793 - val_accuracy: 0.7797\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0809 - accuracy: 0.7725 - val_loss: 0.0789 - val_accuracy: 0.7797\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0806 - accuracy: 0.7725 - val_loss: 0.0787 - val_accuracy: 0.7797\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0803 - accuracy: 0.7725 - val_loss: 0.0784 - val_accuracy: 0.7797\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0800 - accuracy: 0.7725 - val_loss: 0.0781 - val_accuracy: 0.7797\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0798 - accuracy: 0.7725 - val_loss: 0.0778 - val_accuracy: 0.7797\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0795 - accuracy: 0.7725 - val_loss: 0.0775 - val_accuracy: 0.7797\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0792 - accuracy: 0.7725 - val_loss: 0.0772 - val_accuracy: 0.7797\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0789 - accuracy: 0.7725 - val_loss: 0.0770 - val_accuracy: 0.7797\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0786 - accuracy: 0.7725 - val_loss: 0.0767 - val_accuracy: 0.7797\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0783 - accuracy: 0.7725 - val_loss: 0.0764 - val_accuracy: 0.7797\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0780 - accuracy: 0.7725 - val_loss: 0.0761 - val_accuracy: 0.7797\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0777 - accuracy: 0.7725 - val_loss: 0.0758 - val_accuracy: 0.7797\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0774 - accuracy: 0.7725 - val_loss: 0.0755 - val_accuracy: 0.7797\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0772 - accuracy: 0.7725 - val_loss: 0.0752 - val_accuracy: 0.7797\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0768 - accuracy: 0.7725 - val_loss: 0.0749 - val_accuracy: 0.7797\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0765 - accuracy: 0.7725 - val_loss: 0.0745 - val_accuracy: 0.7797\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0762 - accuracy: 0.7725 - val_loss: 0.0743 - val_accuracy: 0.7797\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0759 - accuracy: 0.7725 - val_loss: 0.0740 - val_accuracy: 0.7797\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0756 - accuracy: 0.7725 - val_loss: 0.0738 - val_accuracy: 0.7797\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0753 - accuracy: 0.7725 - val_loss: 0.0733 - val_accuracy: 0.7797\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0749 - accuracy: 0.7725 - val_loss: 0.0729 - val_accuracy: 0.7797\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0745 - accuracy: 0.7725 - val_loss: 0.0726 - val_accuracy: 0.7797\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0742 - accuracy: 0.7725 - val_loss: 0.0722 - val_accuracy: 0.7797\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0738 - accuracy: 0.7725 - val_loss: 0.0718 - val_accuracy: 0.7797\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0734 - accuracy: 0.7725 - val_loss: 0.0715 - val_accuracy: 0.7797\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0730 - accuracy: 0.7725 - val_loss: 0.0712 - val_accuracy: 0.7797\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0727 - accuracy: 0.7725 - val_loss: 0.0708 - val_accuracy: 0.7797\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0723 - accuracy: 0.7725 - val_loss: 0.0704 - val_accuracy: 0.7797\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0720 - accuracy: 0.7725 - val_loss: 0.0700 - val_accuracy: 0.7797\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0716 - accuracy: 0.7725 - val_loss: 0.0696 - val_accuracy: 0.7797\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0712 - accuracy: 0.7725 - val_loss: 0.0693 - val_accuracy: 0.7797\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0708 - accuracy: 0.7725 - val_loss: 0.0689 - val_accuracy: 0.7797\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0704 - accuracy: 0.7725 - val_loss: 0.0685 - val_accuracy: 0.7797\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0700 - accuracy: 0.7725 - val_loss: 0.0681 - val_accuracy: 0.7797\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0696 - accuracy: 0.7725 - val_loss: 0.0677 - val_accuracy: 0.7797\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0692 - accuracy: 0.7725 - val_loss: 0.0673 - val_accuracy: 0.7797\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0688 - accuracy: 0.7725 - val_loss: 0.0669 - val_accuracy: 0.7797\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0684 - accuracy: 0.7725 - val_loss: 0.0665 - val_accuracy: 0.7797\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0680 - accuracy: 0.7725 - val_loss: 0.0661 - val_accuracy: 0.7797\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0676 - accuracy: 0.7725 - val_loss: 0.0657 - val_accuracy: 0.7797\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0672 - accuracy: 0.7725 - val_loss: 0.0653 - val_accuracy: 0.7797\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0668 - accuracy: 0.7725 - val_loss: 0.0649 - val_accuracy: 0.7797\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0665 - accuracy: 0.7725 - val_loss: 0.0645 - val_accuracy: 0.7797\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0661 - accuracy: 0.7725 - val_loss: 0.0641 - val_accuracy: 0.7797\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0656 - accuracy: 0.7725 - val_loss: 0.0637 - val_accuracy: 0.7797\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0652 - accuracy: 0.7725 - val_loss: 0.0633 - val_accuracy: 0.7797\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0648 - accuracy: 0.7725 - val_loss: 0.0629 - val_accuracy: 0.7797\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0644 - accuracy: 0.7725 - val_loss: 0.0625 - val_accuracy: 0.7797\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0640 - accuracy: 0.7725 - val_loss: 0.0621 - val_accuracy: 0.7797\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0636 - accuracy: 0.7725 - val_loss: 0.0617 - val_accuracy: 0.7797\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0631 - accuracy: 0.7725 - val_loss: 0.0612 - val_accuracy: 0.7797\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0627 - accuracy: 0.7725 - val_loss: 0.0608 - val_accuracy: 0.7797\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0623 - accuracy: 0.7725 - val_loss: 0.0603 - val_accuracy: 0.7797\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0618 - accuracy: 0.7725 - val_loss: 0.0600 - val_accuracy: 0.7797\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0615 - accuracy: 0.7725 - val_loss: 0.0596 - val_accuracy: 0.7797\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0610 - accuracy: 0.7725 - val_loss: 0.0591 - val_accuracy: 0.7797\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0606 - accuracy: 0.7725 - val_loss: 0.0586 - val_accuracy: 0.7797\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0602 - accuracy: 0.7725 - val_loss: 0.0582 - val_accuracy: 0.7797\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0597 - accuracy: 0.7725 - val_loss: 0.0578 - val_accuracy: 0.7797\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0593 - accuracy: 0.7725 - val_loss: 0.0574 - val_accuracy: 0.7797\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0589 - accuracy: 0.7725 - val_loss: 0.0571 - val_accuracy: 0.7797\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0586 - accuracy: 0.7725 - val_loss: 0.0568 - val_accuracy: 0.7797\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0583 - accuracy: 0.7725 - val_loss: 0.0563 - val_accuracy: 0.7797\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 0.7725 - val_loss: 0.0558 - val_accuracy: 0.7797\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0573 - accuracy: 0.7725 - val_loss: 0.0553 - val_accuracy: 0.7797\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0569 - accuracy: 0.7725 - val_loss: 0.0550 - val_accuracy: 0.7797\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0565 - accuracy: 0.7725 - val_loss: 0.0545 - val_accuracy: 0.7797\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0561 - accuracy: 0.7725 - val_loss: 0.0542 - val_accuracy: 0.7797\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0557 - accuracy: 0.7725 - val_loss: 0.0538 - val_accuracy: 0.7797\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0554 - accuracy: 0.7725 - val_loss: 0.0535 - val_accuracy: 0.7797\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0550 - accuracy: 0.7730 - val_loss: 0.0531 - val_accuracy: 0.7797\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0546 - accuracy: 0.7730 - val_loss: 0.0527 - val_accuracy: 0.7797\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0542 - accuracy: 0.7725 - val_loss: 0.0523 - val_accuracy: 0.7797\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0539 - accuracy: 0.7725 - val_loss: 0.0520 - val_accuracy: 0.7797\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0536 - accuracy: 0.7725 - val_loss: 0.0516 - val_accuracy: 0.7797\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0532 - accuracy: 0.7725 - val_loss: 0.0513 - val_accuracy: 0.7797\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0529 - accuracy: 0.7818 - val_loss: 0.0510 - val_accuracy: 0.8994\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0526 - accuracy: 0.8917 - val_loss: 0.0506 - val_accuracy: 0.8994\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0522 - accuracy: 0.8917 - val_loss: 0.0503 - val_accuracy: 0.8994\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0519 - accuracy: 0.8957 - val_loss: 0.0499 - val_accuracy: 0.7797\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0515 - accuracy: 0.7728 - val_loss: 0.0496 - val_accuracy: 0.7797\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0513 - accuracy: 0.7728 - val_loss: 0.0493 - val_accuracy: 0.7797\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0509 - accuracy: 0.7917 - val_loss: 0.0490 - val_accuracy: 0.8859\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0506 - accuracy: 0.8920 - val_loss: 0.0487 - val_accuracy: 0.8994\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0503 - accuracy: 0.8917 - val_loss: 0.0484 - val_accuracy: 0.8994\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0500 - accuracy: 0.8917 - val_loss: 0.0481 - val_accuracy: 0.8994\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0497 - accuracy: 0.8917 - val_loss: 0.0478 - val_accuracy: 0.8994\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0495 - accuracy: 0.8917 - val_loss: 0.0475 - val_accuracy: 0.8994\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0492 - accuracy: 0.8917 - val_loss: 0.0472 - val_accuracy: 0.8994\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0489 - accuracy: 0.8917 - val_loss: 0.0469 - val_accuracy: 0.8994\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0486 - accuracy: 0.8917 - val_loss: 0.0466 - val_accuracy: 0.8994\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0483 - accuracy: 0.8917 - val_loss: 0.0464 - val_accuracy: 0.8994\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0481 - accuracy: 0.8917 - val_loss: 0.0461 - val_accuracy: 0.8994\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0478 - accuracy: 0.8917 - val_loss: 0.0459 - val_accuracy: 0.8994\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0476 - accuracy: 0.8917 - val_loss: 0.0456 - val_accuracy: 0.8994\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0473 - accuracy: 0.8917 - val_loss: 0.0454 - val_accuracy: 0.8994\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0471 - accuracy: 0.8917 - val_loss: 0.0451 - val_accuracy: 0.8994\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0469 - accuracy: 0.8917 - val_loss: 0.0449 - val_accuracy: 0.8994\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0467 - accuracy: 0.8917 - val_loss: 0.0447 - val_accuracy: 0.8994\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0464 - accuracy: 0.8917 - val_loss: 0.0445 - val_accuracy: 0.8994\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0462 - accuracy: 0.8917 - val_loss: 0.0442 - val_accuracy: 0.8994\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0460 - accuracy: 0.8917 - val_loss: 0.0441 - val_accuracy: 0.8994\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0458 - accuracy: 0.8917 - val_loss: 0.0438 - val_accuracy: 0.8994\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0456 - accuracy: 0.8917 - val_loss: 0.0436 - val_accuracy: 0.8994\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0454 - accuracy: 0.8917 - val_loss: 0.0434 - val_accuracy: 0.8994\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0452 - accuracy: 0.8917 - val_loss: 0.0433 - val_accuracy: 0.8994\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0451 - accuracy: 0.8917 - val_loss: 0.0431 - val_accuracy: 0.8994\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0448 - accuracy: 0.8917 - val_loss: 0.0428 - val_accuracy: 0.8994\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0446 - accuracy: 0.8917 - val_loss: 0.0426 - val_accuracy: 0.8994\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0445 - accuracy: 0.8917 - val_loss: 0.0425 - val_accuracy: 0.8994\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0443 - accuracy: 0.8917 - val_loss: 0.0424 - val_accuracy: 0.8994\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0442 - accuracy: 0.8917 - val_loss: 0.0422 - val_accuracy: 0.8994\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0440 - accuracy: 0.8917 - val_loss: 0.0420 - val_accuracy: 0.8994\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0438 - accuracy: 0.8917 - val_loss: 0.0418 - val_accuracy: 0.8994\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0437 - accuracy: 0.8917 - val_loss: 0.0417 - val_accuracy: 0.8994\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0435 - accuracy: 0.8917 - val_loss: 0.0415 - val_accuracy: 0.8994\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0434 - accuracy: 0.8917 - val_loss: 0.0414 - val_accuracy: 0.8994\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0433 - accuracy: 0.8917 - val_loss: 0.0413 - val_accuracy: 0.8994\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0431 - accuracy: 0.8917 - val_loss: 0.0411 - val_accuracy: 0.8994\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0430 - accuracy: 0.8917 - val_loss: 0.0410 - val_accuracy: 0.8994\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0428 - accuracy: 0.8917 - val_loss: 0.0408 - val_accuracy: 0.8994\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0427 - accuracy: 0.8917 - val_loss: 0.0407 - val_accuracy: 0.8994\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0426 - accuracy: 0.8917 - val_loss: 0.0406 - val_accuracy: 0.8994\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0425 - accuracy: 0.8917 - val_loss: 0.0404 - val_accuracy: 0.8994\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0423 - accuracy: 0.8917 - val_loss: 0.0403 - val_accuracy: 0.8994\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0422 - accuracy: 0.8917 - val_loss: 0.0402 - val_accuracy: 0.8994\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0421 - accuracy: 0.8917 - val_loss: 0.0401 - val_accuracy: 0.8994\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0420 - accuracy: 0.8917 - val_loss: 0.0400 - val_accuracy: 0.8994\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0418 - accuracy: 0.8917 - val_loss: 0.0398 - val_accuracy: 0.8994\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0418 - accuracy: 0.8917 - val_loss: 0.0397 - val_accuracy: 0.8994\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0417 - accuracy: 0.8917 - val_loss: 0.0396 - val_accuracy: 0.8994\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0415 - accuracy: 0.8917 - val_loss: 0.0395 - val_accuracy: 0.8994\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0414 - accuracy: 0.8917 - val_loss: 0.0395 - val_accuracy: 0.8994\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0414 - accuracy: 0.8917 - val_loss: 0.0394 - val_accuracy: 0.8994\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0413 - accuracy: 0.8917 - val_loss: 0.0392 - val_accuracy: 0.8994\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0412 - accuracy: 0.8917 - val_loss: 0.0391 - val_accuracy: 0.8994\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0410 - accuracy: 0.8917 - val_loss: 0.0390 - val_accuracy: 0.8994\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0409 - accuracy: 0.8917 - val_loss: 0.0389 - val_accuracy: 0.8994\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.8917 - val_loss: 0.0388 - val_accuracy: 0.8994\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.8917 - val_loss: 0.0388 - val_accuracy: 0.8994\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0408 - accuracy: 0.8917 - val_loss: 0.0387 - val_accuracy: 0.8994\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0406 - accuracy: 0.8917 - val_loss: 0.0386 - val_accuracy: 0.8994\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0405 - accuracy: 0.8917 - val_loss: 0.0385 - val_accuracy: 0.8994\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0404 - accuracy: 0.8917 - val_loss: 0.0384 - val_accuracy: 0.8994\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0404 - accuracy: 0.8917 - val_loss: 0.0383 - val_accuracy: 0.8994\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0403 - accuracy: 0.8917 - val_loss: 0.0383 - val_accuracy: 0.8994\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0402 - accuracy: 0.8917 - val_loss: 0.0382 - val_accuracy: 0.8994\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0401 - accuracy: 0.8917 - val_loss: 0.0382 - val_accuracy: 0.8994\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0401 - accuracy: 0.8917 - val_loss: 0.0382 - val_accuracy: 0.8994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7yFdz6emKcaz",
        "outputId": "ec3c3e6b-62f1-4bf2-8aad-2044c110258c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 2ms/step - loss: 0.0754 - accuracy: 0.8076\n",
            "Test results - Loss: 0.07536736875772476 - Accuracy: 80.75966835021973%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2_1 = test_results[1]\n",
        "y_pred2_1 = np.argmax(ae_classifier.predict(X_test),axis=1)\n",
        "y_test2 = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "yXPTp9vUSNsl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8770c4-f703-4934-9310-b6f60d998921"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 3"
      ],
      "metadata": {
        "id": "k6sgvJtGLw5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train3.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test3.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "CUsQTrxgMIKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQZEH8AAPVzB",
        "outputId": "d28af653-b9e7-4e88-8858-f9d160e42ddd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "normal    11711\n",
              "Probe      4509\n",
              "Dos         451\n",
              "R2L          76\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 114
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count3 = len(test.index)"
      ],
      "metadata": {
        "id": "u0VcvUpGL8ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = train.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mDJ1srHeM1aQ",
        "outputId": "e805661c-6f7e-42eb-9788-5a832eb746e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_15 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_32 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_33 (Dense)            (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CcCW2ptnM58u",
        "outputId": "1deaf4e2-f507-40e3-e05e-9252f69f9bb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 10ms/step - loss: 0.0793 - accuracy: 0.1900 - val_loss: 0.1627 - val_accuracy: 0.2047\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0754 - accuracy: 0.1547 - val_loss: 0.1543 - val_accuracy: 0.0472\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0674 - accuracy: 0.0047 - val_loss: 0.1504 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0648 - accuracy: 0.0099 - val_loss: 0.1505 - val_accuracy: 0.0057\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0633 - accuracy: 0.0739 - val_loss: 0.1497 - val_accuracy: 0.0255\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0625 - accuracy: 0.2541 - val_loss: 0.1490 - val_accuracy: 0.0519\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0621 - accuracy: 0.3124 - val_loss: 0.1496 - val_accuracy: 0.0539\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0618 - accuracy: 0.3476 - val_loss: 0.1494 - val_accuracy: 0.0663\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 5ms/step - loss: 0.0617 - accuracy: 0.4131 - val_loss: 0.1486 - val_accuracy: 0.1025\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0616 - accuracy: 0.4425 - val_loss: 0.1480 - val_accuracy: 0.1424\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0615 - accuracy: 0.4514 - val_loss: 0.1477 - val_accuracy: 0.1762\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0614 - accuracy: 0.4272 - val_loss: 0.1475 - val_accuracy: 0.1585\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0614 - accuracy: 0.4340 - val_loss: 0.1474 - val_accuracy: 0.2034\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0613 - accuracy: 0.4363 - val_loss: 0.1473 - val_accuracy: 0.2044\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0613 - accuracy: 0.4352 - val_loss: 0.1472 - val_accuracy: 0.2258\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0613 - accuracy: 0.4707 - val_loss: 0.1471 - val_accuracy: 0.2533\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0613 - accuracy: 0.4682 - val_loss: 0.1470 - val_accuracy: 0.2503\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 0.4321 - val_loss: 0.1470 - val_accuracy: 0.2382\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.4079 - val_loss: 0.1469 - val_accuracy: 0.3092\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.4286 - val_loss: 0.1468 - val_accuracy: 0.3022\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.4038 - val_loss: 0.1468 - val_accuracy: 0.3313\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.0611 - accuracy: 0.4157 - val_loss: 0.1467 - val_accuracy: 0.3233\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.4179 - val_loss: 0.1467 - val_accuracy: 0.3360\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.4148 - val_loss: 0.1466 - val_accuracy: 0.3631\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.4302 - val_loss: 0.1466 - val_accuracy: 0.3802\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.4278 - val_loss: 0.1466 - val_accuracy: 0.3876\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4364 - val_loss: 0.1466 - val_accuracy: 0.3652\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4059 - val_loss: 0.1465 - val_accuracy: 0.3819\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.3842 - val_loss: 0.1465 - val_accuracy: 0.4007\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.3994 - val_loss: 0.1465 - val_accuracy: 0.3950\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.3971 - val_loss: 0.1465 - val_accuracy: 0.3903\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4040 - val_loss: 0.1465 - val_accuracy: 0.3866\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.3971 - val_loss: 0.1464 - val_accuracy: 0.4087\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.3973 - val_loss: 0.1464 - val_accuracy: 0.4144\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4131 - val_loss: 0.1464 - val_accuracy: 0.3977\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.3884 - val_loss: 0.1464 - val_accuracy: 0.4204\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4136 - val_loss: 0.1464 - val_accuracy: 0.3920\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4007 - val_loss: 0.1464 - val_accuracy: 0.4224\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4142 - val_loss: 0.1464 - val_accuracy: 0.3889\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4179 - val_loss: 0.1464 - val_accuracy: 0.4114\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4118 - val_loss: 0.1464 - val_accuracy: 0.4050\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4088 - val_loss: 0.1464 - val_accuracy: 0.4188\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4220 - val_loss: 0.1464 - val_accuracy: 0.4007\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.3970 - val_loss: 0.1463 - val_accuracy: 0.4362\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4409 - val_loss: 0.1463 - val_accuracy: 0.3809\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4332 - val_loss: 0.1463 - val_accuracy: 0.4020\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4155 - val_loss: 0.1463 - val_accuracy: 0.3963\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4210 - val_loss: 0.1463 - val_accuracy: 0.4127\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4127 - val_loss: 0.1463 - val_accuracy: 0.4362\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4284 - val_loss: 0.1463 - val_accuracy: 0.3930\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4194 - val_loss: 0.1463 - val_accuracy: 0.3846\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4331 - val_loss: 0.1463 - val_accuracy: 0.3843\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4253 - val_loss: 0.1463 - val_accuracy: 0.3940\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4425 - val_loss: 0.1463 - val_accuracy: 0.3772\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4314 - val_loss: 0.1463 - val_accuracy: 0.4358\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4185 - val_loss: 0.1463 - val_accuracy: 0.4023\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4332 - val_loss: 0.1463 - val_accuracy: 0.3548\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 0.4354 - val_loss: 0.1463 - val_accuracy: 0.3873\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.4166 - val_loss: 0.1463 - val_accuracy: 0.4111\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.4397 - val_loss: 0.1463 - val_accuracy: 0.3782\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.4201 - val_loss: 0.1463 - val_accuracy: 0.3993\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.4118 - val_loss: 0.1462 - val_accuracy: 0.4044\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.4204 - val_loss: 0.1462 - val_accuracy: 0.4127\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.4238 - val_loss: 0.1462 - val_accuracy: 0.4412\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.4689 - val_loss: 0.1462 - val_accuracy: 0.3534\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 0.4511 - val_loss: 0.1462 - val_accuracy: 0.4111\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4142 - val_loss: 0.1462 - val_accuracy: 0.4325\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4450 - val_loss: 0.1462 - val_accuracy: 0.3648\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4275 - val_loss: 0.1462 - val_accuracy: 0.4054\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4391 - val_loss: 0.1462 - val_accuracy: 0.3839\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4185 - val_loss: 0.1462 - val_accuracy: 0.3588\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4374 - val_loss: 0.1462 - val_accuracy: 0.2925\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4589 - val_loss: 0.1462 - val_accuracy: 0.3588\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4519 - val_loss: 0.1462 - val_accuracy: 0.3005\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4111 - val_loss: 0.1462 - val_accuracy: 0.3571\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4308 - val_loss: 0.1462 - val_accuracy: 0.3092\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4581 - val_loss: 0.1462 - val_accuracy: 0.3420\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4512 - val_loss: 0.1462 - val_accuracy: 0.3430\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4395 - val_loss: 0.1462 - val_accuracy: 0.3327\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4342 - val_loss: 0.1462 - val_accuracy: 0.3142\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4657 - val_loss: 0.1462 - val_accuracy: 0.3424\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4632 - val_loss: 0.1462 - val_accuracy: 0.3377\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4607 - val_loss: 0.1462 - val_accuracy: 0.3394\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4452 - val_loss: 0.1462 - val_accuracy: 0.3441\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4525 - val_loss: 0.1462 - val_accuracy: 0.3303\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4310 - val_loss: 0.1462 - val_accuracy: 0.3069\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4302 - val_loss: 0.1462 - val_accuracy: 0.3350\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4551 - val_loss: 0.1462 - val_accuracy: 0.3481\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4635 - val_loss: 0.1462 - val_accuracy: 0.3541\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.4588 - val_loss: 0.1462 - val_accuracy: 0.3832\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4739 - val_loss: 0.1462 - val_accuracy: 0.2945\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4667 - val_loss: 0.1462 - val_accuracy: 0.4318\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4772 - val_loss: 0.1462 - val_accuracy: 0.3380\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4650 - val_loss: 0.1462 - val_accuracy: 0.3370\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.4814 - val_loss: 0.1462 - val_accuracy: 0.3879\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4834 - val_loss: 0.1462 - val_accuracy: 0.3045\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.4317 - val_loss: 0.1462 - val_accuracy: 0.3759\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0609 - accuracy: 0.4586 - val_loss: 0.1462 - val_accuracy: 0.3142\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.4302 - val_loss: 0.1462 - val_accuracy: 0.3263\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0609 - accuracy: 0.4678 - val_loss: 0.1462 - val_accuracy: 0.3417\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(50, activation=\"sigmoid\")(i_layer)   \n",
        "#fvector = Dense(24, activation='tanh')(fvector)                 \n",
        "#doutput layer\n",
        "o_layer = Dense(4, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "latent_weights_50 = autoencoder.layers[1].get_weights()\n",
        "ae_classifier.layers[1].set_weights(latent_weights_50)\n",
        "ae_classifier.layers[1].trainable = False\n",
        "\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4-QkD4jTM82f",
        "outputId": "1b6efeeb-1214-4d10-9a28-c1c8ec0f819f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 2ms/step\n",
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_16 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,704\n",
            "Trainable params: 204\n",
            "Non-trainable params: 4,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQl93NFyM_h1",
        "outputId": "000cdd2f-240d-4045-bfee-87c5670d10ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 1s 63ms/step - loss: 0.3890 - accuracy: 0.1696 - val_loss: 0.3747 - val_accuracy: 0.1876\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3657 - accuracy: 0.1696 - val_loss: 0.3511 - val_accuracy: 0.1876\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3430 - accuracy: 0.1696 - val_loss: 0.3283 - val_accuracy: 0.1876\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.3211 - accuracy: 0.1696 - val_loss: 0.3064 - val_accuracy: 0.1876\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.3002 - accuracy: 0.1696 - val_loss: 0.2858 - val_accuracy: 0.1876\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2806 - accuracy: 0.1696 - val_loss: 0.2668 - val_accuracy: 0.1876\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2626 - accuracy: 0.1696 - val_loss: 0.2493 - val_accuracy: 0.1876\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2462 - accuracy: 0.1696 - val_loss: 0.2336 - val_accuracy: 0.1876\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2315 - accuracy: 0.1696 - val_loss: 0.2198 - val_accuracy: 0.1876\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2188 - accuracy: 0.1696 - val_loss: 0.2078 - val_accuracy: 0.1876\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.2077 - accuracy: 0.1734 - val_loss: 0.1976 - val_accuracy: 0.1926\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1982 - accuracy: 0.3333 - val_loss: 0.1890 - val_accuracy: 0.5779\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1903 - accuracy: 0.5549 - val_loss: 0.1819 - val_accuracy: 0.5779\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1837 - accuracy: 0.5544 - val_loss: 0.1759 - val_accuracy: 0.5779\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1782 - accuracy: 0.5544 - val_loss: 0.1710 - val_accuracy: 0.5779\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1736 - accuracy: 0.5544 - val_loss: 0.1670 - val_accuracy: 0.5779\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1699 - accuracy: 0.5544 - val_loss: 0.1637 - val_accuracy: 0.5779\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1668 - accuracy: 0.5544 - val_loss: 0.1609 - val_accuracy: 0.5779\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1642 - accuracy: 0.5544 - val_loss: 0.1586 - val_accuracy: 0.5779\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1620 - accuracy: 0.5544 - val_loss: 0.1567 - val_accuracy: 0.5779\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1602 - accuracy: 0.5544 - val_loss: 0.1550 - val_accuracy: 0.5779\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1586 - accuracy: 0.5544 - val_loss: 0.1536 - val_accuracy: 0.5779\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1572 - accuracy: 0.5544 - val_loss: 0.1524 - val_accuracy: 0.5779\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1560 - accuracy: 0.5544 - val_loss: 0.1514 - val_accuracy: 0.5779\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1550 - accuracy: 0.5544 - val_loss: 0.1505 - val_accuracy: 0.5779\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1540 - accuracy: 0.5544 - val_loss: 0.1497 - val_accuracy: 0.5779\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1532 - accuracy: 0.5544 - val_loss: 0.1490 - val_accuracy: 0.5779\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1525 - accuracy: 0.5544 - val_loss: 0.1483 - val_accuracy: 0.5779\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1518 - accuracy: 0.5544 - val_loss: 0.1478 - val_accuracy: 0.5779\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1512 - accuracy: 0.5544 - val_loss: 0.1472 - val_accuracy: 0.5779\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1506 - accuracy: 0.5544 - val_loss: 0.1467 - val_accuracy: 0.5779\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1501 - accuracy: 0.5544 - val_loss: 0.1463 - val_accuracy: 0.5779\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1496 - accuracy: 0.5544 - val_loss: 0.1458 - val_accuracy: 0.5779\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1492 - accuracy: 0.5544 - val_loss: 0.1454 - val_accuracy: 0.5779\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1487 - accuracy: 0.5544 - val_loss: 0.1450 - val_accuracy: 0.5779\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1483 - accuracy: 0.5544 - val_loss: 0.1446 - val_accuracy: 0.5779\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1479 - accuracy: 0.5544 - val_loss: 0.1442 - val_accuracy: 0.5779\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1475 - accuracy: 0.5544 - val_loss: 0.1438 - val_accuracy: 0.5779\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1472 - accuracy: 0.5544 - val_loss: 0.1435 - val_accuracy: 0.5779\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1468 - accuracy: 0.5544 - val_loss: 0.1431 - val_accuracy: 0.5779\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1465 - accuracy: 0.5544 - val_loss: 0.1428 - val_accuracy: 0.5779\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1462 - accuracy: 0.5544 - val_loss: 0.1425 - val_accuracy: 0.5779\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1459 - accuracy: 0.5544 - val_loss: 0.1422 - val_accuracy: 0.5779\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1455 - accuracy: 0.5544 - val_loss: 0.1419 - val_accuracy: 0.5779\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1452 - accuracy: 0.5544 - val_loss: 0.1416 - val_accuracy: 0.5779\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1449 - accuracy: 0.5544 - val_loss: 0.1413 - val_accuracy: 0.5779\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1446 - accuracy: 0.5544 - val_loss: 0.1409 - val_accuracy: 0.5779\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1443 - accuracy: 0.5544 - val_loss: 0.1406 - val_accuracy: 0.5779\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1441 - accuracy: 0.5544 - val_loss: 0.1404 - val_accuracy: 0.5779\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1438 - accuracy: 0.5544 - val_loss: 0.1401 - val_accuracy: 0.5779\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1435 - accuracy: 0.5544 - val_loss: 0.1398 - val_accuracy: 0.5779\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1432 - accuracy: 0.5544 - val_loss: 0.1395 - val_accuracy: 0.5779\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1429 - accuracy: 0.5544 - val_loss: 0.1392 - val_accuracy: 0.5779\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1426 - accuracy: 0.5544 - val_loss: 0.1389 - val_accuracy: 0.5779\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1424 - accuracy: 0.5544 - val_loss: 0.1386 - val_accuracy: 0.5779\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1421 - accuracy: 0.5544 - val_loss: 0.1384 - val_accuracy: 0.5779\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1418 - accuracy: 0.5544 - val_loss: 0.1381 - val_accuracy: 0.5779\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1415 - accuracy: 0.5544 - val_loss: 0.1378 - val_accuracy: 0.5779\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1413 - accuracy: 0.5544 - val_loss: 0.1375 - val_accuracy: 0.5779\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1410 - accuracy: 0.5544 - val_loss: 0.1372 - val_accuracy: 0.5779\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1407 - accuracy: 0.5544 - val_loss: 0.1369 - val_accuracy: 0.5779\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1404 - accuracy: 0.5544 - val_loss: 0.1366 - val_accuracy: 0.5779\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1402 - accuracy: 0.5544 - val_loss: 0.1364 - val_accuracy: 0.5779\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1399 - accuracy: 0.5544 - val_loss: 0.1361 - val_accuracy: 0.5779\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1396 - accuracy: 0.5544 - val_loss: 0.1358 - val_accuracy: 0.5779\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1393 - accuracy: 0.5544 - val_loss: 0.1355 - val_accuracy: 0.5779\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1391 - accuracy: 0.5544 - val_loss: 0.1353 - val_accuracy: 0.5779\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1388 - accuracy: 0.5544 - val_loss: 0.1350 - val_accuracy: 0.5779\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1385 - accuracy: 0.5544 - val_loss: 0.1347 - val_accuracy: 0.5779\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1382 - accuracy: 0.5544 - val_loss: 0.1344 - val_accuracy: 0.5779\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1379 - accuracy: 0.5544 - val_loss: 0.1341 - val_accuracy: 0.5779\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1377 - accuracy: 0.5544 - val_loss: 0.1338 - val_accuracy: 0.5779\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1374 - accuracy: 0.5544 - val_loss: 0.1335 - val_accuracy: 0.5779\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1371 - accuracy: 0.5544 - val_loss: 0.1332 - val_accuracy: 0.5779\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1368 - accuracy: 0.5544 - val_loss: 0.1329 - val_accuracy: 0.5779\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1365 - accuracy: 0.5544 - val_loss: 0.1326 - val_accuracy: 0.5779\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1362 - accuracy: 0.5544 - val_loss: 0.1323 - val_accuracy: 0.5779\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1359 - accuracy: 0.5544 - val_loss: 0.1320 - val_accuracy: 0.5779\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1356 - accuracy: 0.5544 - val_loss: 0.1317 - val_accuracy: 0.5779\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1353 - accuracy: 0.5544 - val_loss: 0.1313 - val_accuracy: 0.5779\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1350 - accuracy: 0.5544 - val_loss: 0.1310 - val_accuracy: 0.5779\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1347 - accuracy: 0.5544 - val_loss: 0.1307 - val_accuracy: 0.5779\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1344 - accuracy: 0.5544 - val_loss: 0.1304 - val_accuracy: 0.5779\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1341 - accuracy: 0.5544 - val_loss: 0.1301 - val_accuracy: 0.5779\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1338 - accuracy: 0.5544 - val_loss: 0.1298 - val_accuracy: 0.5779\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1335 - accuracy: 0.5544 - val_loss: 0.1295 - val_accuracy: 0.5779\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1332 - accuracy: 0.5544 - val_loss: 0.1292 - val_accuracy: 0.5779\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1329 - accuracy: 0.5544 - val_loss: 0.1288 - val_accuracy: 0.5779\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1326 - accuracy: 0.5544 - val_loss: 0.1285 - val_accuracy: 0.5779\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1322 - accuracy: 0.5544 - val_loss: 0.1281 - val_accuracy: 0.5779\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1319 - accuracy: 0.5544 - val_loss: 0.1278 - val_accuracy: 0.5779\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1316 - accuracy: 0.5544 - val_loss: 0.1275 - val_accuracy: 0.5779\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1313 - accuracy: 0.5544 - val_loss: 0.1271 - val_accuracy: 0.5779\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1309 - accuracy: 0.5544 - val_loss: 0.1268 - val_accuracy: 0.5779\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1306 - accuracy: 0.5544 - val_loss: 0.1265 - val_accuracy: 0.5779\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1303 - accuracy: 0.5544 - val_loss: 0.1262 - val_accuracy: 0.5779\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1299 - accuracy: 0.5544 - val_loss: 0.1259 - val_accuracy: 0.5779\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1296 - accuracy: 0.5544 - val_loss: 0.1255 - val_accuracy: 0.5779\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1293 - accuracy: 0.5544 - val_loss: 0.1251 - val_accuracy: 0.5779\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1289 - accuracy: 0.5544 - val_loss: 0.1248 - val_accuracy: 0.5779\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1286 - accuracy: 0.5544 - val_loss: 0.1244 - val_accuracy: 0.5779\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1282 - accuracy: 0.5544 - val_loss: 0.1241 - val_accuracy: 0.5779\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1279 - accuracy: 0.5544 - val_loss: 0.1237 - val_accuracy: 0.5779\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1275 - accuracy: 0.5544 - val_loss: 0.1233 - val_accuracy: 0.5779\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1272 - accuracy: 0.5544 - val_loss: 0.1229 - val_accuracy: 0.5779\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1268 - accuracy: 0.5544 - val_loss: 0.1225 - val_accuracy: 0.5779\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1264 - accuracy: 0.5544 - val_loss: 0.1221 - val_accuracy: 0.5779\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1261 - accuracy: 0.5544 - val_loss: 0.1218 - val_accuracy: 0.5779\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1257 - accuracy: 0.5544 - val_loss: 0.1214 - val_accuracy: 0.5779\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1253 - accuracy: 0.5544 - val_loss: 0.1210 - val_accuracy: 0.5779\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1250 - accuracy: 0.5544 - val_loss: 0.1206 - val_accuracy: 0.5779\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1246 - accuracy: 0.5544 - val_loss: 0.1202 - val_accuracy: 0.5779\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1242 - accuracy: 0.5544 - val_loss: 0.1199 - val_accuracy: 0.5779\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1239 - accuracy: 0.5544 - val_loss: 0.1195 - val_accuracy: 0.5779\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1235 - accuracy: 0.5544 - val_loss: 0.1191 - val_accuracy: 0.5779\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1231 - accuracy: 0.5544 - val_loss: 0.1187 - val_accuracy: 0.5779\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1227 - accuracy: 0.5544 - val_loss: 0.1183 - val_accuracy: 0.5779\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1223 - accuracy: 0.5544 - val_loss: 0.1180 - val_accuracy: 0.5779\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1219 - accuracy: 0.5544 - val_loss: 0.1176 - val_accuracy: 0.5779\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1215 - accuracy: 0.5544 - val_loss: 0.1172 - val_accuracy: 0.5779\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1212 - accuracy: 0.5544 - val_loss: 0.1167 - val_accuracy: 0.5779\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1208 - accuracy: 0.5544 - val_loss: 0.1163 - val_accuracy: 0.5779\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 0.5544 - val_loss: 0.1159 - val_accuracy: 0.5779\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1200 - accuracy: 0.5544 - val_loss: 0.1155 - val_accuracy: 0.5779\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1196 - accuracy: 0.5544 - val_loss: 0.1150 - val_accuracy: 0.5779\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1192 - accuracy: 0.5544 - val_loss: 0.1146 - val_accuracy: 0.5796\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1188 - accuracy: 0.5536 - val_loss: 0.1142 - val_accuracy: 0.5779\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1184 - accuracy: 0.5523 - val_loss: 0.1138 - val_accuracy: 0.5796\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1179 - accuracy: 0.5532 - val_loss: 0.1134 - val_accuracy: 0.5779\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1175 - accuracy: 0.5544 - val_loss: 0.1130 - val_accuracy: 0.5762\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1171 - accuracy: 0.5536 - val_loss: 0.1126 - val_accuracy: 0.5796\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1167 - accuracy: 0.5507 - val_loss: 0.1122 - val_accuracy: 0.5829\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1163 - accuracy: 0.5532 - val_loss: 0.1117 - val_accuracy: 0.5829\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1159 - accuracy: 0.5540 - val_loss: 0.1113 - val_accuracy: 0.5829\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1155 - accuracy: 0.5544 - val_loss: 0.1109 - val_accuracy: 0.5846\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1150 - accuracy: 0.5553 - val_loss: 0.1105 - val_accuracy: 0.5846\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1146 - accuracy: 0.5557 - val_loss: 0.1101 - val_accuracy: 0.5846\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1142 - accuracy: 0.5549 - val_loss: 0.1097 - val_accuracy: 0.5846\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1138 - accuracy: 0.5549 - val_loss: 0.1092 - val_accuracy: 0.5846\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1134 - accuracy: 0.5553 - val_loss: 0.1087 - val_accuracy: 0.5846\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1129 - accuracy: 0.5553 - val_loss: 0.1083 - val_accuracy: 0.5846\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1125 - accuracy: 0.5553 - val_loss: 0.1078 - val_accuracy: 0.5846\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1121 - accuracy: 0.5557 - val_loss: 0.1074 - val_accuracy: 0.5846\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1117 - accuracy: 0.5557 - val_loss: 0.1070 - val_accuracy: 0.5846\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1112 - accuracy: 0.5557 - val_loss: 0.1065 - val_accuracy: 0.5846\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 29ms/step - loss: 0.1108 - accuracy: 0.5561 - val_loss: 0.1061 - val_accuracy: 0.5846\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1104 - accuracy: 0.5561 - val_loss: 0.1056 - val_accuracy: 0.5846\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1099 - accuracy: 0.5565 - val_loss: 0.1052 - val_accuracy: 0.5879\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1095 - accuracy: 0.5574 - val_loss: 0.1048 - val_accuracy: 0.5863\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1091 - accuracy: 0.5561 - val_loss: 0.1043 - val_accuracy: 0.5863\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1086 - accuracy: 0.5536 - val_loss: 0.1039 - val_accuracy: 0.5896\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1082 - accuracy: 0.5507 - val_loss: 0.1034 - val_accuracy: 0.5863\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1078 - accuracy: 0.5511 - val_loss: 0.1030 - val_accuracy: 0.5863\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1073 - accuracy: 0.5511 - val_loss: 0.1025 - val_accuracy: 0.5879\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1069 - accuracy: 0.5515 - val_loss: 0.1021 - val_accuracy: 0.5879\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1065 - accuracy: 0.5515 - val_loss: 0.1017 - val_accuracy: 0.5879\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1060 - accuracy: 0.5515 - val_loss: 0.1012 - val_accuracy: 0.5879\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1056 - accuracy: 0.5515 - val_loss: 0.1008 - val_accuracy: 0.5879\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1052 - accuracy: 0.5540 - val_loss: 0.1003 - val_accuracy: 0.6030\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1047 - accuracy: 0.5766 - val_loss: 0.0998 - val_accuracy: 0.6315\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1043 - accuracy: 0.6089 - val_loss: 0.0994 - val_accuracy: 0.6935\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1039 - accuracy: 0.6545 - val_loss: 0.0990 - val_accuracy: 0.7152\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1034 - accuracy: 0.6750 - val_loss: 0.0985 - val_accuracy: 0.7303\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1030 - accuracy: 0.6960 - val_loss: 0.0981 - val_accuracy: 0.7471\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.1026 - accuracy: 0.7127 - val_loss: 0.0977 - val_accuracy: 0.7621\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.1021 - accuracy: 0.7345 - val_loss: 0.0973 - val_accuracy: 0.7772\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1017 - accuracy: 0.7462 - val_loss: 0.0968 - val_accuracy: 0.7856\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1013 - accuracy: 0.7538 - val_loss: 0.0964 - val_accuracy: 0.7856\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1008 - accuracy: 0.7559 - val_loss: 0.0959 - val_accuracy: 0.7873\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.1004 - accuracy: 0.7592 - val_loss: 0.0955 - val_accuracy: 0.7873\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1000 - accuracy: 0.7621 - val_loss: 0.0950 - val_accuracy: 0.7873\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0996 - accuracy: 0.7642 - val_loss: 0.0946 - val_accuracy: 0.7973\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0991 - accuracy: 0.7697 - val_loss: 0.0942 - val_accuracy: 0.7990\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0987 - accuracy: 0.7776 - val_loss: 0.0938 - val_accuracy: 0.8107\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0983 - accuracy: 0.7843 - val_loss: 0.0933 - val_accuracy: 0.8208\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0978 - accuracy: 0.7927 - val_loss: 0.0929 - val_accuracy: 0.8291\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0974 - accuracy: 0.7977 - val_loss: 0.0924 - val_accuracy: 0.8325\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0970 - accuracy: 0.8057 - val_loss: 0.0920 - val_accuracy: 0.8392\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0966 - accuracy: 0.8220 - val_loss: 0.0916 - val_accuracy: 0.8526\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0961 - accuracy: 0.8321 - val_loss: 0.0911 - val_accuracy: 0.8543\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0957 - accuracy: 0.8375 - val_loss: 0.0907 - val_accuracy: 0.8559\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0953 - accuracy: 0.8421 - val_loss: 0.0903 - val_accuracy: 0.8626\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0949 - accuracy: 0.8551 - val_loss: 0.0899 - val_accuracy: 0.8827\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0945 - accuracy: 0.8769 - val_loss: 0.0895 - val_accuracy: 0.8827\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0940 - accuracy: 0.8773 - val_loss: 0.0890 - val_accuracy: 0.8827\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0936 - accuracy: 0.8773 - val_loss: 0.0886 - val_accuracy: 0.8827\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0932 - accuracy: 0.8781 - val_loss: 0.0882 - val_accuracy: 0.8827\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0928 - accuracy: 0.8781 - val_loss: 0.0877 - val_accuracy: 0.8827\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0924 - accuracy: 0.8781 - val_loss: 0.0873 - val_accuracy: 0.8827\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0920 - accuracy: 0.8781 - val_loss: 0.0869 - val_accuracy: 0.8827\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0916 - accuracy: 0.8781 - val_loss: 0.0865 - val_accuracy: 0.8827\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0912 - accuracy: 0.8786 - val_loss: 0.0861 - val_accuracy: 0.8827\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0907 - accuracy: 0.8786 - val_loss: 0.0857 - val_accuracy: 0.8827\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0903 - accuracy: 0.8790 - val_loss: 0.0853 - val_accuracy: 0.8827\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0899 - accuracy: 0.8790 - val_loss: 0.0849 - val_accuracy: 0.8827\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0895 - accuracy: 0.8794 - val_loss: 0.0845 - val_accuracy: 0.8827\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0891 - accuracy: 0.8794 - val_loss: 0.0841 - val_accuracy: 0.8827\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0887 - accuracy: 0.8798 - val_loss: 0.0837 - val_accuracy: 0.8827\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.0883 - accuracy: 0.8798 - val_loss: 0.0832 - val_accuracy: 0.8827\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0879 - accuracy: 0.8798 - val_loss: 0.0828 - val_accuracy: 0.8844\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dapCiVOZNBon",
        "outputId": "9412f0a1-a4d3-46f7-ac42-ddfc7b8a15e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step - loss: 0.0572 - accuracy: 0.9176\n",
            "Test results - Loss: 0.05717872083187103 - Accuracy: 91.758793592453%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy3_1 = test_results[1]\n",
        "y_pred3_1 = np.argmax(ae_classifier.predict(X_test),axis=1)\n",
        "y_test3 = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "UkAgSiANR-Yd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd58e263-3a53-4bed-8f54-779181c14bd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 4"
      ],
      "metadata": {
        "id": "A7qVVwUOL1Rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train4.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test4.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "4GdJWFGlL6iT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NGOLeyzlPdZ9",
        "outputId": "cfee41dc-e7ec-4a1d-c7f8-4e86511773a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "normal    6201\n",
              "Probe     4880\n",
              "Dos       4181\n",
              "R2L         17\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count4 = len(test.index)"
      ],
      "metadata": {
        "id": "iDXaVmCWNKLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = train.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.drop(['intrusion','Dos','normal','Probe','R2L','label','clusterNo'],axis=1)\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D2ajucOgNNtQ",
        "outputId": "b6583c01-12f6-40f1-d876-aeb0af4c9d18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQZ3csWCNUnp",
        "outputId": "1dd86058-8228-4fa8-de85-2e95441edde7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 1s 17ms/step - loss: 0.1050 - accuracy: 6.5449e-05 - val_loss: 0.1689 - val_accuracy: 3.9565e-04\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.1033 - accuracy: 0.0522 - val_loss: 0.1637 - val_accuracy: 0.0061\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.1657 - val_loss: 0.1559 - val_accuracy: 0.1949\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0912 - accuracy: 0.3552 - val_loss: 0.1542 - val_accuracy: 0.2574\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0898 - accuracy: 0.3932 - val_loss: 0.1537 - val_accuracy: 0.2208\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0892 - accuracy: 0.4175 - val_loss: 0.1533 - val_accuracy: 0.2008\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0888 - accuracy: 0.4148 - val_loss: 0.1532 - val_accuracy: 0.1792\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0886 - accuracy: 0.4140 - val_loss: 0.1530 - val_accuracy: 0.1515\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0885 - accuracy: 0.3747 - val_loss: 0.1528 - val_accuracy: 0.1306\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0884 - accuracy: 0.3534 - val_loss: 0.1527 - val_accuracy: 0.1302\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0884 - accuracy: 0.3491 - val_loss: 0.1525 - val_accuracy: 0.1177\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0883 - accuracy: 0.3347 - val_loss: 0.1521 - val_accuracy: 0.1120\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0882 - accuracy: 0.3386 - val_loss: 0.1374 - val_accuracy: 0.6051\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.4188 - val_loss: 0.1348 - val_accuracy: 0.6657\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0876 - accuracy: 0.4908 - val_loss: 0.1342 - val_accuracy: 0.7407\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0875 - accuracy: 0.4673 - val_loss: 0.1339 - val_accuracy: 0.7383\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0875 - accuracy: 0.4616 - val_loss: 0.1338 - val_accuracy: 0.7496\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.4612 - val_loss: 0.1337 - val_accuracy: 0.7217\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0875 - accuracy: 0.4526 - val_loss: 0.1337 - val_accuracy: 0.7409\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0874 - accuracy: 0.4527 - val_loss: 0.1336 - val_accuracy: 0.7262\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.4715 - val_loss: 0.1336 - val_accuracy: 0.7321\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4656 - val_loss: 0.1336 - val_accuracy: 0.7280\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.4628 - val_loss: 0.1336 - val_accuracy: 0.7195\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.4638 - val_loss: 0.1336 - val_accuracy: 0.7325\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4614 - val_loss: 0.1336 - val_accuracy: 0.7215\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.4578 - val_loss: 0.1336 - val_accuracy: 0.6892\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.4546 - val_loss: 0.1336 - val_accuracy: 0.7221\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.4462 - val_loss: 0.1336 - val_accuracy: 0.7122\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.4392 - val_loss: 0.1336 - val_accuracy: 0.7159\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4538 - val_loss: 0.1336 - val_accuracy: 0.7308\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.4668 - val_loss: 0.1336 - val_accuracy: 0.7373\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4558 - val_loss: 0.1336 - val_accuracy: 0.7147\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4473 - val_loss: 0.1336 - val_accuracy: 0.7141\n",
            "Epoch 34/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4378 - val_loss: 0.1336 - val_accuracy: 0.7248\n",
            "Epoch 35/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0874 - accuracy: 0.4558 - val_loss: 0.1336 - val_accuracy: 0.7149\n",
            "Epoch 36/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.4448 - val_loss: 0.1336 - val_accuracy: 0.7096\n",
            "Epoch 37/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0874 - accuracy: 0.4385 - val_loss: 0.1335 - val_accuracy: 0.7331\n",
            "Epoch 38/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4601 - val_loss: 0.1335 - val_accuracy: 0.6851\n",
            "Epoch 39/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0873 - accuracy: 0.4404 - val_loss: 0.1334 - val_accuracy: 0.7319\n",
            "Epoch 40/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.5214 - val_loss: 0.1334 - val_accuracy: 0.7450\n",
            "Epoch 41/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0871 - accuracy: 0.5481 - val_loss: 0.1334 - val_accuracy: 0.7765\n",
            "Epoch 42/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.5533 - val_loss: 0.1334 - val_accuracy: 0.7379\n",
            "Epoch 43/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5565 - val_loss: 0.1334 - val_accuracy: 0.7881\n",
            "Epoch 44/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.5625 - val_loss: 0.1333 - val_accuracy: 0.7583\n",
            "Epoch 45/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5581 - val_loss: 0.1333 - val_accuracy: 0.7472\n",
            "Epoch 46/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5525 - val_loss: 0.1333 - val_accuracy: 0.7862\n",
            "Epoch 47/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5683 - val_loss: 0.1333 - val_accuracy: 0.7804\n",
            "Epoch 48/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5621 - val_loss: 0.1333 - val_accuracy: 0.7822\n",
            "Epoch 49/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5504 - val_loss: 0.1333 - val_accuracy: 0.7316\n",
            "Epoch 50/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5528 - val_loss: 0.1333 - val_accuracy: 0.7468\n",
            "Epoch 51/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5434 - val_loss: 0.1333 - val_accuracy: 0.7879\n",
            "Epoch 52/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.5411 - val_loss: 0.1333 - val_accuracy: 0.7555\n",
            "Epoch 53/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.5584 - val_loss: 0.1333 - val_accuracy: 0.7616\n",
            "Epoch 54/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.5540 - val_loss: 0.1333 - val_accuracy: 0.7577\n",
            "Epoch 55/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.5528 - val_loss: 0.1333 - val_accuracy: 0.7725\n",
            "Epoch 56/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.5676 - val_loss: 0.1333 - val_accuracy: 0.7610\n",
            "Epoch 57/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0870 - accuracy: 0.5388 - val_loss: 0.1333 - val_accuracy: 0.7598\n",
            "Epoch 58/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0870 - accuracy: 0.5555 - val_loss: 0.1333 - val_accuracy: 0.7755\n",
            "Epoch 59/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.5413 - val_loss: 0.1333 - val_accuracy: 0.7810\n",
            "Epoch 60/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0870 - accuracy: 0.5349 - val_loss: 0.1333 - val_accuracy: 0.7602\n",
            "Epoch 61/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.5453 - val_loss: 0.1333 - val_accuracy: 0.7549\n",
            "Epoch 62/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5472 - val_loss: 0.1333 - val_accuracy: 0.7482\n",
            "Epoch 63/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5493 - val_loss: 0.1333 - val_accuracy: 0.7462\n",
            "Epoch 64/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5417 - val_loss: 0.1333 - val_accuracy: 0.7630\n",
            "Epoch 65/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5576 - val_loss: 0.1333 - val_accuracy: 0.7298\n",
            "Epoch 66/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5428 - val_loss: 0.1333 - val_accuracy: 0.7680\n",
            "Epoch 67/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5460 - val_loss: 0.1333 - val_accuracy: 0.7707\n",
            "Epoch 68/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5422 - val_loss: 0.1333 - val_accuracy: 0.7177\n",
            "Epoch 69/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0870 - accuracy: 0.5382 - val_loss: 0.1333 - val_accuracy: 0.8034\n",
            "Epoch 70/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5434 - val_loss: 0.1333 - val_accuracy: 0.8107\n",
            "Epoch 71/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5403 - val_loss: 0.1333 - val_accuracy: 0.7124\n",
            "Epoch 72/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5294 - val_loss: 0.1333 - val_accuracy: 0.7412\n",
            "Epoch 73/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5498 - val_loss: 0.1333 - val_accuracy: 0.7982\n",
            "Epoch 74/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5448 - val_loss: 0.1333 - val_accuracy: 0.7519\n",
            "Epoch 75/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.5410 - val_loss: 0.1333 - val_accuracy: 0.7650\n",
            "Epoch 76/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5371 - val_loss: 0.1334 - val_accuracy: 0.7486\n",
            "Epoch 77/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5439 - val_loss: 0.1334 - val_accuracy: 0.7771\n",
            "Epoch 78/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5401 - val_loss: 0.1334 - val_accuracy: 0.7377\n",
            "Epoch 79/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5398 - val_loss: 0.1334 - val_accuracy: 0.7523\n",
            "Epoch 80/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5364 - val_loss: 0.1334 - val_accuracy: 0.7329\n",
            "Epoch 81/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5421 - val_loss: 0.1334 - val_accuracy: 0.7422\n",
            "Epoch 82/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.5383 - val_loss: 0.1334 - val_accuracy: 0.7836\n",
            "Epoch 83/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.5459 - val_loss: 0.1334 - val_accuracy: 0.7551\n",
            "Epoch 84/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.5335 - val_loss: 0.1334 - val_accuracy: 0.7553\n",
            "Epoch 85/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5415 - val_loss: 0.1334 - val_accuracy: 0.7721\n",
            "Epoch 86/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5268 - val_loss: 0.1334 - val_accuracy: 0.7666\n",
            "Epoch 87/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5431 - val_loss: 0.1334 - val_accuracy: 0.7555\n",
            "Epoch 88/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5327 - val_loss: 0.1334 - val_accuracy: 0.7875\n",
            "Epoch 89/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5395 - val_loss: 0.1334 - val_accuracy: 0.7292\n",
            "Epoch 90/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5362 - val_loss: 0.1334 - val_accuracy: 0.7527\n",
            "Epoch 91/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0870 - accuracy: 0.5363 - val_loss: 0.1334 - val_accuracy: 0.7377\n",
            "Epoch 92/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5354 - val_loss: 0.1334 - val_accuracy: 0.7308\n",
            "Epoch 93/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5383 - val_loss: 0.1334 - val_accuracy: 0.7553\n",
            "Epoch 94/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5366 - val_loss: 0.1334 - val_accuracy: 0.7221\n",
            "Epoch 95/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5252 - val_loss: 0.1334 - val_accuracy: 0.7915\n",
            "Epoch 96/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5327 - val_loss: 0.1334 - val_accuracy: 0.7401\n",
            "Epoch 97/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5316 - val_loss: 0.1334 - val_accuracy: 0.7369\n",
            "Epoch 98/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5340 - val_loss: 0.1334 - val_accuracy: 0.7424\n",
            "Epoch 99/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0870 - accuracy: 0.5409 - val_loss: 0.1334 - val_accuracy: 0.7104\n",
            "Epoch 100/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0870 - accuracy: 0.5405 - val_loss: 0.1334 - val_accuracy: 0.7444\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(50, activation=\"sigmoid\")(i_layer)   \n",
        "#fvector = Dense(24, activation='tanh')(fvector)                 \n",
        "#doutput layer\n",
        "o_layer = Dense(4, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "latent_weights_50 = autoencoder.layers[1].get_weights()\n",
        "ae_classifier.layers[1].set_weights(latent_weights_50)\n",
        "ae_classifier.layers[1].trainable = False\n",
        "\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w_GBpJjBNXA1",
        "outputId": "77fde77b-a426-4743-a672-f8f4377ea9c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 1ms/step\n",
            "Model: \"model_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_38 (Dense)            (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_39 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,704\n",
            "Trainable params: 204\n",
            "Non-trainable params: 4,500\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MXa8PREtNW6U",
        "outputId": "b6ef72a4-18a4-4135-e6fa-cbceff75f055"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 1s 57ms/step - loss: 0.2516 - accuracy: 0.0371 - val_loss: 0.2381 - val_accuracy: 0.1939\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.2297 - accuracy: 0.5529 - val_loss: 0.2178 - val_accuracy: 0.6311\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.2106 - accuracy: 0.6308 - val_loss: 0.2006 - val_accuracy: 0.6311\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1946 - accuracy: 0.6308 - val_loss: 0.1864 - val_accuracy: 0.6311\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1817 - accuracy: 0.6308 - val_loss: 0.1749 - val_accuracy: 0.6311\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1711 - accuracy: 0.6308 - val_loss: 0.1660 - val_accuracy: 0.6311\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1631 - accuracy: 0.6308 - val_loss: 0.1590 - val_accuracy: 0.6311\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1568 - accuracy: 0.6308 - val_loss: 0.1537 - val_accuracy: 0.6311\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1520 - accuracy: 0.6308 - val_loss: 0.1495 - val_accuracy: 0.6311\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1483 - accuracy: 0.6308 - val_loss: 0.1463 - val_accuracy: 0.6311\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1454 - accuracy: 0.6308 - val_loss: 0.1438 - val_accuracy: 0.6311\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1431 - accuracy: 0.6308 - val_loss: 0.1418 - val_accuracy: 0.6311\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1412 - accuracy: 0.6308 - val_loss: 0.1402 - val_accuracy: 0.6311\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1397 - accuracy: 0.6308 - val_loss: 0.1388 - val_accuracy: 0.6311\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1384 - accuracy: 0.6308 - val_loss: 0.1376 - val_accuracy: 0.6311\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1373 - accuracy: 0.6308 - val_loss: 0.1365 - val_accuracy: 0.6311\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1363 - accuracy: 0.6308 - val_loss: 0.1356 - val_accuracy: 0.6311\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1354 - accuracy: 0.6308 - val_loss: 0.1347 - val_accuracy: 0.6311\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1346 - accuracy: 0.6308 - val_loss: 0.1340 - val_accuracy: 0.6311\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1338 - accuracy: 0.6308 - val_loss: 0.1332 - val_accuracy: 0.6311\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1331 - accuracy: 0.6308 - val_loss: 0.1325 - val_accuracy: 0.6311\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1324 - accuracy: 0.6308 - val_loss: 0.1318 - val_accuracy: 0.6311\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1318 - accuracy: 0.6308 - val_loss: 0.1312 - val_accuracy: 0.6311\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1311 - accuracy: 0.6308 - val_loss: 0.1306 - val_accuracy: 0.6311\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1305 - accuracy: 0.6308 - val_loss: 0.1299 - val_accuracy: 0.6311\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1299 - accuracy: 0.6308 - val_loss: 0.1294 - val_accuracy: 0.6311\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1293 - accuracy: 0.6308 - val_loss: 0.1288 - val_accuracy: 0.6311\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1288 - accuracy: 0.6308 - val_loss: 0.1282 - val_accuracy: 0.6311\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1282 - accuracy: 0.6308 - val_loss: 0.1276 - val_accuracy: 0.6311\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1277 - accuracy: 0.6308 - val_loss: 0.1271 - val_accuracy: 0.6311\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1271 - accuracy: 0.6308 - val_loss: 0.1265 - val_accuracy: 0.6311\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1266 - accuracy: 0.6308 - val_loss: 0.1260 - val_accuracy: 0.6311\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1260 - accuracy: 0.6308 - val_loss: 0.1254 - val_accuracy: 0.6311\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1255 - accuracy: 0.6308 - val_loss: 0.1249 - val_accuracy: 0.6311\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1250 - accuracy: 0.6308 - val_loss: 0.1244 - val_accuracy: 0.6311\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1245 - accuracy: 0.6308 - val_loss: 0.1238 - val_accuracy: 0.6311\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1240 - accuracy: 0.6308 - val_loss: 0.1233 - val_accuracy: 0.6311\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1235 - accuracy: 0.6308 - val_loss: 0.1228 - val_accuracy: 0.6311\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1230 - accuracy: 0.6308 - val_loss: 0.1223 - val_accuracy: 0.6311\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1225 - accuracy: 0.6308 - val_loss: 0.1218 - val_accuracy: 0.6311\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1220 - accuracy: 0.6308 - val_loss: 0.1213 - val_accuracy: 0.6311\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1215 - accuracy: 0.6308 - val_loss: 0.1208 - val_accuracy: 0.6311\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1210 - accuracy: 0.6308 - val_loss: 0.1203 - val_accuracy: 0.6311\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1206 - accuracy: 0.6308 - val_loss: 0.1198 - val_accuracy: 0.6311\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1201 - accuracy: 0.6308 - val_loss: 0.1193 - val_accuracy: 0.6311\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1196 - accuracy: 0.6308 - val_loss: 0.1189 - val_accuracy: 0.6311\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1192 - accuracy: 0.6308 - val_loss: 0.1184 - val_accuracy: 0.6311\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1188 - accuracy: 0.6308 - val_loss: 0.1180 - val_accuracy: 0.6311\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1183 - accuracy: 0.6308 - val_loss: 0.1175 - val_accuracy: 0.6311\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1179 - accuracy: 0.6308 - val_loss: 0.1171 - val_accuracy: 0.6311\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1175 - accuracy: 0.6308 - val_loss: 0.1166 - val_accuracy: 0.6311\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1170 - accuracy: 0.6308 - val_loss: 0.1162 - val_accuracy: 0.6311\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1166 - accuracy: 0.6308 - val_loss: 0.1158 - val_accuracy: 0.6311\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1162 - accuracy: 0.6308 - val_loss: 0.1154 - val_accuracy: 0.6311\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1159 - accuracy: 0.6308 - val_loss: 0.1150 - val_accuracy: 0.6311\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1155 - accuracy: 0.6308 - val_loss: 0.1146 - val_accuracy: 0.6311\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1151 - accuracy: 0.6308 - val_loss: 0.1142 - val_accuracy: 0.6311\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1147 - accuracy: 0.6308 - val_loss: 0.1138 - val_accuracy: 0.6311\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1144 - accuracy: 0.6308 - val_loss: 0.1134 - val_accuracy: 0.6311\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1140 - accuracy: 0.6308 - val_loss: 0.1131 - val_accuracy: 0.6311\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1137 - accuracy: 0.6308 - val_loss: 0.1127 - val_accuracy: 0.6311\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1133 - accuracy: 0.6308 - val_loss: 0.1124 - val_accuracy: 0.6311\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1130 - accuracy: 0.6308 - val_loss: 0.1120 - val_accuracy: 0.6311\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1126 - accuracy: 0.6308 - val_loss: 0.1117 - val_accuracy: 0.6311\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1123 - accuracy: 0.6308 - val_loss: 0.1113 - val_accuracy: 0.6311\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1120 - accuracy: 0.6308 - val_loss: 0.1110 - val_accuracy: 0.6311\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1117 - accuracy: 0.6308 - val_loss: 0.1107 - val_accuracy: 0.6311\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1114 - accuracy: 0.6308 - val_loss: 0.1104 - val_accuracy: 0.6311\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1111 - accuracy: 0.6308 - val_loss: 0.1101 - val_accuracy: 0.6311\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1108 - accuracy: 0.6308 - val_loss: 0.1097 - val_accuracy: 0.6301\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1105 - accuracy: 0.6286 - val_loss: 0.1094 - val_accuracy: 0.6301\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1102 - accuracy: 0.6281 - val_loss: 0.1091 - val_accuracy: 0.6291\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1099 - accuracy: 0.6278 - val_loss: 0.1088 - val_accuracy: 0.6380\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1096 - accuracy: 0.6348 - val_loss: 0.1086 - val_accuracy: 0.6390\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1094 - accuracy: 0.6358 - val_loss: 0.1083 - val_accuracy: 0.6390\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1091 - accuracy: 0.6360 - val_loss: 0.1080 - val_accuracy: 0.6390\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1088 - accuracy: 0.6360 - val_loss: 0.1077 - val_accuracy: 0.6390\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1085 - accuracy: 0.6363 - val_loss: 0.1074 - val_accuracy: 0.6390\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1083 - accuracy: 0.6363 - val_loss: 0.1072 - val_accuracy: 0.6390\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1080 - accuracy: 0.6363 - val_loss: 0.1069 - val_accuracy: 0.6390\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1078 - accuracy: 0.6363 - val_loss: 0.1066 - val_accuracy: 0.6390\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1075 - accuracy: 0.6365 - val_loss: 0.1064 - val_accuracy: 0.6390\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1073 - accuracy: 0.6365 - val_loss: 0.1061 - val_accuracy: 0.6400\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1070 - accuracy: 0.6370 - val_loss: 0.1058 - val_accuracy: 0.6400\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1068 - accuracy: 0.6486 - val_loss: 0.1056 - val_accuracy: 0.6894\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1065 - accuracy: 0.6810 - val_loss: 0.1053 - val_accuracy: 0.6954\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1063 - accuracy: 0.6847 - val_loss: 0.1051 - val_accuracy: 0.6954\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1060 - accuracy: 0.6847 - val_loss: 0.1048 - val_accuracy: 0.6954\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1058 - accuracy: 0.6847 - val_loss: 0.1046 - val_accuracy: 0.6954\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1055 - accuracy: 0.6847 - val_loss: 0.1043 - val_accuracy: 0.6963\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1053 - accuracy: 0.6847 - val_loss: 0.1041 - val_accuracy: 0.6963\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1051 - accuracy: 0.6899 - val_loss: 0.1038 - val_accuracy: 0.7122\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1048 - accuracy: 0.6981 - val_loss: 0.1036 - val_accuracy: 0.7122\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1046 - accuracy: 0.7003 - val_loss: 0.1033 - val_accuracy: 0.7161\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1044 - accuracy: 0.7010 - val_loss: 0.1031 - val_accuracy: 0.7171\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1041 - accuracy: 0.7062 - val_loss: 0.1028 - val_accuracy: 0.7319\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1039 - accuracy: 0.7268 - val_loss: 0.1026 - val_accuracy: 0.7488\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1037 - accuracy: 0.7359 - val_loss: 0.1023 - val_accuracy: 0.7507\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1034 - accuracy: 0.7369 - val_loss: 0.1021 - val_accuracy: 0.7507\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1032 - accuracy: 0.7381 - val_loss: 0.1019 - val_accuracy: 0.7517\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1030 - accuracy: 0.7399 - val_loss: 0.1016 - val_accuracy: 0.7537\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1027 - accuracy: 0.7411 - val_loss: 0.1014 - val_accuracy: 0.7547\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1025 - accuracy: 0.7413 - val_loss: 0.1012 - val_accuracy: 0.7547\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1023 - accuracy: 0.7418 - val_loss: 0.1009 - val_accuracy: 0.7547\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1021 - accuracy: 0.7426 - val_loss: 0.1007 - val_accuracy: 0.7547\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1018 - accuracy: 0.7436 - val_loss: 0.1004 - val_accuracy: 0.7567\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1016 - accuracy: 0.7441 - val_loss: 0.1002 - val_accuracy: 0.7567\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1014 - accuracy: 0.7443 - val_loss: 0.1000 - val_accuracy: 0.7567\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1012 - accuracy: 0.7448 - val_loss: 0.0997 - val_accuracy: 0.7567\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1009 - accuracy: 0.7451 - val_loss: 0.0995 - val_accuracy: 0.7567\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1007 - accuracy: 0.7451 - val_loss: 0.0993 - val_accuracy: 0.7567\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1005 - accuracy: 0.7458 - val_loss: 0.0990 - val_accuracy: 0.7577\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1002 - accuracy: 0.7460 - val_loss: 0.0988 - val_accuracy: 0.7577\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1000 - accuracy: 0.7463 - val_loss: 0.0986 - val_accuracy: 0.7587\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0998 - accuracy: 0.7470 - val_loss: 0.0983 - val_accuracy: 0.7616\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0996 - accuracy: 0.7470 - val_loss: 0.0981 - val_accuracy: 0.7616\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0994 - accuracy: 0.7470 - val_loss: 0.0979 - val_accuracy: 0.7626\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0991 - accuracy: 0.7470 - val_loss: 0.0976 - val_accuracy: 0.7626\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0989 - accuracy: 0.7470 - val_loss: 0.0974 - val_accuracy: 0.7626\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0987 - accuracy: 0.7470 - val_loss: 0.0972 - val_accuracy: 0.7626\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0985 - accuracy: 0.7470 - val_loss: 0.0969 - val_accuracy: 0.7626\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0982 - accuracy: 0.7473 - val_loss: 0.0967 - val_accuracy: 0.7626\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0980 - accuracy: 0.7480 - val_loss: 0.0965 - val_accuracy: 0.7636\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0978 - accuracy: 0.7485 - val_loss: 0.0963 - val_accuracy: 0.7656\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0976 - accuracy: 0.7493 - val_loss: 0.0960 - val_accuracy: 0.7636\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0974 - accuracy: 0.7512 - val_loss: 0.0958 - val_accuracy: 0.7666\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0971 - accuracy: 0.7532 - val_loss: 0.0956 - val_accuracy: 0.7695\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0969 - accuracy: 0.7547 - val_loss: 0.0954 - val_accuracy: 0.7685\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.7559 - val_loss: 0.0951 - val_accuracy: 0.7685\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0965 - accuracy: 0.7567 - val_loss: 0.0949 - val_accuracy: 0.7705\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0963 - accuracy: 0.7577 - val_loss: 0.0947 - val_accuracy: 0.7705\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0961 - accuracy: 0.7589 - val_loss: 0.0945 - val_accuracy: 0.7705\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0959 - accuracy: 0.7596 - val_loss: 0.0943 - val_accuracy: 0.7725\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0957 - accuracy: 0.7599 - val_loss: 0.0940 - val_accuracy: 0.7735\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0954 - accuracy: 0.7599 - val_loss: 0.0938 - val_accuracy: 0.7745\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0952 - accuracy: 0.7599 - val_loss: 0.0936 - val_accuracy: 0.7745\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0950 - accuracy: 0.7604 - val_loss: 0.0934 - val_accuracy: 0.7745\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0948 - accuracy: 0.7587 - val_loss: 0.0932 - val_accuracy: 0.7715\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0946 - accuracy: 0.7591 - val_loss: 0.0930 - val_accuracy: 0.7705\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0944 - accuracy: 0.7584 - val_loss: 0.0928 - val_accuracy: 0.7715\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0942 - accuracy: 0.7619 - val_loss: 0.0926 - val_accuracy: 0.7774\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0940 - accuracy: 0.7601 - val_loss: 0.0924 - val_accuracy: 0.7715\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0938 - accuracy: 0.7599 - val_loss: 0.0922 - val_accuracy: 0.7705\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0936 - accuracy: 0.7604 - val_loss: 0.0920 - val_accuracy: 0.7705\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0934 - accuracy: 0.7604 - val_loss: 0.0918 - val_accuracy: 0.7705\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0932 - accuracy: 0.7606 - val_loss: 0.0916 - val_accuracy: 0.7705\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0930 - accuracy: 0.7611 - val_loss: 0.0914 - val_accuracy: 0.7725\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0928 - accuracy: 0.7619 - val_loss: 0.0912 - val_accuracy: 0.7725\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0927 - accuracy: 0.7621 - val_loss: 0.0910 - val_accuracy: 0.7725\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0925 - accuracy: 0.7621 - val_loss: 0.0908 - val_accuracy: 0.7725\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0923 - accuracy: 0.7621 - val_loss: 0.0906 - val_accuracy: 0.7725\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0921 - accuracy: 0.7621 - val_loss: 0.0904 - val_accuracy: 0.7725\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0919 - accuracy: 0.7621 - val_loss: 0.0902 - val_accuracy: 0.7725\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0917 - accuracy: 0.7621 - val_loss: 0.0901 - val_accuracy: 0.7725\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0916 - accuracy: 0.7619 - val_loss: 0.0899 - val_accuracy: 0.7725\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0914 - accuracy: 0.7619 - val_loss: 0.0897 - val_accuracy: 0.7725\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0912 - accuracy: 0.7619 - val_loss: 0.0895 - val_accuracy: 0.7725\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0911 - accuracy: 0.7619 - val_loss: 0.0894 - val_accuracy: 0.7725\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0909 - accuracy: 0.7619 - val_loss: 0.0892 - val_accuracy: 0.7725\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0907 - accuracy: 0.7619 - val_loss: 0.0890 - val_accuracy: 0.7725\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0906 - accuracy: 0.7619 - val_loss: 0.0889 - val_accuracy: 0.7725\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0904 - accuracy: 0.7616 - val_loss: 0.0887 - val_accuracy: 0.7725\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0902 - accuracy: 0.7616 - val_loss: 0.0885 - val_accuracy: 0.7725\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0901 - accuracy: 0.7616 - val_loss: 0.0884 - val_accuracy: 0.7725\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0899 - accuracy: 0.7616 - val_loss: 0.0882 - val_accuracy: 0.7725\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0898 - accuracy: 0.7616 - val_loss: 0.0881 - val_accuracy: 0.7725\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0896 - accuracy: 0.7616 - val_loss: 0.0879 - val_accuracy: 0.7725\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0895 - accuracy: 0.7616 - val_loss: 0.0878 - val_accuracy: 0.7725\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0893 - accuracy: 0.7616 - val_loss: 0.0876 - val_accuracy: 0.7725\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0892 - accuracy: 0.7616 - val_loss: 0.0875 - val_accuracy: 0.7725\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0890 - accuracy: 0.7619 - val_loss: 0.0873 - val_accuracy: 0.7725\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0889 - accuracy: 0.7616 - val_loss: 0.0872 - val_accuracy: 0.7725\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0887 - accuracy: 0.7616 - val_loss: 0.0870 - val_accuracy: 0.7725\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0886 - accuracy: 0.7614 - val_loss: 0.0869 - val_accuracy: 0.7725\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0885 - accuracy: 0.7616 - val_loss: 0.0868 - val_accuracy: 0.7725\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0883 - accuracy: 0.7616 - val_loss: 0.0866 - val_accuracy: 0.7735\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0882 - accuracy: 0.7698 - val_loss: 0.0865 - val_accuracy: 0.7864\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0881 - accuracy: 0.7807 - val_loss: 0.0864 - val_accuracy: 0.7854\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0880 - accuracy: 0.7767 - val_loss: 0.0863 - val_accuracy: 0.7794\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0878 - accuracy: 0.7750 - val_loss: 0.0861 - val_accuracy: 0.7834\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0877 - accuracy: 0.7750 - val_loss: 0.0860 - val_accuracy: 0.7755\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.0876 - accuracy: 0.7723 - val_loss: 0.0859 - val_accuracy: 0.7745\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0875 - accuracy: 0.7723 - val_loss: 0.0857 - val_accuracy: 0.7755\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0873 - accuracy: 0.7732 - val_loss: 0.0856 - val_accuracy: 0.7765\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0872 - accuracy: 0.7735 - val_loss: 0.0855 - val_accuracy: 0.7765\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0871 - accuracy: 0.7735 - val_loss: 0.0854 - val_accuracy: 0.7765\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0870 - accuracy: 0.7737 - val_loss: 0.0853 - val_accuracy: 0.7765\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0869 - accuracy: 0.7737 - val_loss: 0.0852 - val_accuracy: 0.7765\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0868 - accuracy: 0.7735 - val_loss: 0.0851 - val_accuracy: 0.7765\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.7735 - val_loss: 0.0850 - val_accuracy: 0.7765\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0866 - accuracy: 0.7732 - val_loss: 0.0849 - val_accuracy: 0.7755\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0865 - accuracy: 0.7732 - val_loss: 0.0848 - val_accuracy: 0.7755\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0864 - accuracy: 0.7727 - val_loss: 0.0847 - val_accuracy: 0.7755\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0863 - accuracy: 0.7755 - val_loss: 0.0846 - val_accuracy: 0.7814\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0862 - accuracy: 0.7762 - val_loss: 0.0845 - val_accuracy: 0.7794\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0861 - accuracy: 0.7760 - val_loss: 0.0844 - val_accuracy: 0.7794\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0860 - accuracy: 0.7760 - val_loss: 0.0843 - val_accuracy: 0.7794\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0859 - accuracy: 0.7777 - val_loss: 0.0842 - val_accuracy: 0.7784\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0858 - accuracy: 0.7782 - val_loss: 0.0841 - val_accuracy: 0.7804\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0857 - accuracy: 0.7784 - val_loss: 0.0840 - val_accuracy: 0.7804\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5JOM7eZNbGL",
        "outputId": "2504f15c-3bb1-452b-8e90-ae8b3ce271fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.7505\n",
            "Test results - Loss: 0.10467243194580078 - Accuracy: 75.0544011592865%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy4_1 = test_results[1]\n",
        "y_pred4_1 = np.argmax(ae_classifier.predict(X_test),axis=1)\n",
        "y_test4 = np.argmax(y_test,axis=1)"
      ],
      "metadata": {
        "id": "K5faBHPvRtyS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78be05ec-7ed6-42f6-f3d6-4822d4258b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "_mflRCsKN9rm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "y_test = [*y_test1,*y_test2,*y_test3,*y_test4]\n",
        "y_pred1 = [*y_pred1_1,*y_pred2_1,*y_pred3_1,*y_pred4_1]\n",
        "accuracy = (test_count1*accuracy1_1 + test_count2*accuracy2_1 + test_count3*accuracy3_1 + test_count4*accuracy4_1)/(test_count1 + test_count2 + test_count3 + test_count4)\n",
        "presion = precision_score(y_test,y_pred1,average='weighted')\n",
        "recall = recall_score(y_test,y_pred1,average='weighted')"
      ],
      "metadata": {
        "id": "pnuhqnc_POVI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {}\\t Precision:{}\\t Recall: {}\".format(accuracy,presion,recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Eqko8rnP82i",
        "outputId": "96096916-4583-4c25-ada3-0e033d05bdd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8240458902164398\t Precision:0.8055117897705284\t Recall: 0.8240458826028464\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "9-ozWSaLUGjn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 1"
      ],
      "metadata": {
        "id": "QLscoX4KUMVr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train1.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test1.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count1 = len(test.index)"
      ],
      "metadata": {
        "id": "O5fVJONEUV3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "X_test = test.iloc[:,0:89]\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "y_train = y_train.values\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "# y_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "\n",
        "\n",
        "# X_test = X_test.to_numpy()\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "Go-T7u15hHqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = Sequential()\n",
        "\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "\n",
        "lst.add(Dense(4,activation='softmax'))\n",
        "\n",
        "lst.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "lst.summary()\n",
        "history = lst.fit(X_train, y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfDowLaghHmn",
        "outputId": "9fd782c2-b7cd-47ab-ce93-21a22b9ba828"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_4 (LSTM)               (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_40 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,204\n",
            "Trainable params: 28,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "4/4 [==============================] - 4s 295ms/step - loss: 0.1709 - accuracy: 0.9708 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1579 - val_accuracy: 0.9747 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.1534 - accuracy: 0.9767 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1401 - val_accuracy: 0.9744 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.1354 - accuracy: 0.9766 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1219 - val_accuracy: 0.9744 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.1171 - accuracy: 0.9766 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1036 - val_accuracy: 0.9744 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.0987 - accuracy: 0.9766 - precision: 1.0000 - recall: 0.0037 - val_loss: 0.0855 - val_accuracy: 0.9744 - val_precision: 1.0000 - val_recall: 0.6327\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 68ms/step - loss: 0.0808 - accuracy: 0.9766 - precision: 0.9999 - recall: 0.7890 - val_loss: 0.0686 - val_accuracy: 0.9744 - val_precision: 0.9843 - val_recall: 0.9526\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.0642 - accuracy: 0.9766 - precision: 0.9863 - recall: 0.9611 - val_loss: 0.0536 - val_accuracy: 0.9744 - val_precision: 0.9792 - val_recall: 0.9675\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 76ms/step - loss: 0.0497 - accuracy: 0.9766 - precision: 0.9807 - recall: 0.9709 - val_loss: 0.0411 - val_accuracy: 0.9744 - val_precision: 0.9778 - val_recall: 0.9725\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0379 - accuracy: 0.9766 - precision: 0.9793 - recall: 0.9744 - val_loss: 0.0315 - val_accuracy: 0.9744 - val_precision: 0.9762 - val_recall: 0.9744\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0290 - accuracy: 0.9766 - precision: 0.9786 - recall: 0.9762 - val_loss: 0.0247 - val_accuracy: 0.9744 - val_precision: 0.9757 - val_recall: 0.9744\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0228 - accuracy: 0.9766 - precision: 0.9782 - recall: 0.9765 - val_loss: 0.0202 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.0186 - accuracy: 0.9766 - precision: 0.9775 - recall: 0.9766 - val_loss: 0.0172 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0159 - accuracy: 0.9766 - precision: 0.9773 - recall: 0.9766 - val_loss: 0.0153 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0141 - accuracy: 0.9766 - precision: 0.9773 - recall: 0.9766 - val_loss: 0.0141 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0130 - accuracy: 0.9766 - precision: 0.9769 - recall: 0.9766 - val_loss: 0.0133 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0122 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0127 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0117 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0124 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0114 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0121 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0112 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0119 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0110 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0118 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0108 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0117 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0107 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0116 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0106 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0115 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.0106 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0114 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0105 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0114 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0104 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0113 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0104 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0113 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0103 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0112 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0103 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0112 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0102 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0111 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0102 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0111 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0102 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0111 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0101 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0110 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0101 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0110 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0101 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0110 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0100 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0109 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0100 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0109 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0100 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0109 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0099 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0109 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0099 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0108 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0099 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0108 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0099 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0108 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0098 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0108 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0098 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0107 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0098 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0107 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0097 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0107 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0097 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0106 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0097 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0106 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0096 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0105 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0096 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0105 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0095 - accuracy: 0.9766 - precision: 0.9767 - recall: 0.9766 - val_loss: 0.0104 - val_accuracy: 0.9744 - val_precision: 0.9744 - val_recall: 0.9744\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0095 - accuracy: 0.9766 - precision: 0.9768 - recall: 0.9766 - val_loss: 0.0103 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0094 - accuracy: 0.9766 - precision: 0.9768 - recall: 0.9766 - val_loss: 0.0102 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0093 - accuracy: 0.9766 - precision: 0.9769 - recall: 0.9766 - val_loss: 0.0102 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0093 - accuracy: 0.9766 - precision: 0.9770 - recall: 0.9766 - val_loss: 0.0101 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0092 - accuracy: 0.9766 - precision: 0.9770 - recall: 0.9766 - val_loss: 0.0100 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0092 - accuracy: 0.9766 - precision: 0.9772 - recall: 0.9766 - val_loss: 0.0099 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0091 - accuracy: 0.9766 - precision: 0.9773 - recall: 0.9766 - val_loss: 0.0099 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0090 - accuracy: 0.9766 - precision: 0.9774 - recall: 0.9766 - val_loss: 0.0098 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0090 - accuracy: 0.9766 - precision: 0.9775 - recall: 0.9766 - val_loss: 0.0097 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0089 - accuracy: 0.9766 - precision: 0.9775 - recall: 0.9766 - val_loss: 0.0097 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0088 - accuracy: 0.9766 - precision: 0.9776 - recall: 0.9766 - val_loss: 0.0096 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0088 - accuracy: 0.9766 - precision: 0.9776 - recall: 0.9766 - val_loss: 0.0095 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0087 - accuracy: 0.9766 - precision: 0.9777 - recall: 0.9766 - val_loss: 0.0094 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 52ms/step - loss: 0.0086 - accuracy: 0.9766 - precision: 0.9777 - recall: 0.9766 - val_loss: 0.0093 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0085 - accuracy: 0.9766 - precision: 0.9777 - recall: 0.9766 - val_loss: 0.0091 - val_accuracy: 0.9744 - val_precision: 0.9747 - val_recall: 0.9744\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0083 - accuracy: 0.9767 - precision: 0.9777 - recall: 0.9766 - val_loss: 0.0089 - val_accuracy: 0.9744 - val_precision: 0.9749 - val_recall: 0.9744\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0082 - accuracy: 0.9767 - precision: 0.9777 - recall: 0.9766 - val_loss: 0.0087 - val_accuracy: 0.9744 - val_precision: 0.9749 - val_recall: 0.9744\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0081 - accuracy: 0.9767 - precision: 0.9777 - recall: 0.9766 - val_loss: 0.0086 - val_accuracy: 0.9744 - val_precision: 0.9755 - val_recall: 0.9744\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0080 - accuracy: 0.9767 - precision: 0.9779 - recall: 0.9766 - val_loss: 0.0085 - val_accuracy: 0.9744 - val_precision: 0.9755 - val_recall: 0.9744\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0078 - accuracy: 0.9767 - precision: 0.9780 - recall: 0.9766 - val_loss: 0.0083 - val_accuracy: 0.9744 - val_precision: 0.9755 - val_recall: 0.9744\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0077 - accuracy: 0.9767 - precision: 0.9780 - recall: 0.9766 - val_loss: 0.0081 - val_accuracy: 0.9744 - val_precision: 0.9755 - val_recall: 0.9744\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0075 - accuracy: 0.9767 - precision: 0.9782 - recall: 0.9766 - val_loss: 0.0078 - val_accuracy: 0.9744 - val_precision: 0.9757 - val_recall: 0.9744\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0073 - accuracy: 0.9767 - precision: 0.9788 - recall: 0.9766 - val_loss: 0.0076 - val_accuracy: 0.9744 - val_precision: 0.9760 - val_recall: 0.9744\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0071 - accuracy: 0.9767 - precision: 0.9792 - recall: 0.9766 - val_loss: 0.0074 - val_accuracy: 0.9744 - val_precision: 0.9765 - val_recall: 0.9744\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0069 - accuracy: 0.9767 - precision: 0.9797 - recall: 0.9766 - val_loss: 0.0072 - val_accuracy: 0.9744 - val_precision: 0.9773 - val_recall: 0.9744\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 73ms/step - loss: 0.0068 - accuracy: 0.9767 - precision: 0.9804 - recall: 0.9766 - val_loss: 0.0071 - val_accuracy: 0.9744 - val_precision: 0.9786 - val_recall: 0.9744\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0066 - accuracy: 0.9767 - precision: 0.9815 - recall: 0.9766 - val_loss: 0.0069 - val_accuracy: 0.9744 - val_precision: 0.9833 - val_recall: 0.9744\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0065 - accuracy: 0.9767 - precision: 0.9861 - recall: 0.9766 - val_loss: 0.0068 - val_accuracy: 0.9744 - val_precision: 0.9892 - val_recall: 0.9744\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0063 - accuracy: 0.9767 - precision: 0.9893 - recall: 0.9766 - val_loss: 0.0066 - val_accuracy: 0.9744 - val_precision: 0.9894 - val_recall: 0.9744\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0062 - accuracy: 0.9767 - precision: 0.9894 - recall: 0.9766 - val_loss: 0.0065 - val_accuracy: 0.9744 - val_precision: 0.9894 - val_recall: 0.9744\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0061 - accuracy: 0.9768 - precision: 0.9896 - recall: 0.9766 - val_loss: 0.0063 - val_accuracy: 0.9747 - val_precision: 0.9894 - val_recall: 0.9744\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 55ms/step - loss: 0.0059 - accuracy: 0.9771 - precision: 0.9899 - recall: 0.9766 - val_loss: 0.0062 - val_accuracy: 0.9752 - val_precision: 0.9894 - val_recall: 0.9744\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0058 - accuracy: 0.9775 - precision: 0.9903 - recall: 0.9766 - val_loss: 0.0060 - val_accuracy: 0.9765 - val_precision: 0.9900 - val_recall: 0.9744\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0057 - accuracy: 0.9789 - precision: 0.9907 - recall: 0.9766 - val_loss: 0.0059 - val_accuracy: 0.9837 - val_precision: 0.9905 - val_recall: 0.9744\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0055 - accuracy: 0.9869 - precision: 0.9910 - recall: 0.9766 - val_loss: 0.0057 - val_accuracy: 0.9880 - val_precision: 0.9908 - val_recall: 0.9744\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0054 - accuracy: 0.9876 - precision: 0.9915 - recall: 0.9766 - val_loss: 0.0056 - val_accuracy: 0.9880 - val_precision: 0.9913 - val_recall: 0.9744\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0053 - accuracy: 0.9878 - precision: 0.9919 - recall: 0.9767 - val_loss: 0.0055 - val_accuracy: 0.9883 - val_precision: 0.9913 - val_recall: 0.9752\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0052 - accuracy: 0.9882 - precision: 0.9921 - recall: 0.9777 - val_loss: 0.0053 - val_accuracy: 0.9888 - val_precision: 0.9916 - val_recall: 0.9792\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0050 - accuracy: 0.9886 - precision: 0.9923 - recall: 0.9829 - val_loss: 0.0052 - val_accuracy: 0.9888 - val_precision: 0.9920 - val_recall: 0.9880\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0049 - accuracy: 0.9893 - precision: 0.9926 - recall: 0.9872 - val_loss: 0.0050 - val_accuracy: 0.9899 - val_precision: 0.9928 - val_recall: 0.9880\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 63ms/step - loss: 0.0048 - accuracy: 0.9901 - precision: 0.9932 - recall: 0.9875 - val_loss: 0.0049 - val_accuracy: 0.9901 - val_precision: 0.9928 - val_recall: 0.9885\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0046 - accuracy: 0.9905 - precision: 0.9933 - recall: 0.9881 - val_loss: 0.0047 - val_accuracy: 0.9901 - val_precision: 0.9930 - val_recall: 0.9891\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0045 - accuracy: 0.9905 - precision: 0.9930 - recall: 0.9893 - val_loss: 0.0046 - val_accuracy: 0.9907 - val_precision: 0.9936 - val_recall: 0.9899\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 81ms/step - loss: 0.0044 - accuracy: 0.9907 - precision: 0.9932 - recall: 0.9897 - val_loss: 0.0044 - val_accuracy: 0.9907 - val_precision: 0.9936 - val_recall: 0.9901\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0043 - accuracy: 0.9908 - precision: 0.9932 - recall: 0.9901 - val_loss: 0.0043 - val_accuracy: 0.9907 - val_precision: 0.9936 - val_recall: 0.9901\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 70ms/step - loss: 0.0042 - accuracy: 0.9909 - precision: 0.9933 - recall: 0.9901 - val_loss: 0.0042 - val_accuracy: 0.9907 - val_precision: 0.9936 - val_recall: 0.9901\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.0041 - accuracy: 0.9909 - precision: 0.9933 - recall: 0.9901 - val_loss: 0.0041 - val_accuracy: 0.9907 - val_precision: 0.9936 - val_recall: 0.9901\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 88ms/step - loss: 0.0040 - accuracy: 0.9909 - precision: 0.9933 - recall: 0.9901 - val_loss: 0.0040 - val_accuracy: 0.9907 - val_precision: 0.9933 - val_recall: 0.9901\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0039 - accuracy: 0.9909 - precision: 0.9933 - recall: 0.9901 - val_loss: 0.0040 - val_accuracy: 0.9907 - val_precision: 0.9933 - val_recall: 0.9901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = lst.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PRxai1yh9_v",
        "outputId": "a6235184-e831-4b05-9d6c-c58554b9c9c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9675 - precision: 0.9681 - recall: 0.9675\n",
            "Test results - Loss: 0.017672020941972733 - Accuracy: 96.7469871044159%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy1_2 = test_results[1]\n",
        "y_pred1_2 = np.argmax(lst.predict(X_test),axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GGmTSsXKiE4n",
        "outputId": "ca0cacec-259e-42ae-c63d-c12feab60c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 2"
      ],
      "metadata": {
        "id": "jUWbZDEDiWCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train2.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test2.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count3 = len(test.index)"
      ],
      "metadata": {
        "id": "AGDXNL24iWCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "X_test = test.iloc[:,0:89]\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "y_train = y_train.values\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "# y_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "\n",
        "\n",
        "# X_test = X_test.to_numpy()\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "yFnLE0Y0iWCq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = Sequential()\n",
        "\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "\n",
        "lst.add(Dense(4,activation='softmax'))\n",
        "\n",
        "lst.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "lst.summary()\n",
        "history = lst.fit(X_train, y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWF2tDidiWCq",
        "outputId": "af062a00-e0f4-422c-d2e3-cd614e09f7d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_5 (LSTM)               (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_41 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,204\n",
            "Trainable params: 28,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "6/6 [==============================] - 4s 200ms/step - loss: 0.1786 - accuracy: 0.8074 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1674 - val_accuracy: 0.9874 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.1592 - accuracy: 0.9863 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1471 - val_accuracy: 0.9882 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.1383 - accuracy: 0.9865 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1253 - val_accuracy: 0.9882 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.1159 - accuracy: 0.9865 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1020 - val_accuracy: 0.9882 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0925 - accuracy: 0.9865 - precision: 0.9997 - recall: 0.2587 - val_loss: 0.0786 - val_accuracy: 0.9882 - val_precision: 0.9998 - val_recall: 0.8884\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0697 - accuracy: 0.9865 - precision: 0.9959 - recall: 0.9206 - val_loss: 0.0569 - val_accuracy: 0.9882 - val_precision: 0.9886 - val_recall: 0.9653\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0495 - accuracy: 0.9865 - precision: 0.9867 - recall: 0.9717 - val_loss: 0.0392 - val_accuracy: 0.9882 - val_precision: 0.9884 - val_recall: 0.9824\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0340 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9813 - val_loss: 0.0265 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9854\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0234 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9832 - val_loss: 0.0185 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9858\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0168 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9838 - val_loss: 0.0137 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9865\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0131 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9842 - val_loss: 0.0110 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9867\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 87ms/step - loss: 0.0109 - accuracy: 0.9865 - precision: 0.9865 - recall: 0.9848 - val_loss: 0.0094 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9870\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 84ms/step - loss: 0.0096 - accuracy: 0.9865 - precision: 0.9865 - recall: 0.9852 - val_loss: 0.0084 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9871\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 78ms/step - loss: 0.0088 - accuracy: 0.9865 - precision: 0.9865 - recall: 0.9855 - val_loss: 0.0078 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0083 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0074 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0079 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0071 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 76ms/step - loss: 0.0076 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0068 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0074 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0067 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.0073 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0065 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0071 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0064 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9878\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 60ms/step - loss: 0.0070 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0063 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9878\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.0069 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0062 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9878\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.0069 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9861 - val_loss: 0.0061 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9878\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.0068 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9861 - val_loss: 0.0061 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9878\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0067 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9861 - val_loss: 0.0060 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0067 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9861 - val_loss: 0.0059 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.0066 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9861 - val_loss: 0.0059 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0065 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9861 - val_loss: 0.0058 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0065 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0058 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0065 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0058 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0064 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0057 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0064 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0057 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0063 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0056 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0063 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0056 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0063 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0056 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0062 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9860 - val_loss: 0.0056 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0062 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0055 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0062 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0055 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0061 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0055 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0061 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0054 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9877\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0061 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0054 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0060 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0054 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0060 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0054 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0060 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0053 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0059 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0053 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0059 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0053 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0059 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0053 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0059 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9859 - val_loss: 0.0052 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0058 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0052 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0058 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0052 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0058 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0052 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 80ms/step - loss: 0.0057 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0052 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 85ms/step - loss: 0.0057 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0051 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 1s 91ms/step - loss: 0.0057 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0051 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 81ms/step - loss: 0.0056 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0051 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 77ms/step - loss: 0.0056 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0051 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.0056 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0050 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0056 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9858 - val_loss: 0.0050 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0055 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0050 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0055 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0050 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.0055 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0049 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 65ms/step - loss: 0.0054 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0049 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9875\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0054 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0049 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0054 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0049 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 64ms/step - loss: 0.0053 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9857 - val_loss: 0.0049 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.0053 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9856 - val_loss: 0.0048 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0053 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9856 - val_loss: 0.0048 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0053 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9856 - val_loss: 0.0048 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0052 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9856 - val_loss: 0.0048 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0052 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9856 - val_loss: 0.0047 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0052 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9856 - val_loss: 0.0047 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0051 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9856 - val_loss: 0.0047 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0051 - accuracy: 0.9865 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0047 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0051 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0046 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 62ms/step - loss: 0.0050 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0046 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.0050 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0046 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.0050 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0046 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.0049 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0045 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0049 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0045 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.0049 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0045 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0048 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0045 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0048 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0044 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0048 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0044 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 58ms/step - loss: 0.0047 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0044 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0047 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0043 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0047 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0043 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0046 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0043 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0046 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0042 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0046 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0042 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 82ms/step - loss: 0.0045 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0042 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 79ms/step - loss: 0.0045 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0042 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0045 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0041 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 77ms/step - loss: 0.0044 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0041 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 83ms/step - loss: 0.0044 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0041 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 1s 89ms/step - loss: 0.0043 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0040 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 0.0043 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0040 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0043 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9855 - val_loss: 0.0040 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9874\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0042 - accuracy: 0.9864 - precision: 0.9865 - recall: 0.9855 - val_loss: 0.0039 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9873\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.0042 - accuracy: 0.9864 - precision: 0.9866 - recall: 0.9852 - val_loss: 0.0039 - val_accuracy: 0.9879 - val_precision: 0.9890 - val_recall: 0.9871\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.0041 - accuracy: 0.9864 - precision: 0.9869 - recall: 0.9852 - val_loss: 0.0038 - val_accuracy: 0.9879 - val_precision: 0.9893 - val_recall: 0.9870\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = lst.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0ZUqVixiWCr",
        "outputId": "b4b999de-994c-4272-95b8-44a60b374fa3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1081 - accuracy: 0.7739 - precision: 0.7741 - recall: 0.7739\n",
            "Test results - Loss: 0.10811612755060196 - Accuracy: 77.39090919494629%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2_2 = test_results[1]\n",
        "y_pred2_2 = np.argmax(lst.predict(X_test),axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o1dhGAdfiWCr",
        "outputId": "f56b4863-6bd9-4661-d073-33b92a758279"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 3"
      ],
      "metadata": {
        "id": "CPynXPhQic6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train3.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test3.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count3 = len(test.index)"
      ],
      "metadata": {
        "id": "R7Lvbb7fic6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "X_test = test.iloc[:,0:89]\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "y_train = y_train.values\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "# y_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "\n",
        "\n",
        "# X_test = X_test.to_numpy()\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "A8oeg2piic6X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = Sequential()\n",
        "\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "\n",
        "lst.add(Dense(4,activation='softmax'))\n",
        "\n",
        "lst.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "lst.summary()\n",
        "history = lst.fit(X_train, y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFmtxEPQic6Y",
        "outputId": "f1eb6287-6c9a-46b6-c1d3-c4aa2fe53e03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_6 (LSTM)               (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_42 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,204\n",
            "Trainable params: 28,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 3s 437ms/step - loss: 0.1839 - accuracy: 0.2190 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1799 - val_accuracy: 0.6657 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.1779 - accuracy: 0.6953 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1741 - val_accuracy: 0.7131 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.1720 - accuracy: 0.7156 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1683 - val_accuracy: 0.6949 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1661 - accuracy: 0.7031 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1625 - val_accuracy: 0.6875 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1602 - accuracy: 0.7014 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1566 - val_accuracy: 0.6890 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1542 - accuracy: 0.7018 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1506 - val_accuracy: 0.6890 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1480 - accuracy: 0.7019 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1445 - val_accuracy: 0.6893 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1417 - accuracy: 0.7020 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1382 - val_accuracy: 0.6893 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1354 - accuracy: 0.7022 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1319 - val_accuracy: 0.6893 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.1289 - accuracy: 0.7022 - precision: 1.0000 - recall: 0.0027 - val_loss: 0.1255 - val_accuracy: 0.6896 - val_precision: 1.0000 - val_recall: 0.1048\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1223 - accuracy: 0.7023 - precision: 1.0000 - recall: 0.1818 - val_loss: 0.1191 - val_accuracy: 0.6896 - val_precision: 0.9959 - val_recall: 0.2878\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1158 - accuracy: 0.7022 - precision: 0.9955 - recall: 0.3611 - val_loss: 0.1128 - val_accuracy: 0.6896 - val_precision: 0.9881 - val_recall: 0.4728\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1095 - accuracy: 0.7022 - precision: 0.9820 - recall: 0.4966 - val_loss: 0.1067 - val_accuracy: 0.6899 - val_precision: 0.9737 - val_recall: 0.5200\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1034 - accuracy: 0.7038 - precision: 0.9675 - recall: 0.5414 - val_loss: 0.1008 - val_accuracy: 0.7039 - val_precision: 0.9445 - val_recall: 0.5534\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0975 - accuracy: 0.7181 - precision: 0.9415 - recall: 0.5807 - val_loss: 0.0953 - val_accuracy: 0.7299 - val_precision: 0.9245 - val_recall: 0.5994\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0920 - accuracy: 0.7405 - precision: 0.9309 - recall: 0.6272 - val_loss: 0.0900 - val_accuracy: 0.7618 - val_precision: 0.9210 - val_recall: 0.6337\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0868 - accuracy: 0.7689 - precision: 0.9279 - recall: 0.6492 - val_loss: 0.0851 - val_accuracy: 0.8030 - val_precision: 0.9213 - val_recall: 0.6427\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0819 - accuracy: 0.8064 - precision: 0.9278 - recall: 0.6608 - val_loss: 0.0804 - val_accuracy: 0.8397 - val_precision: 0.9221 - val_recall: 0.6504\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0773 - accuracy: 0.8386 - precision: 0.9284 - recall: 0.6674 - val_loss: 0.0759 - val_accuracy: 0.8588 - val_precision: 0.9227 - val_recall: 0.6558\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0729 - accuracy: 0.8638 - precision: 0.9285 - recall: 0.6702 - val_loss: 0.0715 - val_accuracy: 0.8803 - val_precision: 0.9230 - val_recall: 0.6582\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0686 - accuracy: 0.8871 - precision: 0.9287 - recall: 0.6716 - val_loss: 0.0674 - val_accuracy: 0.8955 - val_precision: 0.9231 - val_recall: 0.6594\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0646 - accuracy: 0.9027 - precision: 0.9302 - recall: 0.6955 - val_loss: 0.0634 - val_accuracy: 0.9048 - val_precision: 0.9322 - val_recall: 0.7675\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0608 - accuracy: 0.9118 - precision: 0.9359 - recall: 0.7849 - val_loss: 0.0597 - val_accuracy: 0.9113 - val_precision: 0.9331 - val_recall: 0.8322\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 0.0573 - accuracy: 0.9218 - precision: 0.9339 - recall: 0.8459 - val_loss: 0.0564 - val_accuracy: 0.9212 - val_precision: 0.9304 - val_recall: 0.8654\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 0.0540 - accuracy: 0.9270 - precision: 0.9333 - recall: 0.8767 - val_loss: 0.0533 - val_accuracy: 0.9206 - val_precision: 0.9305 - val_recall: 0.8833\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.0512 - accuracy: 0.9266 - precision: 0.9322 - recall: 0.8941 - val_loss: 0.0507 - val_accuracy: 0.9188 - val_precision: 0.9276 - val_recall: 0.8991\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.0486 - accuracy: 0.9249 - precision: 0.9303 - recall: 0.9059 - val_loss: 0.0483 - val_accuracy: 0.9176 - val_precision: 0.9271 - val_recall: 0.9107\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 0.0464 - accuracy: 0.9245 - precision: 0.9308 - recall: 0.9156 - val_loss: 0.0462 - val_accuracy: 0.9170 - val_precision: 0.9268 - val_recall: 0.9113\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.0444 - accuracy: 0.9242 - precision: 0.9307 - recall: 0.9163 - val_loss: 0.0444 - val_accuracy: 0.9170 - val_precision: 0.9269 - val_recall: 0.9116\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 126ms/step - loss: 0.0426 - accuracy: 0.9239 - precision: 0.9304 - recall: 0.9171 - val_loss: 0.0428 - val_accuracy: 0.9167 - val_precision: 0.9269 - val_recall: 0.9125\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 89ms/step - loss: 0.0411 - accuracy: 0.9238 - precision: 0.9302 - recall: 0.9177 - val_loss: 0.0414 - val_accuracy: 0.9167 - val_precision: 0.9270 - val_recall: 0.9131\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 0.0397 - accuracy: 0.9239 - precision: 0.9299 - recall: 0.9183 - val_loss: 0.0402 - val_accuracy: 0.9170 - val_precision: 0.9270 - val_recall: 0.9134\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 109ms/step - loss: 0.0385 - accuracy: 0.9239 - precision: 0.9297 - recall: 0.9189 - val_loss: 0.0391 - val_accuracy: 0.9170 - val_precision: 0.9270 - val_recall: 0.9134\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.0375 - accuracy: 0.9242 - precision: 0.9297 - recall: 0.9192 - val_loss: 0.0381 - val_accuracy: 0.9173 - val_precision: 0.9270 - val_recall: 0.9140\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0366 - accuracy: 0.9243 - precision: 0.9298 - recall: 0.9199 - val_loss: 0.0373 - val_accuracy: 0.9176 - val_precision: 0.9271 - val_recall: 0.9146\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0358 - accuracy: 0.9245 - precision: 0.9298 - recall: 0.9200 - val_loss: 0.0366 - val_accuracy: 0.9176 - val_precision: 0.9271 - val_recall: 0.9146\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0351 - accuracy: 0.9248 - precision: 0.9298 - recall: 0.9203 - val_loss: 0.0360 - val_accuracy: 0.9179 - val_precision: 0.9271 - val_recall: 0.9149\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0344 - accuracy: 0.9250 - precision: 0.9298 - recall: 0.9204 - val_loss: 0.0354 - val_accuracy: 0.9182 - val_precision: 0.9271 - val_recall: 0.9149\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0339 - accuracy: 0.9251 - precision: 0.9298 - recall: 0.9207 - val_loss: 0.0349 - val_accuracy: 0.9188 - val_precision: 0.9271 - val_recall: 0.9152\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0334 - accuracy: 0.9252 - precision: 0.9298 - recall: 0.9209 - val_loss: 0.0344 - val_accuracy: 0.9188 - val_precision: 0.9271 - val_recall: 0.9152\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.0329 - accuracy: 0.9254 - precision: 0.9299 - recall: 0.9212 - val_loss: 0.0340 - val_accuracy: 0.9191 - val_precision: 0.9271 - val_recall: 0.9152\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0325 - accuracy: 0.9254 - precision: 0.9299 - recall: 0.9215 - val_loss: 0.0336 - val_accuracy: 0.9197 - val_precision: 0.9271 - val_recall: 0.9152\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 67ms/step - loss: 0.0321 - accuracy: 0.9256 - precision: 0.9299 - recall: 0.9215 - val_loss: 0.0332 - val_accuracy: 0.9200 - val_precision: 0.9271 - val_recall: 0.9152\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0317 - accuracy: 0.9257 - precision: 0.9299 - recall: 0.9218 - val_loss: 0.0329 - val_accuracy: 0.9203 - val_precision: 0.9271 - val_recall: 0.9152\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0314 - accuracy: 0.9260 - precision: 0.9299 - recall: 0.9219 - val_loss: 0.0325 - val_accuracy: 0.9206 - val_precision: 0.9271 - val_recall: 0.9149\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0311 - accuracy: 0.9263 - precision: 0.9300 - recall: 0.9221 - val_loss: 0.0322 - val_accuracy: 0.9212 - val_precision: 0.9271 - val_recall: 0.9149\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.0308 - accuracy: 0.9265 - precision: 0.9301 - recall: 0.9224 - val_loss: 0.0320 - val_accuracy: 0.9215 - val_precision: 0.9271 - val_recall: 0.9152\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0305 - accuracy: 0.9266 - precision: 0.9301 - recall: 0.9224 - val_loss: 0.0317 - val_accuracy: 0.9218 - val_precision: 0.9271 - val_recall: 0.9155\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.0303 - accuracy: 0.9271 - precision: 0.9303 - recall: 0.9227 - val_loss: 0.0314 - val_accuracy: 0.9221 - val_precision: 0.9272 - val_recall: 0.9158\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0300 - accuracy: 0.9275 - precision: 0.9304 - recall: 0.9229 - val_loss: 0.0312 - val_accuracy: 0.9221 - val_precision: 0.9272 - val_recall: 0.9161\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0298 - accuracy: 0.9276 - precision: 0.9304 - recall: 0.9230 - val_loss: 0.0309 - val_accuracy: 0.9221 - val_precision: 0.9272 - val_recall: 0.9161\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0296 - accuracy: 0.9276 - precision: 0.9304 - recall: 0.9234 - val_loss: 0.0307 - val_accuracy: 0.9221 - val_precision: 0.9272 - val_recall: 0.9164\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0293 - accuracy: 0.9277 - precision: 0.9304 - recall: 0.9236 - val_loss: 0.0305 - val_accuracy: 0.9221 - val_precision: 0.9275 - val_recall: 0.9170\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0291 - accuracy: 0.9277 - precision: 0.9305 - recall: 0.9237 - val_loss: 0.0303 - val_accuracy: 0.9221 - val_precision: 0.9276 - val_recall: 0.9176\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0289 - accuracy: 0.9277 - precision: 0.9305 - recall: 0.9238 - val_loss: 0.0301 - val_accuracy: 0.9221 - val_precision: 0.9276 - val_recall: 0.9176\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 68ms/step - loss: 0.0287 - accuracy: 0.9277 - precision: 0.9305 - recall: 0.9237 - val_loss: 0.0298 - val_accuracy: 0.9224 - val_precision: 0.9276 - val_recall: 0.9179\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0285 - accuracy: 0.9279 - precision: 0.9306 - recall: 0.9239 - val_loss: 0.0296 - val_accuracy: 0.9227 - val_precision: 0.9279 - val_recall: 0.9176\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.0283 - accuracy: 0.9279 - precision: 0.9307 - recall: 0.9238 - val_loss: 0.0294 - val_accuracy: 0.9227 - val_precision: 0.9279 - val_recall: 0.9179\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0281 - accuracy: 0.9280 - precision: 0.9307 - recall: 0.9237 - val_loss: 0.0292 - val_accuracy: 0.9230 - val_precision: 0.9279 - val_recall: 0.9182\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0279 - accuracy: 0.9280 - precision: 0.9307 - recall: 0.9234 - val_loss: 0.0290 - val_accuracy: 0.9230 - val_precision: 0.9279 - val_recall: 0.9182\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 64ms/step - loss: 0.0277 - accuracy: 0.9280 - precision: 0.9307 - recall: 0.9232 - val_loss: 0.0289 - val_accuracy: 0.9230 - val_precision: 0.9276 - val_recall: 0.9179\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0276 - accuracy: 0.9280 - precision: 0.9307 - recall: 0.9230 - val_loss: 0.0287 - val_accuracy: 0.9233 - val_precision: 0.9276 - val_recall: 0.9176\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0274 - accuracy: 0.9281 - precision: 0.9307 - recall: 0.9230 - val_loss: 0.0285 - val_accuracy: 0.9236 - val_precision: 0.9276 - val_recall: 0.9173\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0272 - accuracy: 0.9282 - precision: 0.9308 - recall: 0.9228 - val_loss: 0.0283 - val_accuracy: 0.9236 - val_precision: 0.9278 - val_recall: 0.9173\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0270 - accuracy: 0.9286 - precision: 0.9312 - recall: 0.9228 - val_loss: 0.0281 - val_accuracy: 0.9236 - val_precision: 0.9278 - val_recall: 0.9173\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0269 - accuracy: 0.9287 - precision: 0.9314 - recall: 0.9225 - val_loss: 0.0279 - val_accuracy: 0.9245 - val_precision: 0.9292 - val_recall: 0.9170\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0267 - accuracy: 0.9293 - precision: 0.9327 - recall: 0.9224 - val_loss: 0.0278 - val_accuracy: 0.9263 - val_precision: 0.9309 - val_recall: 0.9170\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0265 - accuracy: 0.9292 - precision: 0.9358 - recall: 0.9220 - val_loss: 0.0276 - val_accuracy: 0.9263 - val_precision: 0.9323 - val_recall: 0.9164\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0264 - accuracy: 0.9296 - precision: 0.9387 - recall: 0.9210 - val_loss: 0.0274 - val_accuracy: 0.9266 - val_precision: 0.9362 - val_recall: 0.9149\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0262 - accuracy: 0.9299 - precision: 0.9419 - recall: 0.9201 - val_loss: 0.0273 - val_accuracy: 0.9266 - val_precision: 0.9378 - val_recall: 0.9143\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0261 - accuracy: 0.9303 - precision: 0.9436 - recall: 0.9198 - val_loss: 0.0271 - val_accuracy: 0.9266 - val_precision: 0.9387 - val_recall: 0.9143\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0259 - accuracy: 0.9303 - precision: 0.9447 - recall: 0.9195 - val_loss: 0.0269 - val_accuracy: 0.9266 - val_precision: 0.9396 - val_recall: 0.9140\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0257 - accuracy: 0.9303 - precision: 0.9457 - recall: 0.9195 - val_loss: 0.0268 - val_accuracy: 0.9266 - val_precision: 0.9407 - val_recall: 0.9137\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0256 - accuracy: 0.9303 - precision: 0.9470 - recall: 0.9190 - val_loss: 0.0266 - val_accuracy: 0.9266 - val_precision: 0.9421 - val_recall: 0.9137\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.0254 - accuracy: 0.9303 - precision: 0.9486 - recall: 0.9189 - val_loss: 0.0265 - val_accuracy: 0.9266 - val_precision: 0.9459 - val_recall: 0.9137\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0253 - accuracy: 0.9303 - precision: 0.9509 - recall: 0.9189 - val_loss: 0.0263 - val_accuracy: 0.9269 - val_precision: 0.9491 - val_recall: 0.9137\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0251 - accuracy: 0.9303 - precision: 0.9516 - recall: 0.9189 - val_loss: 0.0261 - val_accuracy: 0.9269 - val_precision: 0.9492 - val_recall: 0.9140\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0250 - accuracy: 0.9303 - precision: 0.9521 - recall: 0.9194 - val_loss: 0.0260 - val_accuracy: 0.9269 - val_precision: 0.9494 - val_recall: 0.9137\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0249 - accuracy: 0.9304 - precision: 0.9527 - recall: 0.9194 - val_loss: 0.0259 - val_accuracy: 0.9278 - val_precision: 0.9512 - val_recall: 0.9137\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0247 - accuracy: 0.9307 - precision: 0.9556 - recall: 0.9194 - val_loss: 0.0257 - val_accuracy: 0.9281 - val_precision: 0.9530 - val_recall: 0.9134\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0246 - accuracy: 0.9313 - precision: 0.9562 - recall: 0.9195 - val_loss: 0.0256 - val_accuracy: 0.9284 - val_precision: 0.9530 - val_recall: 0.9134\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.0244 - accuracy: 0.9321 - precision: 0.9567 - recall: 0.9195 - val_loss: 0.0254 - val_accuracy: 0.9287 - val_precision: 0.9533 - val_recall: 0.9134\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.0243 - accuracy: 0.9326 - precision: 0.9569 - recall: 0.9196 - val_loss: 0.0253 - val_accuracy: 0.9296 - val_precision: 0.9542 - val_recall: 0.9137\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0242 - accuracy: 0.9328 - precision: 0.9572 - recall: 0.9196 - val_loss: 0.0252 - val_accuracy: 0.9299 - val_precision: 0.9548 - val_recall: 0.9140\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0240 - accuracy: 0.9333 - precision: 0.9575 - recall: 0.9195 - val_loss: 0.0250 - val_accuracy: 0.9301 - val_precision: 0.9557 - val_recall: 0.9143\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0239 - accuracy: 0.9339 - precision: 0.9576 - recall: 0.9198 - val_loss: 0.0249 - val_accuracy: 0.9301 - val_precision: 0.9563 - val_recall: 0.9149\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0238 - accuracy: 0.9344 - precision: 0.9580 - recall: 0.9207 - val_loss: 0.0248 - val_accuracy: 0.9301 - val_precision: 0.9570 - val_recall: 0.9173\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.0237 - accuracy: 0.9347 - precision: 0.9593 - recall: 0.9213 - val_loss: 0.0246 - val_accuracy: 0.9307 - val_precision: 0.9588 - val_recall: 0.9176\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0235 - accuracy: 0.9349 - precision: 0.9610 - recall: 0.9214 - val_loss: 0.0245 - val_accuracy: 0.9307 - val_precision: 0.9591 - val_recall: 0.9176\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0234 - accuracy: 0.9354 - precision: 0.9619 - recall: 0.9213 - val_loss: 0.0244 - val_accuracy: 0.9307 - val_precision: 0.9594 - val_recall: 0.9176\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0233 - accuracy: 0.9357 - precision: 0.9625 - recall: 0.9213 - val_loss: 0.0243 - val_accuracy: 0.9310 - val_precision: 0.9597 - val_recall: 0.9176\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0232 - accuracy: 0.9360 - precision: 0.9630 - recall: 0.9213 - val_loss: 0.0242 - val_accuracy: 0.9313 - val_precision: 0.9600 - val_recall: 0.9179\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0231 - accuracy: 0.9363 - precision: 0.9635 - recall: 0.9214 - val_loss: 0.0240 - val_accuracy: 0.9319 - val_precision: 0.9601 - val_recall: 0.9185\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.0230 - accuracy: 0.9365 - precision: 0.9643 - recall: 0.9221 - val_loss: 0.0239 - val_accuracy: 0.9319 - val_precision: 0.9610 - val_recall: 0.9185\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0228 - accuracy: 0.9370 - precision: 0.9649 - recall: 0.9225 - val_loss: 0.0238 - val_accuracy: 0.9322 - val_precision: 0.9613 - val_recall: 0.9191\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0227 - accuracy: 0.9372 - precision: 0.9655 - recall: 0.9233 - val_loss: 0.0237 - val_accuracy: 0.9322 - val_precision: 0.9622 - val_recall: 0.9200\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 97ms/step - loss: 0.0226 - accuracy: 0.9376 - precision: 0.9654 - recall: 0.9235 - val_loss: 0.0236 - val_accuracy: 0.9322 - val_precision: 0.9625 - val_recall: 0.9203\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 0.0225 - accuracy: 0.9377 - precision: 0.9654 - recall: 0.9239 - val_loss: 0.0235 - val_accuracy: 0.9316 - val_precision: 0.9628 - val_recall: 0.9206\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.0224 - accuracy: 0.9380 - precision: 0.9655 - recall: 0.9242 - val_loss: 0.0234 - val_accuracy: 0.9316 - val_precision: 0.9628 - val_recall: 0.9203\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.0223 - accuracy: 0.9386 - precision: 0.9656 - recall: 0.9248 - val_loss: 0.0233 - val_accuracy: 0.9325 - val_precision: 0.9634 - val_recall: 0.9203\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = lst.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T4PYyOpNic6Y",
        "outputId": "ba0e22a1-2b7a-4ff3-afb4-3e209122ae15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 2ms/step - loss: 0.1290 - accuracy: 0.6472 - precision: 0.7680 - recall: 0.6010\n",
            "Test results - Loss: 0.1290203034877777 - Accuracy: 64.7236168384552%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy3_2 = test_results[1]\n",
        "y_pred3_2 = np.argmax(lst.predict(X_test),axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUk-TbiRic6Y",
        "outputId": "5a87d717-2966-4a35-8725-ed41d5efdfd9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 4"
      ],
      "metadata": {
        "id": "Vi1EP7LWinDO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('clusters/train4.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('clusters/test4.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count4 = len(test.index)"
      ],
      "metadata": {
        "id": "BE3ttFXXinDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "X_test = test.iloc[:,0:89]\n",
        "y_train = train[['Dos','normal','Probe','R2L']]\n",
        "y_test = test[['Dos','normal','Probe','R2L']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "y_train = y_train.values\n",
        "\n",
        "# X_train = X_train.to_numpy()\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "# y_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "\n",
        "\n",
        "# X_test = X_test.to_numpy()\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
      ],
      "metadata": {
        "id": "MpZ1LvE5inDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = Sequential()\n",
        "\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "\n",
        "lst.add(Dense(4,activation='softmax'))\n",
        "\n",
        "lst.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "lst.summary()\n",
        "history = lst.fit(X_train, y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M8QdUXJtinDQ",
        "outputId": "b5421c30-c57c-4e64-c211-984fb17280b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_7 (LSTM)               (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_43 (Dense)            (None, 4)                 204       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,204\n",
            "Trainable params: 28,204\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "3/3 [==============================] - 3s 380ms/step - loss: 0.1893 - accuracy: 0.1037 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1862 - val_accuracy: 0.2166 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1851 - accuracy: 0.2929 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1820 - val_accuracy: 0.4539 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1810 - accuracy: 0.4745 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1781 - val_accuracy: 0.5677 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1771 - accuracy: 0.5787 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1742 - val_accuracy: 0.6482 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1733 - accuracy: 0.6949 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1704 - val_accuracy: 0.7651 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.1695 - accuracy: 0.7801 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1665 - val_accuracy: 0.8384 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.1657 - accuracy: 0.8383 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1627 - val_accuracy: 0.8704 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.1619 - accuracy: 0.8639 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1588 - val_accuracy: 0.8809 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1580 - accuracy: 0.8621 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1549 - val_accuracy: 0.8554 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.1541 - accuracy: 0.8544 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1508 - val_accuracy: 0.8495 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.1500 - accuracy: 0.8512 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1467 - val_accuracy: 0.8429 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1458 - accuracy: 0.8407 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1424 - val_accuracy: 0.8364 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.1415 - accuracy: 0.8388 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1379 - val_accuracy: 0.8357 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1371 - accuracy: 0.8354 - precision: 1.0000 - recall: 4.0906e-04 - val_loss: 0.1334 - val_accuracy: 0.8341 - val_precision: 1.0000 - val_recall: 0.0039\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1325 - accuracy: 0.8327 - precision: 0.9817 - recall: 0.0088 - val_loss: 0.1288 - val_accuracy: 0.8318 - val_precision: 0.9798 - val_recall: 0.0317\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1279 - accuracy: 0.8297 - precision: 0.9465 - recall: 0.0391 - val_loss: 0.1241 - val_accuracy: 0.8279 - val_precision: 0.9641 - val_recall: 0.0792\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1232 - accuracy: 0.8266 - precision: 0.9430 - recall: 0.0920 - val_loss: 0.1194 - val_accuracy: 0.8256 - val_precision: 0.9541 - val_recall: 0.1293\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1185 - accuracy: 0.8243 - precision: 0.9350 - recall: 0.1613 - val_loss: 0.1147 - val_accuracy: 0.8230 - val_precision: 0.9584 - val_recall: 0.3017\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.1138 - accuracy: 0.8234 - precision: 0.9482 - recall: 0.3296 - val_loss: 0.1100 - val_accuracy: 0.8230 - val_precision: 0.9561 - val_recall: 0.3851\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1092 - accuracy: 0.8239 - precision: 0.9515 - recall: 0.4061 - val_loss: 0.1053 - val_accuracy: 0.8249 - val_precision: 0.9582 - val_recall: 0.4571\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1046 - accuracy: 0.8253 - precision: 0.9525 - recall: 0.4694 - val_loss: 0.1008 - val_accuracy: 0.8276 - val_precision: 0.9562 - val_recall: 0.5209\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.1001 - accuracy: 0.8481 - precision: 0.9560 - recall: 0.5801 - val_loss: 0.0963 - val_accuracy: 0.8642 - val_precision: 0.9617 - val_recall: 0.6482\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.0957 - accuracy: 0.8630 - precision: 0.9566 - recall: 0.6471 - val_loss: 0.0920 - val_accuracy: 0.8688 - val_precision: 0.9601 - val_recall: 0.6770\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0914 - accuracy: 0.8658 - precision: 0.9539 - recall: 0.6743 - val_loss: 0.0879 - val_accuracy: 0.8734 - val_precision: 0.9569 - val_recall: 0.6895\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0874 - accuracy: 0.8678 - precision: 0.9515 - recall: 0.6850 - val_loss: 0.0839 - val_accuracy: 0.8750 - val_precision: 0.9524 - val_recall: 0.7202\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.0836 - accuracy: 0.8697 - precision: 0.9477 - recall: 0.7186 - val_loss: 0.0802 - val_accuracy: 0.8776 - val_precision: 0.9467 - val_recall: 0.7317\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 105ms/step - loss: 0.0799 - accuracy: 0.8717 - precision: 0.9440 - recall: 0.7298 - val_loss: 0.0767 - val_accuracy: 0.8802 - val_precision: 0.9444 - val_recall: 0.7510\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.0765 - accuracy: 0.8738 - precision: 0.9430 - recall: 0.7544 - val_loss: 0.0735 - val_accuracy: 0.8835 - val_precision: 0.9452 - val_recall: 0.7899\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.0734 - accuracy: 0.8776 - precision: 0.9435 - recall: 0.7851 - val_loss: 0.0705 - val_accuracy: 0.8855 - val_precision: 0.9436 - val_recall: 0.7945\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 96ms/step - loss: 0.0704 - accuracy: 0.8797 - precision: 0.9428 - recall: 0.7909 - val_loss: 0.0677 - val_accuracy: 0.8858 - val_precision: 0.9424 - val_recall: 0.7971\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.0677 - accuracy: 0.8812 - precision: 0.9420 - recall: 0.7936 - val_loss: 0.0651 - val_accuracy: 0.8894 - val_precision: 0.9414 - val_recall: 0.7984\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.0653 - accuracy: 0.8879 - precision: 0.9410 - recall: 0.7958 - val_loss: 0.0628 - val_accuracy: 0.8956 - val_precision: 0.9401 - val_recall: 0.8014\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.0630 - accuracy: 0.8932 - precision: 0.9401 - recall: 0.8039 - val_loss: 0.0607 - val_accuracy: 0.8959 - val_precision: 0.9412 - val_recall: 0.8177\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.0609 - accuracy: 0.8932 - precision: 0.9400 - recall: 0.8222 - val_loss: 0.0588 - val_accuracy: 0.8963 - val_precision: 0.9417 - val_recall: 0.8348\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 0.0591 - accuracy: 0.8935 - precision: 0.9404 - recall: 0.8404 - val_loss: 0.0570 - val_accuracy: 0.8963 - val_precision: 0.9418 - val_recall: 0.8472\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.0573 - accuracy: 0.8938 - precision: 0.9396 - recall: 0.8510 - val_loss: 0.0554 - val_accuracy: 0.8963 - val_precision: 0.9400 - val_recall: 0.8563\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 0.0558 - accuracy: 0.8936 - precision: 0.9344 - recall: 0.8618 - val_loss: 0.0540 - val_accuracy: 0.8959 - val_precision: 0.9234 - val_recall: 0.8678\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0544 - accuracy: 0.8932 - precision: 0.9224 - recall: 0.8732 - val_loss: 0.0527 - val_accuracy: 0.8953 - val_precision: 0.9159 - val_recall: 0.8727\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 59ms/step - loss: 0.0531 - accuracy: 0.8934 - precision: 0.9161 - recall: 0.8765 - val_loss: 0.0515 - val_accuracy: 0.8953 - val_precision: 0.9127 - val_recall: 0.8753\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0519 - accuracy: 0.8940 - precision: 0.9118 - recall: 0.8786 - val_loss: 0.0504 - val_accuracy: 0.8953 - val_precision: 0.9079 - val_recall: 0.8773\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0509 - accuracy: 0.8944 - precision: 0.9078 - recall: 0.8801 - val_loss: 0.0494 - val_accuracy: 0.8966 - val_precision: 0.9055 - val_recall: 0.8779\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0499 - accuracy: 0.8945 - precision: 0.9060 - recall: 0.8811 - val_loss: 0.0485 - val_accuracy: 0.8959 - val_precision: 0.9035 - val_recall: 0.8793\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.0490 - accuracy: 0.8947 - precision: 0.9045 - recall: 0.8822 - val_loss: 0.0477 - val_accuracy: 0.8959 - val_precision: 0.9038 - val_recall: 0.8789\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0482 - accuracy: 0.8950 - precision: 0.9047 - recall: 0.8834 - val_loss: 0.0470 - val_accuracy: 0.8959 - val_precision: 0.9041 - val_recall: 0.8796\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0475 - accuracy: 0.8953 - precision: 0.9049 - recall: 0.8842 - val_loss: 0.0463 - val_accuracy: 0.8966 - val_precision: 0.9043 - val_recall: 0.8812\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0468 - accuracy: 0.8963 - precision: 0.9050 - recall: 0.8851 - val_loss: 0.0456 - val_accuracy: 0.8966 - val_precision: 0.9044 - val_recall: 0.8819\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0462 - accuracy: 0.8966 - precision: 0.9050 - recall: 0.8857 - val_loss: 0.0450 - val_accuracy: 0.8969 - val_precision: 0.9045 - val_recall: 0.8829\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0456 - accuracy: 0.8972 - precision: 0.9048 - recall: 0.8869 - val_loss: 0.0445 - val_accuracy: 0.8969 - val_precision: 0.9047 - val_recall: 0.8848\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0451 - accuracy: 0.8976 - precision: 0.9049 - recall: 0.8887 - val_loss: 0.0439 - val_accuracy: 0.8979 - val_precision: 0.9045 - val_recall: 0.8868\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0446 - accuracy: 0.8980 - precision: 0.9045 - recall: 0.8896 - val_loss: 0.0434 - val_accuracy: 0.8979 - val_precision: 0.9040 - val_recall: 0.8878\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0441 - accuracy: 0.8981 - precision: 0.9045 - recall: 0.8901 - val_loss: 0.0430 - val_accuracy: 0.8979 - val_precision: 0.9045 - val_recall: 0.8894\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0437 - accuracy: 0.8984 - precision: 0.9045 - recall: 0.8904 - val_loss: 0.0425 - val_accuracy: 0.8973 - val_precision: 0.9040 - val_recall: 0.8901\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0433 - accuracy: 0.8989 - precision: 0.9045 - recall: 0.8908 - val_loss: 0.0421 - val_accuracy: 0.8973 - val_precision: 0.9038 - val_recall: 0.8914\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0429 - accuracy: 0.8992 - precision: 0.9046 - recall: 0.8913 - val_loss: 0.0417 - val_accuracy: 0.8973 - val_precision: 0.9038 - val_recall: 0.8920\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0425 - accuracy: 0.8996 - precision: 0.9048 - recall: 0.8917 - val_loss: 0.0414 - val_accuracy: 0.8976 - val_precision: 0.9044 - val_recall: 0.8920\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0421 - accuracy: 0.8996 - precision: 0.9053 - recall: 0.8920 - val_loss: 0.0410 - val_accuracy: 0.8979 - val_precision: 0.9045 - val_recall: 0.8927\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0418 - accuracy: 0.8999 - precision: 0.9063 - recall: 0.8925 - val_loss: 0.0407 - val_accuracy: 0.8982 - val_precision: 0.9060 - val_recall: 0.8927\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0414 - accuracy: 0.9004 - precision: 0.9071 - recall: 0.8927 - val_loss: 0.0403 - val_accuracy: 0.8982 - val_precision: 0.9073 - val_recall: 0.8933\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 62ms/step - loss: 0.0411 - accuracy: 0.9003 - precision: 0.9078 - recall: 0.8936 - val_loss: 0.0400 - val_accuracy: 0.8992 - val_precision: 0.9076 - val_recall: 0.8937\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.0408 - accuracy: 0.9007 - precision: 0.9084 - recall: 0.8942 - val_loss: 0.0397 - val_accuracy: 0.8999 - val_precision: 0.9085 - val_recall: 0.8940\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0405 - accuracy: 0.9009 - precision: 0.9094 - recall: 0.8950 - val_loss: 0.0393 - val_accuracy: 0.9005 - val_precision: 0.9089 - val_recall: 0.8943\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.0402 - accuracy: 0.9017 - precision: 0.9105 - recall: 0.8952 - val_loss: 0.0390 - val_accuracy: 0.9012 - val_precision: 0.9104 - val_recall: 0.8946\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0399 - accuracy: 0.9021 - precision: 0.9114 - recall: 0.8957 - val_loss: 0.0387 - val_accuracy: 0.9012 - val_precision: 0.9115 - val_recall: 0.8963\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 63ms/step - loss: 0.0396 - accuracy: 0.9026 - precision: 0.9127 - recall: 0.8959 - val_loss: 0.0384 - val_accuracy: 0.9012 - val_precision: 0.9131 - val_recall: 0.8969\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.0393 - accuracy: 0.9026 - precision: 0.9151 - recall: 0.8967 - val_loss: 0.0381 - val_accuracy: 0.9012 - val_precision: 0.9149 - val_recall: 0.8966\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0390 - accuracy: 0.9029 - precision: 0.9157 - recall: 0.8970 - val_loss: 0.0378 - val_accuracy: 0.9012 - val_precision: 0.9159 - val_recall: 0.8976\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0388 - accuracy: 0.9029 - precision: 0.9167 - recall: 0.8973 - val_loss: 0.0375 - val_accuracy: 0.9018 - val_precision: 0.9161 - val_recall: 0.8969\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.0385 - accuracy: 0.9031 - precision: 0.9178 - recall: 0.8972 - val_loss: 0.0372 - val_accuracy: 0.9018 - val_precision: 0.9182 - val_recall: 0.8963\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0382 - accuracy: 0.9031 - precision: 0.9185 - recall: 0.8979 - val_loss: 0.0369 - val_accuracy: 0.9022 - val_precision: 0.9188 - val_recall: 0.8966\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0379 - accuracy: 0.9035 - precision: 0.9193 - recall: 0.8978 - val_loss: 0.0366 - val_accuracy: 0.9025 - val_precision: 0.9198 - val_recall: 0.8966\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0376 - accuracy: 0.9041 - precision: 0.9200 - recall: 0.8981 - val_loss: 0.0363 - val_accuracy: 0.9025 - val_precision: 0.9207 - val_recall: 0.8963\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0373 - accuracy: 0.9042 - precision: 0.9212 - recall: 0.8983 - val_loss: 0.0360 - val_accuracy: 0.9028 - val_precision: 0.9217 - val_recall: 0.8969\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0371 - accuracy: 0.9043 - precision: 0.9225 - recall: 0.8982 - val_loss: 0.0357 - val_accuracy: 0.9031 - val_precision: 0.9235 - val_recall: 0.8966\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0368 - accuracy: 0.9048 - precision: 0.9237 - recall: 0.8986 - val_loss: 0.0354 - val_accuracy: 0.9041 - val_precision: 0.9235 - val_recall: 0.8966\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0365 - accuracy: 0.9060 - precision: 0.9247 - recall: 0.8986 - val_loss: 0.0351 - val_accuracy: 0.9061 - val_precision: 0.9247 - val_recall: 0.8963\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.0362 - accuracy: 0.9072 - precision: 0.9260 - recall: 0.8985 - val_loss: 0.0348 - val_accuracy: 0.9090 - val_precision: 0.9260 - val_recall: 0.8966\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 65ms/step - loss: 0.0359 - accuracy: 0.9084 - precision: 0.9278 - recall: 0.8986 - val_loss: 0.0344 - val_accuracy: 0.9094 - val_precision: 0.9281 - val_recall: 0.8959\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.0356 - accuracy: 0.9098 - precision: 0.9281 - recall: 0.8983 - val_loss: 0.0341 - val_accuracy: 0.9107 - val_precision: 0.9294 - val_recall: 0.8959\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0353 - accuracy: 0.9112 - precision: 0.9287 - recall: 0.8986 - val_loss: 0.0338 - val_accuracy: 0.9110 - val_precision: 0.9304 - val_recall: 0.8966\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0350 - accuracy: 0.9128 - precision: 0.9299 - recall: 0.8990 - val_loss: 0.0335 - val_accuracy: 0.9130 - val_precision: 0.9311 - val_recall: 0.8973\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0347 - accuracy: 0.9139 - precision: 0.9309 - recall: 0.8991 - val_loss: 0.0332 - val_accuracy: 0.9139 - val_precision: 0.9330 - val_recall: 0.8976\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0344 - accuracy: 0.9148 - precision: 0.9317 - recall: 0.9004 - val_loss: 0.0329 - val_accuracy: 0.9159 - val_precision: 0.9325 - val_recall: 0.8995\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0342 - accuracy: 0.9157 - precision: 0.9321 - recall: 0.9012 - val_loss: 0.0326 - val_accuracy: 0.9169 - val_precision: 0.9333 - val_recall: 0.9015\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0339 - accuracy: 0.9170 - precision: 0.9326 - recall: 0.9027 - val_loss: 0.0323 - val_accuracy: 0.9182 - val_precision: 0.9336 - val_recall: 0.9022\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0336 - accuracy: 0.9175 - precision: 0.9332 - recall: 0.9047 - val_loss: 0.0321 - val_accuracy: 0.9188 - val_precision: 0.9346 - val_recall: 0.9018\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.0334 - accuracy: 0.9185 - precision: 0.9334 - recall: 0.9059 - val_loss: 0.0318 - val_accuracy: 0.9205 - val_precision: 0.9346 - val_recall: 0.9031\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0331 - accuracy: 0.9195 - precision: 0.9344 - recall: 0.9076 - val_loss: 0.0315 - val_accuracy: 0.9218 - val_precision: 0.9344 - val_recall: 0.9038\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0329 - accuracy: 0.9203 - precision: 0.9348 - recall: 0.9084 - val_loss: 0.0313 - val_accuracy: 0.9221 - val_precision: 0.9351 - val_recall: 0.9051\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0326 - accuracy: 0.9209 - precision: 0.9355 - recall: 0.9093 - val_loss: 0.0310 - val_accuracy: 0.9228 - val_precision: 0.9355 - val_recall: 0.9064\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0324 - accuracy: 0.9214 - precision: 0.9353 - recall: 0.9100 - val_loss: 0.0308 - val_accuracy: 0.9234 - val_precision: 0.9362 - val_recall: 0.9074\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0322 - accuracy: 0.9218 - precision: 0.9353 - recall: 0.9108 - val_loss: 0.0305 - val_accuracy: 0.9241 - val_precision: 0.9376 - val_recall: 0.9094\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0320 - accuracy: 0.9220 - precision: 0.9358 - recall: 0.9116 - val_loss: 0.0303 - val_accuracy: 0.9247 - val_precision: 0.9379 - val_recall: 0.9094\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.0318 - accuracy: 0.9229 - precision: 0.9356 - recall: 0.9121 - val_loss: 0.0301 - val_accuracy: 0.9257 - val_precision: 0.9383 - val_recall: 0.9107\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0316 - accuracy: 0.9234 - precision: 0.9356 - recall: 0.9126 - val_loss: 0.0299 - val_accuracy: 0.9260 - val_precision: 0.9375 - val_recall: 0.9123\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0314 - accuracy: 0.9238 - precision: 0.9357 - recall: 0.9132 - val_loss: 0.0297 - val_accuracy: 0.9260 - val_precision: 0.9378 - val_recall: 0.9130\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0312 - accuracy: 0.9242 - precision: 0.9358 - recall: 0.9139 - val_loss: 0.0295 - val_accuracy: 0.9264 - val_precision: 0.9379 - val_recall: 0.9139\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0310 - accuracy: 0.9247 - precision: 0.9359 - recall: 0.9145 - val_loss: 0.0294 - val_accuracy: 0.9260 - val_precision: 0.9379 - val_recall: 0.9143\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.0308 - accuracy: 0.9249 - precision: 0.9360 - recall: 0.9152 - val_loss: 0.0292 - val_accuracy: 0.9264 - val_precision: 0.9386 - val_recall: 0.9156\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0307 - accuracy: 0.9256 - precision: 0.9360 - recall: 0.9157 - val_loss: 0.0290 - val_accuracy: 0.9257 - val_precision: 0.9402 - val_recall: 0.9159\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.0305 - accuracy: 0.9256 - precision: 0.9371 - recall: 0.9160 - val_loss: 0.0288 - val_accuracy: 0.9267 - val_precision: 0.9405 - val_recall: 0.9162\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = lst.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2LIWAipinDQ",
        "outputId": "4eef2d65-3f4f-4fef-ecb8-48b65bfe9025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1093 - accuracy: 0.7545 - precision: 0.7615 - recall: 0.7464\n",
            "Test results - Loss: 0.10925447195768356 - Accuracy: 75.45005083084106%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy4_2 = test_results[1]\n",
        "y_pred4_2 = np.argmax(lst.predict(X_test),axis=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RR1AYUXYinDQ",
        "outputId": "47011899-40c8-40c4-a0f8-f352d578e5a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "91KiF4aPUbK5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "y_test = [*y_test1,*y_test2,*y_test3,*y_test4]\n",
        "y_pred2 = [*y_pred1_2,*y_pred2_2,*y_pred3_2,*y_pred4_2]\n",
        "accuracy = (test_count1*accuracy1_2 + test_count2*accuracy2_2 + test_count3*accuracy3_2 + test_count4*accuracy4_2)/(test_count1 + test_count2 + test_count3 + test_count4)\n",
        "presion = precision_score(y_test,y_pred2,average='weighted')\n",
        "recall = recall_score(y_test,y_pred2,average='weighted')"
      ],
      "metadata": {
        "id": "MaQ5keILPfCm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {}\\t Precision:{}\\t Recall: {}\".format(accuracy,presion,recall))"
      ],
      "metadata": {
        "id": "7BaGjFrJUdcD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9ba836b9-9f3f-4931-d398-80e916952303"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7629398804611401\t Precision:0.7967608515909846\t Recall: 0.7629398852934929\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Model"
      ],
      "metadata": {
        "id": "tdYa8loRlL5w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding Best"
      ],
      "metadata": {
        "id": "C_7F670FDbjk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "if accuracy1_1 > accuracy1_2:\n",
        "  y_pred.extend(y_pred1_1)\n",
        "  accuracy1 = accuracy1_1\n",
        "else:\n",
        "  y_pred.extend(y_pred1_2)\n",
        "  accuracy1 = accuracy1_2\n",
        "\n",
        "if accuracy2_1 > accuracy2_2:\n",
        "  y_pred.extend(y_pred2_1)\n",
        "  accuracy2 = accuracy2_1\n",
        "else:\n",
        "  y_pred.extend(y_pred2_2)\n",
        "  accuracy2 = accuracy2_2\n",
        "\n",
        "if accuracy3_1 > accuracy3_2:\n",
        "  y_pred.extend(y_pred3_1)\n",
        "  accuracy3 = accuracy3_1\n",
        "else:\n",
        "  y_pred.extend(y_pred3_2)\n",
        "  accuracy3 = accuracy3_2\n",
        "\n",
        "if accuracy4_1 > accuracy4_2:\n",
        "  y_pred.extend(y_pred4_1)\n",
        "  accuracy4 = accuracy4_1\n",
        "else:\n",
        "  y_pred.extend(y_pred4_2)\n",
        "  accuracy4 = accuracy4_2\n",
        "\n",
        "y_test = [*y_test1,*y_test2,*y_test3,*y_test4]"
      ],
      "metadata": {
        "id": "u_4mEbgSDYVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result"
      ],
      "metadata": {
        "id": "QLWZlGNqDjNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "y_pred = np.array(y_pred) \n",
        "accuracy = (test_count1*accuracy1 + test_count2*accuracy2 + test_count3*accuracy3 + test_count4*accuracy4)/(test_count1 + test_count2 + test_count3 + test_count4)\n",
        "presion = precision_score(y_test,y_pred,average='weighted')\n",
        "recall = recall_score(y_test,y_pred,average='weighted')"
      ],
      "metadata": {
        "id": "DqkE4erElLP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {}\\t Precision:{}\\t Recall: {}\".format(accuracy,presion,recall))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Urc-okxoGXEC",
        "outputId": "09392d9e-f393-4bb2-9693-50c2f8eb895c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8306308982013213\t Precision:0.8203919910888552\t Recall: 0.8306308857891382\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Clustering (Binary)\n"
      ],
      "metadata": {
        "id": "orgMVDvEb3c7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating clusters"
      ],
      "metadata": {
        "id": "0nB8R8isb3c8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 'https://drive.google.com/uc?id=1sqbAdoBpxpQUC_BW0npQqsi4WXTBbq9O&confirm=t'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "911ff9f5-07ed-4593-c320-cfdbf0ee98cc",
        "id": "8doShcbBb3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1sqbAdoBpxpQUC_BW0npQqsi4WXTBbq9O&confirm=t\n",
            "To: /content/bin_data.csv\n",
            "100% 36.4M/36.4M [00:00<00:00, 170MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv('bin_data.csv')\n",
        "data = data.drop(['Unnamed: 0'],axis=1)\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "928ef279-8fa1-4105-9085-3cfa8ecdd0b1",
        "id": "yPdJ-Q_Fb3c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count  srv_serror_rate  serror_rate  dst_host_serror_rate  \\\n",
              "0      -0.615658        -0.514055    -0.516891             -0.513194   \n",
              "1      -0.473366        -0.514055    -0.516891             -0.513194   \n",
              "2       0.949553         1.985588     1.984040              2.005094   \n",
              "3      -0.576851        -0.014126    -0.016705             -0.437645   \n",
              "4      -0.253460        -0.514055    -0.516891             -0.513194   \n",
              "...          ...              ...          ...                   ...   \n",
              "102209  1.001295        -0.514055    -0.516891             -0.513194   \n",
              "102210  0.044059        -0.514055    -0.516891             -0.513194   \n",
              "102211 -0.628593        -0.514055    -0.516891             -0.488011   \n",
              "102212 -0.615658        -0.514055    -0.516891             -0.488011   \n",
              "102213 -0.589786        -0.514055    -0.516891             -0.513194   \n",
              "\n",
              "        dst_host_srv_serror_rate  logged_in  dst_host_same_srv_rate  \\\n",
              "0                      -0.503145  -0.864470               -0.959621   \n",
              "1                      -0.503145  -0.864470               -1.335998   \n",
              "2                       2.016338  -0.864470               -1.114600   \n",
              "3                      -0.477950   1.156779                0.877982   \n",
              "4                      -0.503145   1.156779                0.877982   \n",
              "...                          ...        ...                     ...   \n",
              "102209                 -0.503145  -0.864470               -1.181019   \n",
              "102210                 -0.503145  -0.864470                0.877982   \n",
              "102211                 -0.503145   1.156779                0.258068   \n",
              "102212                 -0.503145   1.156779                0.877982   \n",
              "102213                 -0.503145  -0.864470                0.855842   \n",
              "\n",
              "        dst_host_srv_count  same_srv_rate  protocol_type_icmp  ...  flag_S0  \\\n",
              "0                -0.967411       0.657887                   0  ...        0   \n",
              "1                -1.177300      -1.620628                   0  ...        0   \n",
              "2                -0.958665      -1.694928                   0  ...        1   \n",
              "3                 1.044027       0.657887                   0  ...        0   \n",
              "4                 1.044027       0.657887                   0  ...        0   \n",
              "...                    ...            ...                 ...  ...      ...   \n",
              "102209           -1.028628      -1.472029                   0  ...        0   \n",
              "102210            1.044027       0.657887                   1  ...        0   \n",
              "102211            0.047054       0.657887                   0  ...        0   \n",
              "102212            1.044027       0.657887                   0  ...        0   \n",
              "102213            1.017791       0.657887                   0  ...        0   \n",
              "\n",
              "        flag_S1  flag_S2  flag_S3  flag_SF  flag_SH  intrusion  abnormal  \\\n",
              "0             0        0        0        1        0          1         0   \n",
              "1             0        0        0        1        0          1         0   \n",
              "2             0        0        0        0        0          0         1   \n",
              "3             0        0        0        1        0          1         0   \n",
              "4             0        0        0        1        0          1         0   \n",
              "...         ...      ...      ...      ...      ...        ...       ...   \n",
              "102209        0        0        0        0        0          0         1   \n",
              "102210        0        0        0        1        0          0         1   \n",
              "102211        0        0        0        1        0          1         0   \n",
              "102212        0        0        0        1        0          1         0   \n",
              "102213        0        0        0        1        0          1         0   \n",
              "\n",
              "        normal     label  \n",
              "0            1    normal  \n",
              "1            1    normal  \n",
              "2            0  abnormal  \n",
              "3            1    normal  \n",
              "4            1    normal  \n",
              "...        ...       ...  \n",
              "102209       0  abnormal  \n",
              "102210       0  abnormal  \n",
              "102211       1    normal  \n",
              "102212       1    normal  \n",
              "102213       1    normal  \n",
              "\n",
              "[102214 rows x 93 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1bfc264f-87ae-42d2-b31d-84e5877b9db5\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S0</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>abnormal</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.959621</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.473366</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.620628</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.576851</td>\n",
              "      <td>-0.014126</td>\n",
              "      <td>-0.016705</td>\n",
              "      <td>-0.437645</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.253460</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102209</th>\n",
              "      <td>1.001295</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.181019</td>\n",
              "      <td>-1.028628</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102210</th>\n",
              "      <td>0.044059</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102211</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.258068</td>\n",
              "      <td>0.047054</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102212</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102213</th>\n",
              "      <td>-0.589786</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.855842</td>\n",
              "      <td>1.017791</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102214 rows × 93 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1bfc264f-87ae-42d2-b31d-84e5877b9db5')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1bfc264f-87ae-42d2-b31d-84e5877b9db5 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1bfc264f-87ae-42d2-b31d-84e5877b9db5');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 305
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "X = data.iloc[:,:89].values\n",
        "model = KMeans(n_clusters=4)\n",
        "model.fit(X)\n",
        "clusterNos = model.predict(X)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a106a1b1-7fa1-4e69-d698-6cf9e8d47794",
        "id": "Ev9QL57vb3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clusterNos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c540cd54-f119-4822-9b9f-9db598708675",
        "id": "9W558TRwb3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3, 3, 0, ..., 1, 1, 2], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 307
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data['clusterNo'] = clusterNos.tolist()\n",
        "data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b9fc5b9-15a2-441e-b1db-8ee2a8ef1d8a",
        "id": "pIEDav8bb3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count  srv_serror_rate  serror_rate  dst_host_serror_rate  \\\n",
              "0      -0.615658        -0.514055    -0.516891             -0.513194   \n",
              "1      -0.473366        -0.514055    -0.516891             -0.513194   \n",
              "2       0.949553         1.985588     1.984040              2.005094   \n",
              "3      -0.576851        -0.014126    -0.016705             -0.437645   \n",
              "4      -0.253460        -0.514055    -0.516891             -0.513194   \n",
              "...          ...              ...          ...                   ...   \n",
              "102209  1.001295        -0.514055    -0.516891             -0.513194   \n",
              "102210  0.044059        -0.514055    -0.516891             -0.513194   \n",
              "102211 -0.628593        -0.514055    -0.516891             -0.488011   \n",
              "102212 -0.615658        -0.514055    -0.516891             -0.488011   \n",
              "102213 -0.589786        -0.514055    -0.516891             -0.513194   \n",
              "\n",
              "        dst_host_srv_serror_rate  logged_in  dst_host_same_srv_rate  \\\n",
              "0                      -0.503145  -0.864470               -0.959621   \n",
              "1                      -0.503145  -0.864470               -1.335998   \n",
              "2                       2.016338  -0.864470               -1.114600   \n",
              "3                      -0.477950   1.156779                0.877982   \n",
              "4                      -0.503145   1.156779                0.877982   \n",
              "...                          ...        ...                     ...   \n",
              "102209                 -0.503145  -0.864470               -1.181019   \n",
              "102210                 -0.503145  -0.864470                0.877982   \n",
              "102211                 -0.503145   1.156779                0.258068   \n",
              "102212                 -0.503145   1.156779                0.877982   \n",
              "102213                 -0.503145  -0.864470                0.855842   \n",
              "\n",
              "        dst_host_srv_count  same_srv_rate  protocol_type_icmp  ...  flag_S1  \\\n",
              "0                -0.967411       0.657887                   0  ...        0   \n",
              "1                -1.177300      -1.620628                   0  ...        0   \n",
              "2                -0.958665      -1.694928                   0  ...        0   \n",
              "3                 1.044027       0.657887                   0  ...        0   \n",
              "4                 1.044027       0.657887                   0  ...        0   \n",
              "...                    ...            ...                 ...  ...      ...   \n",
              "102209           -1.028628      -1.472029                   0  ...        0   \n",
              "102210            1.044027       0.657887                   1  ...        0   \n",
              "102211            0.047054       0.657887                   0  ...        0   \n",
              "102212            1.044027       0.657887                   0  ...        0   \n",
              "102213            1.017791       0.657887                   0  ...        0   \n",
              "\n",
              "        flag_S2  flag_S3  flag_SF  flag_SH  intrusion  abnormal  normal  \\\n",
              "0             0        0        1        0          1         0       1   \n",
              "1             0        0        1        0          1         0       1   \n",
              "2             0        0        0        0          0         1       0   \n",
              "3             0        0        1        0          1         0       1   \n",
              "4             0        0        1        0          1         0       1   \n",
              "...         ...      ...      ...      ...        ...       ...     ...   \n",
              "102209        0        0        0        0          0         1       0   \n",
              "102210        0        0        1        0          0         1       0   \n",
              "102211        0        0        1        0          1         0       1   \n",
              "102212        0        0        1        0          1         0       1   \n",
              "102213        0        0        1        0          1         0       1   \n",
              "\n",
              "           label  clusterNo  \n",
              "0         normal          3  \n",
              "1         normal          3  \n",
              "2       abnormal          0  \n",
              "3         normal          1  \n",
              "4         normal          1  \n",
              "...          ...        ...  \n",
              "102209  abnormal          3  \n",
              "102210  abnormal          2  \n",
              "102211    normal          1  \n",
              "102212    normal          1  \n",
              "102213    normal          2  \n",
              "\n",
              "[102214 rows x 94 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-466135a7-fb15-453a-9e06-7badc7ec28ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>abnormal</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.959621</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.473366</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.620628</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.576851</td>\n",
              "      <td>-0.014126</td>\n",
              "      <td>-0.016705</td>\n",
              "      <td>-0.437645</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.253460</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102209</th>\n",
              "      <td>1.001295</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.181019</td>\n",
              "      <td>-1.028628</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102210</th>\n",
              "      <td>0.044059</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102211</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.258068</td>\n",
              "      <td>0.047054</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102212</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102213</th>\n",
              "      <td>-0.589786</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.855842</td>\n",
              "      <td>1.017791</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102214 rows × 94 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-466135a7-fb15-453a-9e06-7badc7ec28ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-466135a7-fb15-453a-9e06-7badc7ec28ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-466135a7-fb15-453a-9e06-7badc7ec28ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = data.iloc[:88091]\n",
        "train_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e9f5fd5c-274b-46f1-844c-698a7fa05e3f",
        "id": "z24QPBZPb3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          count  srv_serror_rate  serror_rate  dst_host_serror_rate  \\\n",
              "0     -0.615658        -0.514055    -0.516891             -0.513194   \n",
              "1     -0.473366        -0.514055    -0.516891             -0.513194   \n",
              "2      0.949553         1.985588     1.984040              2.005094   \n",
              "3     -0.576851        -0.014126    -0.016705             -0.437645   \n",
              "4     -0.253460        -0.514055    -0.516891             -0.513194   \n",
              "...         ...              ...          ...                   ...   \n",
              "88086 -0.602722        -0.289087     0.308416              0.317841   \n",
              "88087  1.738626         1.985588     1.984040              2.005094   \n",
              "88088 -0.615658        -0.514055    -0.516891             -0.513194   \n",
              "88089  1.221201         1.985588     1.984040              2.005094   \n",
              "88090 -0.628593        -0.514055    -0.516891             -0.513194   \n",
              "\n",
              "       dst_host_srv_serror_rate  logged_in  dst_host_same_srv_rate  \\\n",
              "0                     -0.503145  -0.864470               -0.959621   \n",
              "1                     -0.503145  -0.864470               -1.335998   \n",
              "2                      2.016338  -0.864470               -1.114600   \n",
              "3                     -0.477950   1.156779                0.877982   \n",
              "4                     -0.503145   1.156779                0.877982   \n",
              "...                         ...        ...                     ...   \n",
              "88086                 -0.503145   1.156779                0.877982   \n",
              "88087                  2.016338  -0.864470               -1.114600   \n",
              "88088                 -0.503145  -0.864470                0.789423   \n",
              "88089                  2.016338  -0.864470               -1.269578   \n",
              "88090                 -0.503145   1.156779               -0.671804   \n",
              "\n",
              "       dst_host_srv_count  same_srv_rate  protocol_type_icmp  ...  flag_S1  \\\n",
              "0               -0.967411       0.657887                   0  ...        0   \n",
              "1               -1.177300      -1.620628                   0  ...        0   \n",
              "2               -0.958665      -1.694928                   0  ...        0   \n",
              "3                1.044027       0.657887                   0  ...        0   \n",
              "4                1.044027       0.657887                   0  ...        0   \n",
              "...                   ...            ...                 ...  ...      ...   \n",
              "88086            1.044027       0.657887                   0  ...        0   \n",
              "88087           -0.967411      -1.472029                   0  ...        0   \n",
              "88088            0.947828       0.657887                   0  ...        0   \n",
              "88089           -1.116082      -1.670161                   0  ...        0   \n",
              "88090           -0.512651       0.657887                   0  ...        0   \n",
              "\n",
              "       flag_S2  flag_S3  flag_SF  flag_SH  intrusion  abnormal  normal  \\\n",
              "0            0        0        1        0          1         0       1   \n",
              "1            0        0        1        0          1         0       1   \n",
              "2            0        0        0        0          0         1       0   \n",
              "3            0        0        1        0          1         0       1   \n",
              "4            0        0        1        0          1         0       1   \n",
              "...        ...      ...      ...      ...        ...       ...     ...   \n",
              "88086        0        0        1        0          1         0       1   \n",
              "88087        0        0        0        0          0         1       0   \n",
              "88088        0        0        1        0          1         0       1   \n",
              "88089        0        0        0        0          0         1       0   \n",
              "88090        0        0        1        0          1         0       1   \n",
              "\n",
              "          label  clusterNo  \n",
              "0        normal          3  \n",
              "1        normal          3  \n",
              "2      abnormal          0  \n",
              "3        normal          1  \n",
              "4        normal          1  \n",
              "...         ...        ...  \n",
              "88086    normal          1  \n",
              "88087  abnormal          0  \n",
              "88088    normal          2  \n",
              "88089  abnormal          0  \n",
              "88090    normal          1  \n",
              "\n",
              "[88091 rows x 94 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0431a45e-1eb8-4cce-841f-335a9ca4a997\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>abnormal</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-0.959621</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.473366</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.620628</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-0.576851</td>\n",
              "      <td>-0.014126</td>\n",
              "      <td>-0.016705</td>\n",
              "      <td>-0.437645</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.253460</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88086</th>\n",
              "      <td>-0.602722</td>\n",
              "      <td>-0.289087</td>\n",
              "      <td>0.308416</td>\n",
              "      <td>0.317841</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88087</th>\n",
              "      <td>1.738626</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>-0.967411</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88088</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.789423</td>\n",
              "      <td>0.947828</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88089</th>\n",
              "      <td>1.221201</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.984040</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.269578</td>\n",
              "      <td>-1.116082</td>\n",
              "      <td>-1.670161</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88090</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-0.671804</td>\n",
              "      <td>-0.512651</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>88091 rows × 94 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0431a45e-1eb8-4cce-841f-335a9ca4a997')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0431a45e-1eb8-4cce-841f-335a9ca4a997 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0431a45e-1eb8-4cce-841f-335a9ca4a997');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = data.iloc[88091:]\n",
        "test_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0767c61d-55b6-4461-92a2-9ab465f46649",
        "id": "ClzJUEgMb3c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           count  srv_serror_rate  serror_rate  dst_host_serror_rate  \\\n",
              "88091   2.320729        -0.514055    -0.516891             -0.513194   \n",
              "88092   1.117716        -0.514055    -0.516891             -0.513194   \n",
              "88093  -0.628593        -0.514055    -0.516891             -0.513194   \n",
              "88094  -0.628593        -0.514055    -0.516891             -0.488011   \n",
              "88095  -0.214653        -0.514055    -0.516891             -0.513194   \n",
              "...          ...              ...          ...                   ...   \n",
              "102209  1.001295        -0.514055    -0.516891             -0.513194   \n",
              "102210  0.044059        -0.514055    -0.516891             -0.513194   \n",
              "102211 -0.628593        -0.514055    -0.516891             -0.488011   \n",
              "102212 -0.615658        -0.514055    -0.516891             -0.488011   \n",
              "102213 -0.589786        -0.514055    -0.516891             -0.513194   \n",
              "\n",
              "        dst_host_srv_serror_rate  logged_in  dst_host_same_srv_rate  \\\n",
              "88091                  -0.503145  -0.864470               -1.247439   \n",
              "88092                  -0.503145  -0.864470               -1.335998   \n",
              "88093                  -0.503145   1.156779               -1.092460   \n",
              "88094                  -0.477950  -0.864470                0.877982   \n",
              "88095                  -0.503145   1.156779                0.877982   \n",
              "...                          ...        ...                     ...   \n",
              "102209                 -0.503145  -0.864470               -1.181019   \n",
              "102210                 -0.503145  -0.864470                0.877982   \n",
              "102211                 -0.503145   1.156779                0.258068   \n",
              "102212                 -0.503145   1.156779                0.877982   \n",
              "102213                 -0.503145  -0.864470                0.855842   \n",
              "\n",
              "        dst_host_srv_count  same_srv_rate  protocol_type_icmp  ...  flag_S1  \\\n",
              "88091            -1.098591      -1.719694                   0  ...        0   \n",
              "88092            -1.177300      -1.793994                   0  ...        0   \n",
              "88093            -0.941174       0.657887                   0  ...        0   \n",
              "88094             1.044027       0.657887                   0  ...        0   \n",
              "88095             1.044027       0.657887                   0  ...        0   \n",
              "...                    ...            ...                 ...  ...      ...   \n",
              "102209           -1.028628      -1.472029                   0  ...        0   \n",
              "102210            1.044027       0.657887                   1  ...        0   \n",
              "102211            0.047054       0.657887                   0  ...        0   \n",
              "102212            1.044027       0.657887                   0  ...        0   \n",
              "102213            1.017791       0.657887                   0  ...        0   \n",
              "\n",
              "        flag_S2  flag_S3  flag_SF  flag_SH  intrusion  abnormal  normal  \\\n",
              "88091         0        0        0        0          0         1       0   \n",
              "88092         0        0        0        0          0         1       0   \n",
              "88093         0        0        1        0          1         0       1   \n",
              "88094         0        0        1        0          0         1       0   \n",
              "88095         0        0        1        0          1         0       1   \n",
              "...         ...      ...      ...      ...        ...       ...     ...   \n",
              "102209        0        0        0        0          0         1       0   \n",
              "102210        0        0        1        0          0         1       0   \n",
              "102211        0        0        1        0          1         0       1   \n",
              "102212        0        0        1        0          1         0       1   \n",
              "102213        0        0        1        0          1         0       1   \n",
              "\n",
              "           label  clusterNo  \n",
              "88091   abnormal          3  \n",
              "88092   abnormal          3  \n",
              "88093     normal          3  \n",
              "88094   abnormal          2  \n",
              "88095     normal          1  \n",
              "...          ...        ...  \n",
              "102209  abnormal          3  \n",
              "102210  abnormal          2  \n",
              "102211    normal          1  \n",
              "102212    normal          1  \n",
              "102213    normal          2  \n",
              "\n",
              "[14123 rows x 94 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e1b7c9e4-c8ac-4fcd-9b58-b7bb45d13294\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>abnormal</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>88091</th>\n",
              "      <td>2.320729</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.247439</td>\n",
              "      <td>-1.098591</td>\n",
              "      <td>-1.719694</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88092</th>\n",
              "      <td>1.117716</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.335998</td>\n",
              "      <td>-1.177300</td>\n",
              "      <td>-1.793994</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88093</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>-1.092460</td>\n",
              "      <td>-0.941174</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88094</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>-0.477950</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88095</th>\n",
              "      <td>-0.214653</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102209</th>\n",
              "      <td>1.001295</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>-1.181019</td>\n",
              "      <td>-1.028628</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102210</th>\n",
              "      <td>0.044059</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>1</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102211</th>\n",
              "      <td>-0.628593</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.258068</td>\n",
              "      <td>0.047054</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102212</th>\n",
              "      <td>-0.615658</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.488011</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>1.156779</td>\n",
              "      <td>0.877982</td>\n",
              "      <td>1.044027</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102213</th>\n",
              "      <td>-0.589786</td>\n",
              "      <td>-0.514055</td>\n",
              "      <td>-0.516891</td>\n",
              "      <td>-0.513194</td>\n",
              "      <td>-0.503145</td>\n",
              "      <td>-0.864470</td>\n",
              "      <td>0.855842</td>\n",
              "      <td>1.017791</td>\n",
              "      <td>0.657887</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>normal</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>14123 rows × 94 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e1b7c9e4-c8ac-4fcd-9b58-b7bb45d13294')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e1b7c9e4-c8ac-4fcd-9b58-b7bb45d13294 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e1b7c9e4-c8ac-4fcd-9b58-b7bb45d13294');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 310
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UniqueClusters = train_data.clusterNo.unique()\n",
        "DataFrameDict = {cls : pd.DataFrame() for cls in UniqueClusters}\n",
        "for key in DataFrameDict.keys():\n",
        "    DataFrameDict[key] = train_data[:][train_data.clusterNo == key]"
      ],
      "metadata": {
        "id": "EsnQvdceb3c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrameDict[0].to_csv('bin_clusters/train1.csv')\n",
        "DataFrameDict[1].to_csv('bin_clusters/train2.csv')\n",
        "DataFrameDict[2].to_csv('bin_clusters/train3.csv')\n",
        "DataFrameDict[3].to_csv('bin_clusters/train4.csv')"
      ],
      "metadata": {
        "id": "NwWqvCrsb3c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "UniqueClusters = test_data.clusterNo.unique()\n",
        "DataFrameDict = {cls : pd.DataFrame() for cls in UniqueClusters}\n",
        "for key in DataFrameDict.keys():\n",
        "    DataFrameDict[key] = test_data[:][test_data.clusterNo == key]"
      ],
      "metadata": {
        "id": "_rjNliVPb3c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "DataFrameDict[0].to_csv('bin_clusters/test1.csv')\n",
        "DataFrameDict[1].to_csv('bin_clusters/test2.csv')\n",
        "DataFrameDict[2].to_csv('bin_clusters/test3.csv')\n",
        "DataFrameDict[3].to_csv('bin_clusters/test4.csv')"
      ],
      "metadata": {
        "id": "jNetpzyFb3c-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r bin_clusters.zip bin_clusters"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "895b5f5a-cee7-41de-b09d-2cb98798acbc",
        "id": "Vv8PI1ZVb3c-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: bin_clusters/ (stored 0%)\n",
            "  adding: bin_clusters/train1.csv (deflated 94%)\n",
            "  adding: bin_clusters/test2.csv (deflated 96%)\n",
            "  adding: bin_clusters/test4.csv (deflated 94%)\n",
            "  adding: bin_clusters/train4.csv (deflated 94%)\n",
            "  adding: bin_clusters/train3.csv (deflated 94%)\n",
            "  adding: bin_clusters/test3.csv (deflated 95%)\n",
            "  adding: bin_clusters/train2.csv (deflated 97%)\n",
            "  adding: bin_clusters/test1.csv (deflated 94%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Models on clusters"
      ],
      "metadata": {
        "id": "ocjq_79Ub3c-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!gdown 'https://drive.google.com/uc?id=1L-7PkAkdq-Ym7W3qqPtwAag_3QFxn1ct&confirm=t'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e51aa5d-d993-4205-ec84-8693bc660fd1",
        "id": "ZomhNhltb3c-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1L-7PkAkdq-Ym7W3qqPtwAag_3QFxn1ct&confirm=t\n",
            "To: /content/bin_clusters.zip\n",
            "\r  0% 0.00/1.79M [00:00<?, ?B/s]\r100% 1.79M/1.79M [00:00<00:00, 102MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf bin_clusters\n",
        "!unzip bin_clusters.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d59bf75-6b59-428f-bb2e-79ce963e2744",
        "id": "TR58C-iSb3c-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  bin_clusters.zip\n",
            "   creating: bin_clusters/\n",
            "  inflating: bin_clusters/train1.csv  \n",
            "  inflating: bin_clusters/test2.csv  \n",
            "  inflating: bin_clusters/test4.csv  \n",
            "  inflating: bin_clusters/train4.csv  \n",
            "  inflating: bin_clusters/train3.csv  \n",
            "  inflating: bin_clusters/test3.csv  \n",
            "  inflating: bin_clusters/train2.csv  \n",
            "  inflating: bin_clusters/test1.csv  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auto encoder"
      ],
      "metadata": {
        "id": "nH0Iw9Tgb3c_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 1"
      ],
      "metadata": {
        "id": "HIZlsxbIb3c_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train1.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test1.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "QH00sjh_b3c_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d4c9bac-2754-41e0-b875-d3fd177bfbe2",
        "id": "VLUDPdZNb3c_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "abnormal    18688\n",
              "normal         72\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 334
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count1 = len(test.index)"
      ],
      "metadata": {
        "id": "Dr0CL7qub3dB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913dc0f7-6866-4b45-bd19-2e2184575826",
        "id": "-6hu_bxlb3dB"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      count  srv_serror_rate  serror_rate  dst_host_serror_rate  \\\n",
              "0  0.949553         1.985588      1.98404              2.005094   \n",
              "1  1.505785         1.985588      1.98404              2.005094   \n",
              "2  0.871939         1.985588      1.98404              2.005094   \n",
              "3  1.078909         1.985588      1.98404              2.005094   \n",
              "4  0.600291         1.985588      1.98404              2.005094   \n",
              "\n",
              "   dst_host_srv_serror_rate  logged_in  dst_host_same_srv_rate  \\\n",
              "0                  2.016338   -0.86447               -1.114600   \n",
              "1                  2.016338   -0.86447               -1.247439   \n",
              "2                  2.016338   -0.86447               -1.203159   \n",
              "3                  2.016338   -0.86447               -1.225299   \n",
              "4                  2.016338   -0.86447               -1.313858   \n",
              "\n",
              "   dst_host_srv_count  same_srv_rate  protocol_type_icmp  ...  flag_S1  \\\n",
              "0           -0.958665      -1.694928                   0  ...        0   \n",
              "1           -1.107337      -1.694928                   0  ...        0   \n",
              "2           -1.054864      -1.472029                   0  ...        0   \n",
              "3           -1.072355      -1.670161                   0  ...        0   \n",
              "4           -1.168554      -1.397730                   0  ...        0   \n",
              "\n",
              "   flag_S2  flag_S3  flag_SF  flag_SH  intrusion  abnormal  normal     label  \\\n",
              "0        0        0        0        0          0         1       0  abnormal   \n",
              "1        0        0        0        0          0         1       0  abnormal   \n",
              "2        0        0        0        0          0         1       0  abnormal   \n",
              "3        0        0        0        0          0         1       0  abnormal   \n",
              "4        0        0        0        0          0         1       0  abnormal   \n",
              "\n",
              "   clusterNo  \n",
              "0          0  \n",
              "1          0  \n",
              "2          0  \n",
              "3          0  \n",
              "4          0  \n",
              "\n",
              "[5 rows x 94 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5e8b0892-4ad6-4776-bbb8-cd5f5ddb73b8\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>srv_serror_rate</th>\n",
              "      <th>serror_rate</th>\n",
              "      <th>dst_host_serror_rate</th>\n",
              "      <th>dst_host_srv_serror_rate</th>\n",
              "      <th>logged_in</th>\n",
              "      <th>dst_host_same_srv_rate</th>\n",
              "      <th>dst_host_srv_count</th>\n",
              "      <th>same_srv_rate</th>\n",
              "      <th>protocol_type_icmp</th>\n",
              "      <th>...</th>\n",
              "      <th>flag_S1</th>\n",
              "      <th>flag_S2</th>\n",
              "      <th>flag_S3</th>\n",
              "      <th>flag_SF</th>\n",
              "      <th>flag_SH</th>\n",
              "      <th>intrusion</th>\n",
              "      <th>abnormal</th>\n",
              "      <th>normal</th>\n",
              "      <th>label</th>\n",
              "      <th>clusterNo</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.949553</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>-1.114600</td>\n",
              "      <td>-0.958665</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.505785</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>-1.247439</td>\n",
              "      <td>-1.107337</td>\n",
              "      <td>-1.694928</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.871939</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>-1.203159</td>\n",
              "      <td>-1.054864</td>\n",
              "      <td>-1.472029</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.078909</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>-1.225299</td>\n",
              "      <td>-1.072355</td>\n",
              "      <td>-1.670161</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.600291</td>\n",
              "      <td>1.985588</td>\n",
              "      <td>1.98404</td>\n",
              "      <td>2.005094</td>\n",
              "      <td>2.016338</td>\n",
              "      <td>-0.86447</td>\n",
              "      <td>-1.313858</td>\n",
              "      <td>-1.168554</td>\n",
              "      <td>-1.397730</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>abnormal</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 94 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5e8b0892-4ad6-4776-bbb8-cd5f5ddb73b8')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5e8b0892-4ad6-4776-bbb8-cd5f5ddb73b8 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5e8b0892-4ad6-4776-bbb8-cd5f5ddb73b8');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 336
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['intrusion']]\n",
        "\n",
        "X_train = train.iloc[:,0:89]\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['intrusion']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.iloc[:,0:89]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7133376-a7dc-452c-c864-51a808dbb008",
        "id": "RHiqDwJWb3dC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_41\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_42 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_100 (Dense)           (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_101 (Dense)           (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f28273d3-3e61-45a1-9061-6ebcf7e27018",
        "id": "a1xsF1BJb3dC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.2775 - accuracy: 0.1193 - val_loss: 0.3009 - val_accuracy: 0.1404\n",
            "Epoch 2/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2527 - accuracy: 0.0451 - val_loss: 0.2743 - val_accuracy: 0.0319\n",
            "Epoch 3/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2412 - accuracy: 0.3628 - val_loss: 0.2730 - val_accuracy: 0.2976\n",
            "Epoch 4/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2403 - accuracy: 0.2441 - val_loss: 0.2726 - val_accuracy: 0.5205\n",
            "Epoch 5/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.2402 - accuracy: 0.4470 - val_loss: 0.2724 - val_accuracy: 0.4645\n",
            "Epoch 6/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2401 - accuracy: 0.5294 - val_loss: 0.2723 - val_accuracy: 0.4675\n",
            "Epoch 7/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.2401 - accuracy: 0.5518 - val_loss: 0.2722 - val_accuracy: 0.5416\n",
            "Epoch 8/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.2400 - accuracy: 0.6195 - val_loss: 0.2721 - val_accuracy: 0.4964\n",
            "Epoch 9/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2400 - accuracy: 0.6917 - val_loss: 0.2721 - val_accuracy: 0.5386\n",
            "Epoch 10/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2400 - accuracy: 0.7292 - val_loss: 0.2721 - val_accuracy: 0.5554\n",
            "Epoch 11/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.2400 - accuracy: 0.7563 - val_loss: 0.2720 - val_accuracy: 0.5494\n",
            "Epoch 12/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.2400 - accuracy: 0.7634 - val_loss: 0.2720 - val_accuracy: 0.5789\n",
            "Epoch 13/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2400 - accuracy: 0.7812 - val_loss: 0.2719 - val_accuracy: 0.5693\n",
            "Epoch 14/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2400 - accuracy: 0.8011 - val_loss: 0.2719 - val_accuracy: 0.5873\n",
            "Epoch 15/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2400 - accuracy: 0.8047 - val_loss: 0.2719 - val_accuracy: 0.5825\n",
            "Epoch 16/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.2400 - accuracy: 0.8241 - val_loss: 0.2718 - val_accuracy: 0.5873\n",
            "Epoch 17/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.2399 - accuracy: 0.8295 - val_loss: 0.2718 - val_accuracy: 0.5934\n",
            "Epoch 18/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.8421 - val_loss: 0.2718 - val_accuracy: 0.6169\n",
            "Epoch 19/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.2399 - accuracy: 0.8512 - val_loss: 0.2718 - val_accuracy: 0.6157\n",
            "Epoch 20/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.8598 - val_loss: 0.2717 - val_accuracy: 0.6066\n",
            "Epoch 21/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.8648 - val_loss: 0.2717 - val_accuracy: 0.6337\n",
            "Epoch 22/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.8707 - val_loss: 0.2717 - val_accuracy: 0.6006\n",
            "Epoch 23/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.8837 - val_loss: 0.2717 - val_accuracy: 0.6307\n",
            "Epoch 24/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.8851 - val_loss: 0.2717 - val_accuracy: 0.6054\n",
            "Epoch 25/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9050 - val_loss: 0.2717 - val_accuracy: 0.6036\n",
            "Epoch 26/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9095 - val_loss: 0.2717 - val_accuracy: 0.6066\n",
            "Epoch 27/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2399 - accuracy: 0.9193 - val_loss: 0.2716 - val_accuracy: 0.6012\n",
            "Epoch 28/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2399 - accuracy: 0.9253 - val_loss: 0.2716 - val_accuracy: 0.6012\n",
            "Epoch 29/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.9278 - val_loss: 0.2716 - val_accuracy: 0.6000\n",
            "Epoch 30/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.9282 - val_loss: 0.2716 - val_accuracy: 0.5982\n",
            "Epoch 31/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.2399 - accuracy: 0.9312 - val_loss: 0.2716 - val_accuracy: 0.6114\n",
            "Epoch 32/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.2399 - accuracy: 0.9287 - val_loss: 0.2716 - val_accuracy: 0.6030\n",
            "Epoch 33/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2399 - accuracy: 0.9328 - val_loss: 0.2716 - val_accuracy: 0.6120\n",
            "Epoch 34/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.2399 - accuracy: 0.9343 - val_loss: 0.2716 - val_accuracy: 0.6072\n",
            "Epoch 35/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.2399 - accuracy: 0.9320 - val_loss: 0.2716 - val_accuracy: 0.6139\n",
            "Epoch 36/100\n",
            "38/38 [==============================] - 1s 23ms/step - loss: 0.2399 - accuracy: 0.9365 - val_loss: 0.2716 - val_accuracy: 0.6127\n",
            "Epoch 37/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2399 - accuracy: 0.9357 - val_loss: 0.2716 - val_accuracy: 0.6428\n",
            "Epoch 38/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.2399 - accuracy: 0.9397 - val_loss: 0.2716 - val_accuracy: 0.6151\n",
            "Epoch 39/100\n",
            "38/38 [==============================] - 1s 21ms/step - loss: 0.2399 - accuracy: 0.9390 - val_loss: 0.2716 - val_accuracy: 0.6066\n",
            "Epoch 40/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9396 - val_loss: 0.2716 - val_accuracy: 0.6066\n",
            "Epoch 41/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9432 - val_loss: 0.2716 - val_accuracy: 0.6078\n",
            "Epoch 42/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9449 - val_loss: 0.2716 - val_accuracy: 0.6078\n",
            "Epoch 43/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9446 - val_loss: 0.2716 - val_accuracy: 0.6476\n",
            "Epoch 44/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9426 - val_loss: 0.2716 - val_accuracy: 0.6072\n",
            "Epoch 45/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2399 - accuracy: 0.9422 - val_loss: 0.2715 - val_accuracy: 0.6090\n",
            "Epoch 46/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9463 - val_loss: 0.2715 - val_accuracy: 0.6482\n",
            "Epoch 47/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.9453 - val_loss: 0.2715 - val_accuracy: 0.6458\n",
            "Epoch 48/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9416 - val_loss: 0.2715 - val_accuracy: 0.6108\n",
            "Epoch 49/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9472 - val_loss: 0.2715 - val_accuracy: 0.6139\n",
            "Epoch 50/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.2399 - accuracy: 0.9528 - val_loss: 0.2715 - val_accuracy: 0.6476\n",
            "Epoch 51/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9587 - val_loss: 0.2715 - val_accuracy: 0.6524\n",
            "Epoch 52/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9612 - val_loss: 0.2715 - val_accuracy: 0.6114\n",
            "Epoch 53/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9665 - val_loss: 0.2715 - val_accuracy: 0.6452\n",
            "Epoch 54/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2399 - accuracy: 0.9683 - val_loss: 0.2715 - val_accuracy: 0.6482\n",
            "Epoch 55/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.2399 - accuracy: 0.9705 - val_loss: 0.2715 - val_accuracy: 0.6506\n",
            "Epoch 56/100\n",
            "38/38 [==============================] - 1s 19ms/step - loss: 0.2399 - accuracy: 0.9705 - val_loss: 0.2715 - val_accuracy: 0.6488\n",
            "Epoch 57/100\n",
            "38/38 [==============================] - 1s 22ms/step - loss: 0.2399 - accuracy: 0.9733 - val_loss: 0.2715 - val_accuracy: 0.6512\n",
            "Epoch 58/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.2399 - accuracy: 0.9779 - val_loss: 0.2715 - val_accuracy: 0.6506\n",
            "Epoch 59/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2399 - accuracy: 0.9797 - val_loss: 0.2715 - val_accuracy: 0.6530\n",
            "Epoch 60/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.9807 - val_loss: 0.2715 - val_accuracy: 0.6506\n",
            "Epoch 61/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.2399 - accuracy: 0.9822 - val_loss: 0.2715 - val_accuracy: 0.6536\n",
            "Epoch 62/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.2399 - accuracy: 0.9813 - val_loss: 0.2715 - val_accuracy: 0.6506\n",
            "Epoch 63/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9820 - val_loss: 0.2715 - val_accuracy: 0.6530\n",
            "Epoch 64/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9826 - val_loss: 0.2715 - val_accuracy: 0.6482\n",
            "Epoch 65/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9821 - val_loss: 0.2715 - val_accuracy: 0.6500\n",
            "Epoch 66/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9824 - val_loss: 0.2715 - val_accuracy: 0.6488\n",
            "Epoch 67/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9819 - val_loss: 0.2715 - val_accuracy: 0.6506\n",
            "Epoch 68/100\n",
            "38/38 [==============================] - 0s 9ms/step - loss: 0.2399 - accuracy: 0.9823 - val_loss: 0.2715 - val_accuracy: 0.6488\n",
            "Epoch 69/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9832 - val_loss: 0.2715 - val_accuracy: 0.6512\n",
            "Epoch 70/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9824 - val_loss: 0.2715 - val_accuracy: 0.6440\n",
            "Epoch 71/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.2399 - accuracy: 0.9826 - val_loss: 0.2715 - val_accuracy: 0.6440\n",
            "Epoch 72/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.2399 - accuracy: 0.9821 - val_loss: 0.2715 - val_accuracy: 0.6458\n",
            "Epoch 73/100\n",
            "38/38 [==============================] - 1s 17ms/step - loss: 0.2399 - accuracy: 0.9820 - val_loss: 0.2715 - val_accuracy: 0.6470\n",
            "Epoch 74/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.9814 - val_loss: 0.2715 - val_accuracy: 0.6464\n",
            "Epoch 75/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.9822 - val_loss: 0.2715 - val_accuracy: 0.6488\n",
            "Epoch 76/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9814 - val_loss: 0.2715 - val_accuracy: 0.6476\n",
            "Epoch 77/100\n",
            "38/38 [==============================] - 0s 13ms/step - loss: 0.2399 - accuracy: 0.9825 - val_loss: 0.2715 - val_accuracy: 0.6482\n",
            "Epoch 78/100\n",
            "38/38 [==============================] - 0s 11ms/step - loss: 0.2399 - accuracy: 0.9826 - val_loss: 0.2715 - val_accuracy: 0.6392\n",
            "Epoch 79/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9817 - val_loss: 0.2715 - val_accuracy: 0.6398\n",
            "Epoch 80/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2399 - accuracy: 0.9814 - val_loss: 0.2715 - val_accuracy: 0.6422\n",
            "Epoch 81/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.2399 - accuracy: 0.9818 - val_loss: 0.2715 - val_accuracy: 0.6392\n",
            "Epoch 82/100\n",
            "38/38 [==============================] - 1s 20ms/step - loss: 0.2399 - accuracy: 0.9824 - val_loss: 0.2715 - val_accuracy: 0.6458\n",
            "Epoch 83/100\n",
            "38/38 [==============================] - 1s 18ms/step - loss: 0.2399 - accuracy: 0.9815 - val_loss: 0.2715 - val_accuracy: 0.6476\n",
            "Epoch 84/100\n",
            "38/38 [==============================] - 1s 15ms/step - loss: 0.2399 - accuracy: 0.9817 - val_loss: 0.2715 - val_accuracy: 0.6446\n",
            "Epoch 85/100\n",
            "38/38 [==============================] - 1s 14ms/step - loss: 0.2399 - accuracy: 0.9823 - val_loss: 0.2715 - val_accuracy: 0.6404\n",
            "Epoch 86/100\n",
            "38/38 [==============================] - 1s 16ms/step - loss: 0.2399 - accuracy: 0.9816 - val_loss: 0.2715 - val_accuracy: 0.6398\n",
            "Epoch 87/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9817 - val_loss: 0.2715 - val_accuracy: 0.6398\n",
            "Epoch 88/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9811 - val_loss: 0.2715 - val_accuracy: 0.6482\n",
            "Epoch 89/100\n",
            "38/38 [==============================] - 0s 10ms/step - loss: 0.2399 - accuracy: 0.9812 - val_loss: 0.2715 - val_accuracy: 0.6380\n",
            "Epoch 90/100\n",
            "38/38 [==============================] - 1s 13ms/step - loss: 0.2399 - accuracy: 0.9808 - val_loss: 0.2715 - val_accuracy: 0.6398\n",
            "Epoch 91/100\n",
            "38/38 [==============================] - 0s 12ms/step - loss: 0.2399 - accuracy: 0.9805 - val_loss: 0.2715 - val_accuracy: 0.6361\n",
            "Epoch 92/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9801 - val_loss: 0.2715 - val_accuracy: 0.6283\n",
            "Epoch 93/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9797 - val_loss: 0.2715 - val_accuracy: 0.6398\n",
            "Epoch 94/100\n",
            "38/38 [==============================] - 0s 7ms/step - loss: 0.2399 - accuracy: 0.9805 - val_loss: 0.2715 - val_accuracy: 0.6373\n",
            "Epoch 95/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9797 - val_loss: 0.2715 - val_accuracy: 0.6373\n",
            "Epoch 96/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9808 - val_loss: 0.2715 - val_accuracy: 0.6355\n",
            "Epoch 97/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9810 - val_loss: 0.2715 - val_accuracy: 0.6331\n",
            "Epoch 98/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9808 - val_loss: 0.2715 - val_accuracy: 0.6428\n",
            "Epoch 99/100\n",
            "38/38 [==============================] - 0s 6ms/step - loss: 0.2399 - accuracy: 0.9798 - val_loss: 0.2715 - val_accuracy: 0.6361\n",
            "Epoch 100/100\n",
            "38/38 [==============================] - 0s 5ms/step - loss: 0.2399 - accuracy: 0.9807 - val_loss: 0.2715 - val_accuracy: 0.6349\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(48, activation=\"sigmoid\")(i_layer)   \n",
        "#fvector = Dense(24, activation='tanh')(fvector)                 \n",
        "#doutput layer\n",
        "o_layer = Dense(1, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f281818a-bad4-4804-d074-febae0124955",
        "id": "okXHlZadb3dC"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 1ms/step\n",
            "Model: \"model_42\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_43 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_102 (Dense)           (None, 48)                4320      \n",
            "                                                                 \n",
            " dense_103 (Dense)           (None, 1)                 49        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,369\n",
            "Trainable params: 4,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bb8043d-45f7-4bdd-aff5-047136bcb22e",
        "id": "OluCEQfBb3dD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "2/2 [==============================] - 2s 243ms/step - loss: 0.0903 - accuracy: 0.9992 - val_loss: 0.0847 - val_accuracy: 1.0000\n",
            "Epoch 2/200\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0833 - accuracy: 0.9992 - val_loss: 0.0780 - val_accuracy: 1.0000\n",
            "Epoch 3/200\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0768 - accuracy: 0.9992 - val_loss: 0.0718 - val_accuracy: 1.0000\n",
            "Epoch 4/200\n",
            "2/2 [==============================] - 0s 68ms/step - loss: 0.0707 - accuracy: 0.9992 - val_loss: 0.0661 - val_accuracy: 1.0000\n",
            "Epoch 5/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0651 - accuracy: 0.9992 - val_loss: 0.0608 - val_accuracy: 1.0000\n",
            "Epoch 6/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0599 - accuracy: 0.9992 - val_loss: 0.0559 - val_accuracy: 1.0000\n",
            "Epoch 7/200\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0552 - accuracy: 0.9992 - val_loss: 0.0514 - val_accuracy: 1.0000\n",
            "Epoch 8/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0508 - accuracy: 0.9992 - val_loss: 0.0473 - val_accuracy: 1.0000\n",
            "Epoch 9/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0468 - accuracy: 0.9992 - val_loss: 0.0436 - val_accuracy: 1.0000\n",
            "Epoch 10/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0432 - accuracy: 0.9992 - val_loss: 0.0402 - val_accuracy: 1.0000\n",
            "Epoch 11/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0399 - accuracy: 0.9992 - val_loss: 0.0371 - val_accuracy: 1.0000\n",
            "Epoch 12/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0369 - accuracy: 0.9992 - val_loss: 0.0344 - val_accuracy: 1.0000\n",
            "Epoch 13/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0342 - accuracy: 0.9992 - val_loss: 0.0318 - val_accuracy: 1.0000\n",
            "Epoch 14/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0317 - accuracy: 0.9992 - val_loss: 0.0295 - val_accuracy: 1.0000\n",
            "Epoch 15/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0295 - accuracy: 0.9992 - val_loss: 0.0275 - val_accuracy: 1.0000\n",
            "Epoch 16/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0275 - accuracy: 0.9992 - val_loss: 0.0256 - val_accuracy: 1.0000\n",
            "Epoch 17/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0256 - accuracy: 0.9992 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
            "Epoch 18/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0240 - accuracy: 0.9992 - val_loss: 0.0223 - val_accuracy: 1.0000\n",
            "Epoch 19/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0225 - accuracy: 0.9992 - val_loss: 0.0209 - val_accuracy: 1.0000\n",
            "Epoch 20/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0211 - accuracy: 0.9992 - val_loss: 0.0197 - val_accuracy: 1.0000\n",
            "Epoch 21/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0199 - accuracy: 0.9992 - val_loss: 0.0185 - val_accuracy: 1.0000\n",
            "Epoch 22/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0188 - accuracy: 0.9992 - val_loss: 0.0174 - val_accuracy: 1.0000\n",
            "Epoch 23/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0177 - accuracy: 0.9992 - val_loss: 0.0165 - val_accuracy: 1.0000\n",
            "Epoch 24/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0168 - accuracy: 0.9992 - val_loss: 0.0156 - val_accuracy: 1.0000\n",
            "Epoch 25/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0159 - accuracy: 0.9992 - val_loss: 0.0148 - val_accuracy: 1.0000\n",
            "Epoch 26/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0151 - accuracy: 0.9992 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
            "Epoch 27/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0144 - accuracy: 0.9992 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
            "Epoch 28/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0138 - accuracy: 0.9992 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
            "Epoch 29/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0131 - accuracy: 0.9992 - val_loss: 0.0121 - val_accuracy: 1.0000\n",
            "Epoch 30/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0126 - accuracy: 0.9992 - val_loss: 0.0116 - val_accuracy: 1.0000\n",
            "Epoch 31/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0120 - accuracy: 0.9992 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
            "Epoch 32/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0116 - accuracy: 0.9992 - val_loss: 0.0106 - val_accuracy: 1.0000\n",
            "Epoch 33/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0111 - accuracy: 0.9992 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
            "Epoch 34/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0107 - accuracy: 0.9992 - val_loss: 0.0098 - val_accuracy: 1.0000\n",
            "Epoch 35/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0103 - accuracy: 0.9992 - val_loss: 0.0094 - val_accuracy: 1.0000\n",
            "Epoch 36/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0099 - accuracy: 0.9992 - val_loss: 0.0090 - val_accuracy: 1.0000\n",
            "Epoch 37/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0096 - accuracy: 0.9992 - val_loss: 0.0087 - val_accuracy: 1.0000\n",
            "Epoch 38/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0092 - accuracy: 0.9992 - val_loss: 0.0084 - val_accuracy: 1.0000\n",
            "Epoch 39/200\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0089 - accuracy: 0.9992 - val_loss: 0.0081 - val_accuracy: 1.0000\n",
            "Epoch 40/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0087 - accuracy: 0.9992 - val_loss: 0.0078 - val_accuracy: 1.0000\n",
            "Epoch 41/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0084 - accuracy: 0.9992 - val_loss: 0.0076 - val_accuracy: 1.0000\n",
            "Epoch 42/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0081 - accuracy: 0.9992 - val_loss: 0.0073 - val_accuracy: 1.0000\n",
            "Epoch 43/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0079 - accuracy: 0.9992 - val_loss: 0.0071 - val_accuracy: 1.0000\n",
            "Epoch 44/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0077 - accuracy: 0.9992 - val_loss: 0.0069 - val_accuracy: 1.0000\n",
            "Epoch 45/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0074 - accuracy: 0.9992 - val_loss: 0.0067 - val_accuracy: 1.0000\n",
            "Epoch 46/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0072 - accuracy: 0.9992 - val_loss: 0.0065 - val_accuracy: 1.0000\n",
            "Epoch 47/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0070 - accuracy: 0.9992 - val_loss: 0.0063 - val_accuracy: 1.0000\n",
            "Epoch 48/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0069 - accuracy: 0.9992 - val_loss: 0.0061 - val_accuracy: 1.0000\n",
            "Epoch 49/200\n",
            "2/2 [==============================] - 0s 37ms/step - loss: 0.0067 - accuracy: 0.9992 - val_loss: 0.0059 - val_accuracy: 1.0000\n",
            "Epoch 50/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0065 - accuracy: 0.9992 - val_loss: 0.0057 - val_accuracy: 1.0000\n",
            "Epoch 51/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0063 - accuracy: 0.9992 - val_loss: 0.0056 - val_accuracy: 1.0000\n",
            "Epoch 52/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0062 - accuracy: 0.9992 - val_loss: 0.0054 - val_accuracy: 1.0000\n",
            "Epoch 53/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0060 - accuracy: 0.9992 - val_loss: 0.0053 - val_accuracy: 1.0000\n",
            "Epoch 54/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0059 - accuracy: 0.9992 - val_loss: 0.0052 - val_accuracy: 1.0000\n",
            "Epoch 55/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0058 - accuracy: 0.9992 - val_loss: 0.0050 - val_accuracy: 1.0000\n",
            "Epoch 56/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0056 - accuracy: 0.9992 - val_loss: 0.0049 - val_accuracy: 1.0000\n",
            "Epoch 57/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0055 - accuracy: 0.9992 - val_loss: 0.0048 - val_accuracy: 1.0000\n",
            "Epoch 58/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0054 - accuracy: 0.9992 - val_loss: 0.0047 - val_accuracy: 1.0000\n",
            "Epoch 59/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0053 - accuracy: 0.9992 - val_loss: 0.0046 - val_accuracy: 1.0000\n",
            "Epoch 60/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0052 - accuracy: 0.9992 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
            "Epoch 61/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0051 - accuracy: 0.9992 - val_loss: 0.0043 - val_accuracy: 1.0000\n",
            "Epoch 62/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0050 - accuracy: 0.9992 - val_loss: 0.0042 - val_accuracy: 1.0000\n",
            "Epoch 63/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0049 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 64/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0041 - val_accuracy: 1.0000\n",
            "Epoch 65/200\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0047 - accuracy: 0.9992 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 66/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0046 - accuracy: 0.9992 - val_loss: 0.0039 - val_accuracy: 1.0000\n",
            "Epoch 67/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0045 - accuracy: 0.9992 - val_loss: 0.0038 - val_accuracy: 1.0000\n",
            "Epoch 68/200\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0037 - val_accuracy: 1.0000\n",
            "Epoch 69/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0044 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 70/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0043 - accuracy: 0.9992 - val_loss: 0.0036 - val_accuracy: 1.0000\n",
            "Epoch 71/200\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0042 - accuracy: 0.9992 - val_loss: 0.0035 - val_accuracy: 1.0000\n",
            "Epoch 72/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 73/200\n",
            "2/2 [==============================] - 0s 73ms/step - loss: 0.0041 - accuracy: 0.9992 - val_loss: 0.0034 - val_accuracy: 1.0000\n",
            "Epoch 74/200\n",
            "2/2 [==============================] - 0s 78ms/step - loss: 0.0040 - accuracy: 0.9992 - val_loss: 0.0033 - val_accuracy: 1.0000\n",
            "Epoch 75/200\n",
            "2/2 [==============================] - 0s 77ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 76/200\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0039 - accuracy: 0.9992 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
            "Epoch 77/200\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0031 - val_accuracy: 1.0000\n",
            "Epoch 78/200\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0038 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 79/200\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0037 - accuracy: 0.9992 - val_loss: 0.0030 - val_accuracy: 1.0000\n",
            "Epoch 80/200\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 81/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0036 - accuracy: 0.9992 - val_loss: 0.0029 - val_accuracy: 1.0000\n",
            "Epoch 82/200\n",
            "2/2 [==============================] - 0s 75ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 83/200\n",
            "2/2 [==============================] - 0s 82ms/step - loss: 0.0035 - accuracy: 0.9992 - val_loss: 0.0028 - val_accuracy: 1.0000\n",
            "Epoch 84/200\n",
            "2/2 [==============================] - 0s 72ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 85/200\n",
            "2/2 [==============================] - 0s 88ms/step - loss: 0.0034 - accuracy: 0.9992 - val_loss: 0.0027 - val_accuracy: 1.0000\n",
            "Epoch 86/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 87/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
            "Epoch 88/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0033 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 89/200\n",
            "2/2 [==============================] - 0s 81ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 90/200\n",
            "2/2 [==============================] - 0s 100ms/step - loss: 0.0032 - accuracy: 0.9992 - val_loss: 0.0025 - val_accuracy: 1.0000\n",
            "Epoch 91/200\n",
            "2/2 [==============================] - 0s 80ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 92/200\n",
            "2/2 [==============================] - 0s 56ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0024 - val_accuracy: 1.0000\n",
            "Epoch 93/200\n",
            "2/2 [==============================] - 0s 74ms/step - loss: 0.0031 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 94/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 95/200\n",
            "2/2 [==============================] - 0s 58ms/step - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0023 - val_accuracy: 1.0000\n",
            "Epoch 96/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 97/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 98/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0029 - accuracy: 0.9992 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
            "Epoch 99/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 100/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 101/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0028 - accuracy: 0.9992 - val_loss: 0.0021 - val_accuracy: 1.0000\n",
            "Epoch 102/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 103/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 104/200\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 105/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0027 - accuracy: 0.9992 - val_loss: 0.0020 - val_accuracy: 1.0000\n",
            "Epoch 106/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 107/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 108/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0019 - val_accuracy: 1.0000\n",
            "Epoch 109/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0026 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 110/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 111/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 112/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0018 - val_accuracy: 1.0000\n",
            "Epoch 113/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0025 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 114/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 115/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 116/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 117/200\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0024 - accuracy: 0.9992 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
            "Epoch 118/200\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 119/200\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 120/200\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 121/200\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 122/200\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0023 - accuracy: 0.9992 - val_loss: 0.0016 - val_accuracy: 1.0000\n",
            "Epoch 123/200\n",
            "2/2 [==============================] - 0s 64ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 124/200\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 125/200\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 126/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 127/200\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
            "Epoch 128/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0022 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 129/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 130/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 131/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 132/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 133/200\n",
            "2/2 [==============================] - 0s 70ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0014 - val_accuracy: 1.0000\n",
            "Epoch 134/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0021 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 135/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 136/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 137/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 138/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 139/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 140/200\n",
            "2/2 [==============================] - 0s 69ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0013 - val_accuracy: 1.0000\n",
            "Epoch 141/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0020 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 142/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 143/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 144/200\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 145/200\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 146/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 147/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 148/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0012 - val_accuracy: 1.0000\n",
            "Epoch 149/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0019 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 150/200\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 151/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 152/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 153/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 154/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 155/200\n",
            "2/2 [==============================] - 0s 60ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 156/200\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 157/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 158/200\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0018 - accuracy: 0.9992 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 159/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 160/200\n",
            "2/2 [==============================] - 0s 66ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 161/200\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 162/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 0.0010 - val_accuracy: 1.0000\n",
            "Epoch 163/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 9.9362e-04 - val_accuracy: 1.0000\n",
            "Epoch 164/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 9.8414e-04 - val_accuracy: 1.0000\n",
            "Epoch 165/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 9.7480e-04 - val_accuracy: 1.0000\n",
            "Epoch 166/200\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 9.6557e-04 - val_accuracy: 1.0000\n",
            "Epoch 167/200\n",
            "2/2 [==============================] - 0s 59ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 9.5649e-04 - val_accuracy: 1.0000\n",
            "Epoch 168/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 9.4755e-04 - val_accuracy: 1.0000\n",
            "Epoch 169/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0017 - accuracy: 0.9992 - val_loss: 9.3875e-04 - val_accuracy: 1.0000\n",
            "Epoch 170/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 9.3007e-04 - val_accuracy: 1.0000\n",
            "Epoch 171/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 9.2153e-04 - val_accuracy: 1.0000\n",
            "Epoch 172/200\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 9.1312e-04 - val_accuracy: 1.0000\n",
            "Epoch 173/200\n",
            "2/2 [==============================] - 0s 61ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 9.0482e-04 - val_accuracy: 1.0000\n",
            "Epoch 174/200\n",
            "2/2 [==============================] - 0s 38ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.9665e-04 - val_accuracy: 1.0000\n",
            "Epoch 175/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.8858e-04 - val_accuracy: 1.0000\n",
            "Epoch 176/200\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.8062e-04 - val_accuracy: 1.0000\n",
            "Epoch 177/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.7279e-04 - val_accuracy: 1.0000\n",
            "Epoch 178/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.6506e-04 - val_accuracy: 1.0000\n",
            "Epoch 179/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.5744e-04 - val_accuracy: 1.0000\n",
            "Epoch 180/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.4993e-04 - val_accuracy: 1.0000\n",
            "Epoch 181/200\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0016 - accuracy: 0.9992 - val_loss: 8.4254e-04 - val_accuracy: 1.0000\n",
            "Epoch 182/200\n",
            "2/2 [==============================] - 0s 67ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.3524e-04 - val_accuracy: 1.0000\n",
            "Epoch 183/200\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.2804e-04 - val_accuracy: 1.0000\n",
            "Epoch 184/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.2092e-04 - val_accuracy: 1.0000\n",
            "Epoch 185/200\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.1391e-04 - val_accuracy: 1.0000\n",
            "Epoch 186/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.0699e-04 - val_accuracy: 1.0000\n",
            "Epoch 187/200\n",
            "2/2 [==============================] - 0s 39ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 8.0016e-04 - val_accuracy: 1.0000\n",
            "Epoch 188/200\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.9342e-04 - val_accuracy: 1.0000\n",
            "Epoch 189/200\n",
            "2/2 [==============================] - 0s 65ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.8676e-04 - val_accuracy: 1.0000\n",
            "Epoch 190/200\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.8020e-04 - val_accuracy: 1.0000\n",
            "Epoch 191/200\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.7371e-04 - val_accuracy: 1.0000\n",
            "Epoch 192/200\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.6733e-04 - val_accuracy: 1.0000\n",
            "Epoch 193/200\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.6101e-04 - val_accuracy: 1.0000\n",
            "Epoch 194/200\n",
            "2/2 [==============================] - 0s 63ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.5479e-04 - val_accuracy: 1.0000\n",
            "Epoch 195/200\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.4863e-04 - val_accuracy: 1.0000\n",
            "Epoch 196/200\n",
            "2/2 [==============================] - 0s 62ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.4257e-04 - val_accuracy: 1.0000\n",
            "Epoch 197/200\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 0.9992 - val_loss: 7.3657e-04 - val_accuracy: 1.0000\n",
            "Epoch 198/200\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 7.3066e-04 - val_accuracy: 1.0000\n",
            "Epoch 199/200\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 7.2483e-04 - val_accuracy: 1.0000\n",
            "Epoch 200/200\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.0014 - accuracy: 0.9992 - val_loss: 7.1905e-04 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8bf8b18-128b-4764-e46b-3312d75e96c3",
        "id": "qvO6dXfUb3dD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 2ms/step - loss: 6.5503e-04 - accuracy: 0.9994\n",
            "Test results - Loss: 0.0006550265825353563 - Accuracy: 99.93975758552551%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy1_1 = test_results[1]\n",
        "y_pred1_1 = np.where(ae_classifier.predict(X_test).ravel()>=0.5,1,0)\n",
        "y_test1 = y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CoPBSZ2xb3dD",
        "outputId": "98678cc1-2e8d-47f1-f11d-030850d6cbe9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 2"
      ],
      "metadata": {
        "id": "jSRKqp0hb3dD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train2.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test2.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "4wc0uVoNb3dD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc4f8246-3403-4acb-ce82-cd0eb276e6af",
        "id": "DIm-Rx-Lb3dE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "normal      36815\n",
              "abnormal      490\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 344
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count2 = len(test.index)"
      ],
      "metadata": {
        "id": "BxZ58v3Ab3dE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['intrusion']]\n",
        "\n",
        "X_train = train.iloc[:,0:89]\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['intrusion']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.iloc[:,0:89]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59e6c0c2-89b8-4d44-84e0-137277749314",
        "id": "O0BlUQSfb3dE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_43\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_44 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_104 (Dense)           (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_105 (Dense)           (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1cd3405-3e32-4bc8-d2aa-2fe12be76d2f",
        "id": "_up9n3czb3dF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0808 - accuracy: 0.9576 - val_loss: 0.0675 - val_accuracy: 0.9982\n",
            "Epoch 2/100\n",
            "75/75 [==============================] - 1s 12ms/step - loss: 0.0683 - accuracy: 0.9840 - val_loss: 0.0651 - val_accuracy: 0.9681\n",
            "Epoch 3/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0676 - accuracy: 0.9908 - val_loss: 0.0647 - val_accuracy: 0.9982\n",
            "Epoch 4/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0675 - accuracy: 0.9908 - val_loss: 0.0646 - val_accuracy: 0.9982\n",
            "Epoch 5/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0675 - accuracy: 0.9915 - val_loss: 0.0646 - val_accuracy: 0.9982\n",
            "Epoch 6/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9922 - val_loss: 0.0646 - val_accuracy: 0.9982\n",
            "Epoch 7/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9931 - val_loss: 0.0646 - val_accuracy: 0.9982\n",
            "Epoch 8/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0675 - accuracy: 0.9931 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 9/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0675 - accuracy: 0.9932 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 10/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0675 - accuracy: 0.9933 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 11/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9934 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 12/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9935 - val_loss: 0.0645 - val_accuracy: 0.9982\n",
            "Epoch 13/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9935 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 14/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9935 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 15/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9935 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 16/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9935 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 17/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9935 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 18/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 19/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 20/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 21/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 22/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 23/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 24/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 25/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 26/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 27/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 28/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 29/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 30/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 31/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 32/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 33/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 34/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 35/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 36/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 37/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 38/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 39/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9936 - val_loss: 0.0644 - val_accuracy: 0.9982\n",
            "Epoch 40/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9947 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 41/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9947 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 42/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9947 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 43/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 44/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 45/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 46/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 47/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 48/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 49/100\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 50/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 51/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 52/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 53/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 54/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 55/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 56/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 57/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 58/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 59/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 60/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 61/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 62/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 63/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 64/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 65/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 66/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 67/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 68/100\n",
            "75/75 [==============================] - 0s 7ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 69/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 70/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 71/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 72/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 73/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 74/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 75/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 76/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 77/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 78/100\n",
            "75/75 [==============================] - 1s 8ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 79/100\n",
            "75/75 [==============================] - 1s 9ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 80/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 81/100\n",
            "75/75 [==============================] - 1s 10ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 82/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 83/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 84/100\n",
            "75/75 [==============================] - 1s 7ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 85/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 86/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 87/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 88/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 89/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 90/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 91/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 92/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 93/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 94/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 95/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 96/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 97/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 98/100\n",
            "75/75 [==============================] - 0s 5ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 99/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n",
            "Epoch 100/100\n",
            "75/75 [==============================] - 0s 6ms/step - loss: 0.0674 - accuracy: 0.9949 - val_loss: 0.0644 - val_accuracy: 0.9986\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(48, activation=\"sigmoid\")(i_layer)   \n",
        "#fvector = Dense(24, activation='tanh')(fvector)                 \n",
        "#doutput layer\n",
        "o_layer = Dense(1, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2578f5a4-3ae3-4579-cab5-29219f52debc",
        "id": "_e6Er4zNb3dF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 1ms/step\n",
            "Model: \"model_44\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_45 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_106 (Dense)           (None, 48)                4320      \n",
            "                                                                 \n",
            " dense_107 (Dense)           (None, 1)                 49        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,369\n",
            "Trainable params: 4,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52b60e57-a9ee-4b1a-eba6-cf47ad6a65b6",
        "id": "a4rndPbyb3dF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 1s 44ms/step - loss: 0.2491 - accuracy: 0.5791 - val_loss: 0.2337 - val_accuracy: 0.7797\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.2275 - accuracy: 0.7725 - val_loss: 0.2143 - val_accuracy: 0.7797\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.2100 - accuracy: 0.7725 - val_loss: 0.1997 - val_accuracy: 0.7797\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1977 - accuracy: 0.7725 - val_loss: 0.1891 - val_accuracy: 0.7797\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1887 - accuracy: 0.7725 - val_loss: 0.1821 - val_accuracy: 0.7797\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1830 - accuracy: 0.7725 - val_loss: 0.1775 - val_accuracy: 0.7797\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1794 - accuracy: 0.7725 - val_loss: 0.1747 - val_accuracy: 0.7797\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1773 - accuracy: 0.7725 - val_loss: 0.1731 - val_accuracy: 0.7797\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1761 - accuracy: 0.7725 - val_loss: 0.1720 - val_accuracy: 0.7797\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1753 - accuracy: 0.7725 - val_loss: 0.1713 - val_accuracy: 0.7797\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1746 - accuracy: 0.7725 - val_loss: 0.1707 - val_accuracy: 0.7797\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1742 - accuracy: 0.7725 - val_loss: 0.1702 - val_accuracy: 0.7797\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1738 - accuracy: 0.7725 - val_loss: 0.1698 - val_accuracy: 0.7797\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1734 - accuracy: 0.7725 - val_loss: 0.1695 - val_accuracy: 0.7797\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 22ms/step - loss: 0.1731 - accuracy: 0.7725 - val_loss: 0.1691 - val_accuracy: 0.7797\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1728 - accuracy: 0.7725 - val_loss: 0.1688 - val_accuracy: 0.7797\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1724 - accuracy: 0.7725 - val_loss: 0.1684 - val_accuracy: 0.7797\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1721 - accuracy: 0.7725 - val_loss: 0.1681 - val_accuracy: 0.7797\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1717 - accuracy: 0.7725 - val_loss: 0.1677 - val_accuracy: 0.7797\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1713 - accuracy: 0.7725 - val_loss: 0.1674 - val_accuracy: 0.7797\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1710 - accuracy: 0.7725 - val_loss: 0.1670 - val_accuracy: 0.7797\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1706 - accuracy: 0.7725 - val_loss: 0.1666 - val_accuracy: 0.7797\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1702 - accuracy: 0.7725 - val_loss: 0.1663 - val_accuracy: 0.7797\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1698 - accuracy: 0.7725 - val_loss: 0.1659 - val_accuracy: 0.7797\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1694 - accuracy: 0.7725 - val_loss: 0.1655 - val_accuracy: 0.7797\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1690 - accuracy: 0.7725 - val_loss: 0.1651 - val_accuracy: 0.7797\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.1686 - accuracy: 0.7725 - val_loss: 0.1647 - val_accuracy: 0.7797\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.1682 - accuracy: 0.7725 - val_loss: 0.1643 - val_accuracy: 0.7797\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1678 - accuracy: 0.7725 - val_loss: 0.1638 - val_accuracy: 0.7797\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.1674 - accuracy: 0.7725 - val_loss: 0.1634 - val_accuracy: 0.7797\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1670 - accuracy: 0.7725 - val_loss: 0.1630 - val_accuracy: 0.7797\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.1666 - accuracy: 0.7725 - val_loss: 0.1626 - val_accuracy: 0.7797\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1662 - accuracy: 0.7725 - val_loss: 0.1622 - val_accuracy: 0.7797\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1658 - accuracy: 0.7725 - val_loss: 0.1618 - val_accuracy: 0.7797\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1653 - accuracy: 0.7725 - val_loss: 0.1613 - val_accuracy: 0.7797\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1649 - accuracy: 0.7725 - val_loss: 0.1609 - val_accuracy: 0.7797\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1644 - accuracy: 0.7725 - val_loss: 0.1605 - val_accuracy: 0.7797\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1640 - accuracy: 0.7725 - val_loss: 0.1601 - val_accuracy: 0.7797\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1635 - accuracy: 0.7725 - val_loss: 0.1596 - val_accuracy: 0.7797\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1630 - accuracy: 0.7725 - val_loss: 0.1592 - val_accuracy: 0.7797\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1626 - accuracy: 0.7725 - val_loss: 0.1587 - val_accuracy: 0.7797\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1621 - accuracy: 0.7725 - val_loss: 0.1582 - val_accuracy: 0.7797\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1616 - accuracy: 0.7725 - val_loss: 0.1578 - val_accuracy: 0.7797\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1611 - accuracy: 0.7725 - val_loss: 0.1572 - val_accuracy: 0.7797\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1606 - accuracy: 0.7725 - val_loss: 0.1567 - val_accuracy: 0.7797\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1602 - accuracy: 0.7725 - val_loss: 0.1562 - val_accuracy: 0.7797\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1597 - accuracy: 0.7725 - val_loss: 0.1557 - val_accuracy: 0.7797\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1592 - accuracy: 0.7725 - val_loss: 0.1552 - val_accuracy: 0.7797\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1587 - accuracy: 0.7725 - val_loss: 0.1547 - val_accuracy: 0.7797\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1581 - accuracy: 0.7725 - val_loss: 0.1542 - val_accuracy: 0.7797\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1576 - accuracy: 0.7725 - val_loss: 0.1537 - val_accuracy: 0.7797\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1571 - accuracy: 0.7725 - val_loss: 0.1532 - val_accuracy: 0.7797\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1566 - accuracy: 0.7725 - val_loss: 0.1527 - val_accuracy: 0.7797\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1560 - accuracy: 0.7725 - val_loss: 0.1521 - val_accuracy: 0.7797\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1554 - accuracy: 0.7725 - val_loss: 0.1516 - val_accuracy: 0.7797\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1549 - accuracy: 0.7725 - val_loss: 0.1511 - val_accuracy: 0.7797\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1543 - accuracy: 0.7725 - val_loss: 0.1505 - val_accuracy: 0.7797\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1537 - accuracy: 0.7725 - val_loss: 0.1499 - val_accuracy: 0.7797\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1531 - accuracy: 0.7725 - val_loss: 0.1493 - val_accuracy: 0.7797\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1525 - accuracy: 0.7725 - val_loss: 0.1487 - val_accuracy: 0.7797\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1519 - accuracy: 0.7725 - val_loss: 0.1481 - val_accuracy: 0.7797\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1513 - accuracy: 0.7725 - val_loss: 0.1475 - val_accuracy: 0.7797\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1507 - accuracy: 0.7725 - val_loss: 0.1469 - val_accuracy: 0.7797\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1500 - accuracy: 0.7725 - val_loss: 0.1463 - val_accuracy: 0.7797\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1494 - accuracy: 0.7725 - val_loss: 0.1456 - val_accuracy: 0.7797\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1488 - accuracy: 0.7725 - val_loss: 0.1449 - val_accuracy: 0.7797\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1481 - accuracy: 0.7725 - val_loss: 0.1443 - val_accuracy: 0.7797\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1474 - accuracy: 0.7725 - val_loss: 0.1436 - val_accuracy: 0.7797\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1468 - accuracy: 0.7725 - val_loss: 0.1430 - val_accuracy: 0.7797\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1461 - accuracy: 0.7725 - val_loss: 0.1423 - val_accuracy: 0.7797\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1455 - accuracy: 0.7725 - val_loss: 0.1416 - val_accuracy: 0.7797\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1448 - accuracy: 0.7725 - val_loss: 0.1410 - val_accuracy: 0.7797\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1441 - accuracy: 0.7725 - val_loss: 0.1403 - val_accuracy: 0.7797\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1434 - accuracy: 0.7725 - val_loss: 0.1396 - val_accuracy: 0.7797\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1427 - accuracy: 0.7725 - val_loss: 0.1389 - val_accuracy: 0.7797\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1420 - accuracy: 0.7725 - val_loss: 0.1382 - val_accuracy: 0.7797\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1413 - accuracy: 0.7725 - val_loss: 0.1375 - val_accuracy: 0.7797\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1405 - accuracy: 0.7725 - val_loss: 0.1367 - val_accuracy: 0.7797\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1398 - accuracy: 0.7725 - val_loss: 0.1360 - val_accuracy: 0.7797\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1391 - accuracy: 0.7725 - val_loss: 0.1352 - val_accuracy: 0.7797\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1383 - accuracy: 0.7725 - val_loss: 0.1345 - val_accuracy: 0.7797\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1376 - accuracy: 0.7725 - val_loss: 0.1337 - val_accuracy: 0.7797\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1369 - accuracy: 0.7725 - val_loss: 0.1330 - val_accuracy: 0.7797\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1360 - accuracy: 0.7725 - val_loss: 0.1322 - val_accuracy: 0.7797\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1352 - accuracy: 0.7725 - val_loss: 0.1315 - val_accuracy: 0.7797\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1346 - accuracy: 0.7725 - val_loss: 0.1310 - val_accuracy: 0.7797\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1339 - accuracy: 0.7725 - val_loss: 0.1301 - val_accuracy: 0.7797\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1330 - accuracy: 0.7725 - val_loss: 0.1290 - val_accuracy: 0.7797\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1321 - accuracy: 0.7725 - val_loss: 0.1282 - val_accuracy: 0.7797\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1313 - accuracy: 0.7725 - val_loss: 0.1275 - val_accuracy: 0.7797\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1306 - accuracy: 0.7725 - val_loss: 0.1266 - val_accuracy: 0.7797\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1297 - accuracy: 0.7725 - val_loss: 0.1259 - val_accuracy: 0.7797\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1288 - accuracy: 0.7725 - val_loss: 0.1251 - val_accuracy: 0.7797\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1281 - accuracy: 0.7725 - val_loss: 0.1244 - val_accuracy: 0.7797\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1273 - accuracy: 0.7725 - val_loss: 0.1234 - val_accuracy: 0.7797\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1264 - accuracy: 0.7725 - val_loss: 0.1226 - val_accuracy: 0.7797\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1256 - accuracy: 0.7725 - val_loss: 0.1217 - val_accuracy: 0.7797\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1248 - accuracy: 0.7725 - val_loss: 0.1209 - val_accuracy: 0.7797\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1240 - accuracy: 0.7725 - val_loss: 0.1202 - val_accuracy: 0.7797\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1233 - accuracy: 0.7725 - val_loss: 0.1195 - val_accuracy: 0.7797\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1225 - accuracy: 0.7725 - val_loss: 0.1186 - val_accuracy: 0.7797\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1217 - accuracy: 0.7725 - val_loss: 0.1178 - val_accuracy: 0.7797\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1209 - accuracy: 0.7725 - val_loss: 0.1170 - val_accuracy: 0.7797\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1201 - accuracy: 0.7725 - val_loss: 0.1162 - val_accuracy: 0.7797\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1193 - accuracy: 0.7725 - val_loss: 0.1155 - val_accuracy: 0.7797\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1185 - accuracy: 0.7725 - val_loss: 0.1147 - val_accuracy: 0.7797\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1177 - accuracy: 0.7725 - val_loss: 0.1138 - val_accuracy: 0.7797\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1169 - accuracy: 0.7725 - val_loss: 0.1130 - val_accuracy: 0.7797\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1161 - accuracy: 0.7725 - val_loss: 0.1122 - val_accuracy: 0.7797\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1153 - accuracy: 0.7725 - val_loss: 0.1114 - val_accuracy: 0.7797\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1146 - accuracy: 0.7725 - val_loss: 0.1107 - val_accuracy: 0.7797\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1138 - accuracy: 0.7725 - val_loss: 0.1099 - val_accuracy: 0.7797\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1131 - accuracy: 0.7725 - val_loss: 0.1092 - val_accuracy: 0.7797\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1123 - accuracy: 0.7725 - val_loss: 0.1084 - val_accuracy: 0.7797\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1115 - accuracy: 0.7725 - val_loss: 0.1077 - val_accuracy: 0.7797\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1108 - accuracy: 0.7725 - val_loss: 0.1069 - val_accuracy: 0.7797\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1100 - accuracy: 0.7725 - val_loss: 0.1062 - val_accuracy: 0.7797\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1094 - accuracy: 0.7725 - val_loss: 0.1055 - val_accuracy: 0.7797\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1086 - accuracy: 0.7725 - val_loss: 0.1048 - val_accuracy: 0.7797\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1079 - accuracy: 0.7725 - val_loss: 0.1040 - val_accuracy: 0.7797\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1072 - accuracy: 0.7725 - val_loss: 0.1033 - val_accuracy: 0.7797\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1065 - accuracy: 0.7725 - val_loss: 0.1026 - val_accuracy: 0.7797\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1058 - accuracy: 0.7725 - val_loss: 0.1019 - val_accuracy: 0.7797\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1051 - accuracy: 0.7725 - val_loss: 0.1013 - val_accuracy: 0.7797\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1046 - accuracy: 0.7725 - val_loss: 0.1007 - val_accuracy: 0.7797\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1039 - accuracy: 0.7725 - val_loss: 0.1000 - val_accuracy: 0.7797\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1033 - accuracy: 0.7725 - val_loss: 0.0994 - val_accuracy: 0.7797\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1027 - accuracy: 0.7725 - val_loss: 0.0988 - val_accuracy: 0.7797\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1021 - accuracy: 0.7713 - val_loss: 0.0981 - val_accuracy: 0.8429\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.1014 - accuracy: 0.8383 - val_loss: 0.0975 - val_accuracy: 0.8678\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.1009 - accuracy: 0.8734 - val_loss: 0.0970 - val_accuracy: 0.8904\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1003 - accuracy: 0.8731 - val_loss: 0.0964 - val_accuracy: 0.8644\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0998 - accuracy: 0.8544 - val_loss: 0.0959 - val_accuracy: 0.8621\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0993 - accuracy: 0.8496 - val_loss: 0.0954 - val_accuracy: 0.8621\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0988 - accuracy: 0.8578 - val_loss: 0.0948 - val_accuracy: 0.8802\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0983 - accuracy: 0.8677 - val_loss: 0.0944 - val_accuracy: 0.8859\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0978 - accuracy: 0.8785 - val_loss: 0.0938 - val_accuracy: 0.8972\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0972 - accuracy: 0.8906 - val_loss: 0.0933 - val_accuracy: 0.8994\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0967 - accuracy: 0.8915 - val_loss: 0.0928 - val_accuracy: 0.8994\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0962 - accuracy: 0.8915 - val_loss: 0.0922 - val_accuracy: 0.8994\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0956 - accuracy: 0.8915 - val_loss: 0.0917 - val_accuracy: 0.8994\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0952 - accuracy: 0.8920 - val_loss: 0.0912 - val_accuracy: 0.8994\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0947 - accuracy: 0.8920 - val_loss: 0.0908 - val_accuracy: 0.8994\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0942 - accuracy: 0.8920 - val_loss: 0.0903 - val_accuracy: 0.8994\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0937 - accuracy: 0.8920 - val_loss: 0.0898 - val_accuracy: 0.8994\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0933 - accuracy: 0.8920 - val_loss: 0.0893 - val_accuracy: 0.8994\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0928 - accuracy: 0.8920 - val_loss: 0.0889 - val_accuracy: 0.8994\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0924 - accuracy: 0.8920 - val_loss: 0.0885 - val_accuracy: 0.8994\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0920 - accuracy: 0.8920 - val_loss: 0.0880 - val_accuracy: 0.8994\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0916 - accuracy: 0.8920 - val_loss: 0.0876 - val_accuracy: 0.8994\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0912 - accuracy: 0.8920 - val_loss: 0.0872 - val_accuracy: 0.8994\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0908 - accuracy: 0.8920 - val_loss: 0.0868 - val_accuracy: 0.8994\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0904 - accuracy: 0.8920 - val_loss: 0.0864 - val_accuracy: 0.8994\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0900 - accuracy: 0.8920 - val_loss: 0.0860 - val_accuracy: 0.8994\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0896 - accuracy: 0.8920 - val_loss: 0.0857 - val_accuracy: 0.8994\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0893 - accuracy: 0.8920 - val_loss: 0.0853 - val_accuracy: 0.8994\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0890 - accuracy: 0.8920 - val_loss: 0.0851 - val_accuracy: 0.8994\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0887 - accuracy: 0.8920 - val_loss: 0.0848 - val_accuracy: 0.8994\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0884 - accuracy: 0.8920 - val_loss: 0.0843 - val_accuracy: 0.8994\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0880 - accuracy: 0.8920 - val_loss: 0.0840 - val_accuracy: 0.8994\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0877 - accuracy: 0.8920 - val_loss: 0.0837 - val_accuracy: 0.8994\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0874 - accuracy: 0.8920 - val_loss: 0.0834 - val_accuracy: 0.8994\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0871 - accuracy: 0.8920 - val_loss: 0.0831 - val_accuracy: 0.8994\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0869 - accuracy: 0.8920 - val_loss: 0.0830 - val_accuracy: 0.8994\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0867 - accuracy: 0.8920 - val_loss: 0.0827 - val_accuracy: 0.8994\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0863 - accuracy: 0.8920 - val_loss: 0.0823 - val_accuracy: 0.8994\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0860 - accuracy: 0.8920 - val_loss: 0.0820 - val_accuracy: 0.8994\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0858 - accuracy: 0.8920 - val_loss: 0.0818 - val_accuracy: 0.8994\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0856 - accuracy: 0.8920 - val_loss: 0.0816 - val_accuracy: 0.8994\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0854 - accuracy: 0.8920 - val_loss: 0.0814 - val_accuracy: 0.8994\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0852 - accuracy: 0.8920 - val_loss: 0.0812 - val_accuracy: 0.8994\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0849 - accuracy: 0.8920 - val_loss: 0.0809 - val_accuracy: 0.8994\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0846 - accuracy: 0.8920 - val_loss: 0.0806 - val_accuracy: 0.8994\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0844 - accuracy: 0.8920 - val_loss: 0.0804 - val_accuracy: 0.8994\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0842 - accuracy: 0.8920 - val_loss: 0.0802 - val_accuracy: 0.8994\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0840 - accuracy: 0.8920 - val_loss: 0.0800 - val_accuracy: 0.8994\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0838 - accuracy: 0.8920 - val_loss: 0.0798 - val_accuracy: 0.8994\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0836 - accuracy: 0.8920 - val_loss: 0.0796 - val_accuracy: 0.8994\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0834 - accuracy: 0.8920 - val_loss: 0.0794 - val_accuracy: 0.8994\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0832 - accuracy: 0.8920 - val_loss: 0.0792 - val_accuracy: 0.8994\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0830 - accuracy: 0.8920 - val_loss: 0.0790 - val_accuracy: 0.8994\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0829 - accuracy: 0.8920 - val_loss: 0.0788 - val_accuracy: 0.8994\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0827 - accuracy: 0.8920 - val_loss: 0.0786 - val_accuracy: 0.8994\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0825 - accuracy: 0.8920 - val_loss: 0.0785 - val_accuracy: 0.8994\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0824 - accuracy: 0.8920 - val_loss: 0.0783 - val_accuracy: 0.8994\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0822 - accuracy: 0.8920 - val_loss: 0.0781 - val_accuracy: 0.8994\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0820 - accuracy: 0.8920 - val_loss: 0.0779 - val_accuracy: 0.8994\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0819 - accuracy: 0.8920 - val_loss: 0.0778 - val_accuracy: 0.8994\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0817 - accuracy: 0.8920 - val_loss: 0.0776 - val_accuracy: 0.8994\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0816 - accuracy: 0.8920 - val_loss: 0.0775 - val_accuracy: 0.8994\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0814 - accuracy: 0.8920 - val_loss: 0.0773 - val_accuracy: 0.8994\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0813 - accuracy: 0.8920 - val_loss: 0.0772 - val_accuracy: 0.8994\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0811 - accuracy: 0.8920 - val_loss: 0.0771 - val_accuracy: 0.8994\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0810 - accuracy: 0.8920 - val_loss: 0.0770 - val_accuracy: 0.8994\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0810 - accuracy: 0.8920 - val_loss: 0.0770 - val_accuracy: 0.8994\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0810 - accuracy: 0.8920 - val_loss: 0.0769 - val_accuracy: 0.8994\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0808 - accuracy: 0.8920 - val_loss: 0.0767 - val_accuracy: 0.8994\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0806 - accuracy: 0.8920 - val_loss: 0.0765 - val_accuracy: 0.8994\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0805 - accuracy: 0.8920 - val_loss: 0.0763 - val_accuracy: 0.8994\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0803 - accuracy: 0.8920 - val_loss: 0.0762 - val_accuracy: 0.8994\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "78d3b371-58ad-4372-d845-6f419685e4d4",
        "id": "1mExCwgob3dF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.8639\n",
            "Test results - Loss: 0.12950848042964935 - Accuracy: 86.38932704925537%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2_1 = test_results[1]\n",
        "y_pred2_1 = np.where(ae_classifier.predict(X_test).ravel()>=0.5,1,0)\n",
        "y_test2 = y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qmMChY7bb3dG",
        "outputId": "2eb5d55d-a056-40b1-d05a-9fe5705f1333"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 3"
      ],
      "metadata": {
        "id": "z-SsndIeb3dG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train3.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test3.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "NljzBK-Tb3dG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b21f18ab-1fbd-4cb7-8e69-c6a7302a9bc4",
        "id": "qFu9C5FKb3dG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "normal      11711\n",
              "abnormal     5036\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 353
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count3 = len(test.index)"
      ],
      "metadata": {
        "id": "FDDB8Bk0b3dH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['intrusion']]\n",
        "\n",
        "X_train = train.iloc[:,0:89]\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['intrusion']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.iloc[:,0:89]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e3776ae-0f75-43d9-cada-2daba2e85097",
        "id": "pjS6WNzqb3dH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_45\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_46 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_108 (Dense)           (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_109 (Dense)           (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc579d46-3899-44c1-c47c-edc823e5256b",
        "id": "GpScPltDb3dH"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "34/34 [==============================] - 1s 11ms/step - loss: 0.0793 - accuracy: 0.0871 - val_loss: 0.1627 - val_accuracy: 0.0955\n",
            "Epoch 2/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0751 - accuracy: 0.2284 - val_loss: 0.1548 - val_accuracy: 0.1099\n",
            "Epoch 3/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0671 - accuracy: 0.0655 - val_loss: 0.1510 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0640 - accuracy: 0.0156 - val_loss: 0.1513 - val_accuracy: 0.0097\n",
            "Epoch 5/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0627 - accuracy: 0.1450 - val_loss: 0.1504 - val_accuracy: 0.0214\n",
            "Epoch 6/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0620 - accuracy: 0.3383 - val_loss: 0.1496 - val_accuracy: 0.0653\n",
            "Epoch 7/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0617 - accuracy: 0.4668 - val_loss: 0.1489 - val_accuracy: 0.1106\n",
            "Epoch 8/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0615 - accuracy: 0.4970 - val_loss: 0.1483 - val_accuracy: 0.1323\n",
            "Epoch 9/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0614 - accuracy: 0.4941 - val_loss: 0.1478 - val_accuracy: 0.1705\n",
            "Epoch 10/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.5058 - val_loss: 0.1475 - val_accuracy: 0.2224\n",
            "Epoch 11/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0613 - accuracy: 0.4878 - val_loss: 0.1473 - val_accuracy: 0.2358\n",
            "Epoch 12/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 0.4573 - val_loss: 0.1471 - val_accuracy: 0.2482\n",
            "Epoch 13/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0612 - accuracy: 0.4398 - val_loss: 0.1470 - val_accuracy: 0.2492\n",
            "Epoch 14/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0612 - accuracy: 0.4353 - val_loss: 0.1469 - val_accuracy: 0.2596\n",
            "Epoch 15/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0611 - accuracy: 0.4503 - val_loss: 0.1468 - val_accuracy: 0.2861\n",
            "Epoch 16/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.4948 - val_loss: 0.1468 - val_accuracy: 0.2982\n",
            "Epoch 17/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.0611 - accuracy: 0.5073 - val_loss: 0.1467 - val_accuracy: 0.3149\n",
            "Epoch 18/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.5339 - val_loss: 0.1467 - val_accuracy: 0.3508\n",
            "Epoch 19/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.5373 - val_loss: 0.1466 - val_accuracy: 0.3725\n",
            "Epoch 20/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0611 - accuracy: 0.5079 - val_loss: 0.1466 - val_accuracy: 0.3598\n",
            "Epoch 21/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.5181 - val_loss: 0.1466 - val_accuracy: 0.3702\n",
            "Epoch 22/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.5035 - val_loss: 0.1465 - val_accuracy: 0.3789\n",
            "Epoch 23/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.5002 - val_loss: 0.1465 - val_accuracy: 0.3591\n",
            "Epoch 24/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.4861 - val_loss: 0.1465 - val_accuracy: 0.3497\n",
            "Epoch 25/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0611 - accuracy: 0.4950 - val_loss: 0.1465 - val_accuracy: 0.3866\n",
            "Epoch 26/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4966 - val_loss: 0.1465 - val_accuracy: 0.3829\n",
            "Epoch 27/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4890 - val_loss: 0.1465 - val_accuracy: 0.3836\n",
            "Epoch 28/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5000 - val_loss: 0.1465 - val_accuracy: 0.3953\n",
            "Epoch 29/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4819 - val_loss: 0.1465 - val_accuracy: 0.3652\n",
            "Epoch 30/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.4795 - val_loss: 0.1465 - val_accuracy: 0.3943\n",
            "Epoch 31/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.4856 - val_loss: 0.1465 - val_accuracy: 0.4017\n",
            "Epoch 32/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.4652 - val_loss: 0.1465 - val_accuracy: 0.3652\n",
            "Epoch 33/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.4895 - val_loss: 0.1465 - val_accuracy: 0.3936\n",
            "Epoch 34/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.5001 - val_loss: 0.1465 - val_accuracy: 0.3668\n",
            "Epoch 35/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.4688 - val_loss: 0.1465 - val_accuracy: 0.4003\n",
            "Epoch 36/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.5089 - val_loss: 0.1464 - val_accuracy: 0.3923\n",
            "Epoch 37/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4988 - val_loss: 0.1464 - val_accuracy: 0.3544\n",
            "Epoch 38/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5208 - val_loss: 0.1464 - val_accuracy: 0.3963\n",
            "Epoch 39/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4933 - val_loss: 0.1464 - val_accuracy: 0.3889\n",
            "Epoch 40/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5258 - val_loss: 0.1464 - val_accuracy: 0.4104\n",
            "Epoch 41/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5014 - val_loss: 0.1464 - val_accuracy: 0.4295\n",
            "Epoch 42/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4860 - val_loss: 0.1464 - val_accuracy: 0.4201\n",
            "Epoch 43/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5141 - val_loss: 0.1464 - val_accuracy: 0.4104\n",
            "Epoch 44/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5246 - val_loss: 0.1464 - val_accuracy: 0.4147\n",
            "Epoch 45/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4890 - val_loss: 0.1464 - val_accuracy: 0.3920\n",
            "Epoch 46/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5131 - val_loss: 0.1464 - val_accuracy: 0.4037\n",
            "Epoch 47/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5077 - val_loss: 0.1464 - val_accuracy: 0.4000\n",
            "Epoch 48/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5021 - val_loss: 0.1464 - val_accuracy: 0.3873\n",
            "Epoch 49/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.5117 - val_loss: 0.1464 - val_accuracy: 0.4352\n",
            "Epoch 50/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5115 - val_loss: 0.1464 - val_accuracy: 0.3953\n",
            "Epoch 51/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4963 - val_loss: 0.1464 - val_accuracy: 0.3655\n",
            "Epoch 52/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4884 - val_loss: 0.1464 - val_accuracy: 0.3719\n",
            "Epoch 53/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4835 - val_loss: 0.1464 - val_accuracy: 0.3122\n",
            "Epoch 54/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4867 - val_loss: 0.1464 - val_accuracy: 0.3571\n",
            "Epoch 55/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4912 - val_loss: 0.1464 - val_accuracy: 0.3933\n",
            "Epoch 56/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4913 - val_loss: 0.1464 - val_accuracy: 0.3471\n",
            "Epoch 57/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.5051 - val_loss: 0.1464 - val_accuracy: 0.3199\n",
            "Epoch 58/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4781 - val_loss: 0.1464 - val_accuracy: 0.3303\n",
            "Epoch 59/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4625 - val_loss: 0.1463 - val_accuracy: 0.3631\n",
            "Epoch 60/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4820 - val_loss: 0.1463 - val_accuracy: 0.2988\n",
            "Epoch 61/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4675 - val_loss: 0.1463 - val_accuracy: 0.3286\n",
            "Epoch 62/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4618 - val_loss: 0.1463 - val_accuracy: 0.3410\n",
            "Epoch 63/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4976 - val_loss: 0.1463 - val_accuracy: 0.3491\n",
            "Epoch 64/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4675 - val_loss: 0.1463 - val_accuracy: 0.3132\n",
            "Epoch 65/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4841 - val_loss: 0.1463 - val_accuracy: 0.3072\n",
            "Epoch 66/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4708 - val_loss: 0.1463 - val_accuracy: 0.3548\n",
            "Epoch 67/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4603 - val_loss: 0.1463 - val_accuracy: 0.3528\n",
            "Epoch 68/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4681 - val_loss: 0.1463 - val_accuracy: 0.3179\n",
            "Epoch 69/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 0.4374 - val_loss: 0.1463 - val_accuracy: 0.3625\n",
            "Epoch 70/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4798 - val_loss: 0.1463 - val_accuracy: 0.3139\n",
            "Epoch 71/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4683 - val_loss: 0.1463 - val_accuracy: 0.3055\n",
            "Epoch 72/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4545 - val_loss: 0.1463 - val_accuracy: 0.3581\n",
            "Epoch 73/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4721 - val_loss: 0.1463 - val_accuracy: 0.3705\n",
            "Epoch 74/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4658 - val_loss: 0.1463 - val_accuracy: 0.3082\n",
            "Epoch 75/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4508 - val_loss: 0.1463 - val_accuracy: 0.3082\n",
            "Epoch 76/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4526 - val_loss: 0.1463 - val_accuracy: 0.3913\n",
            "Epoch 77/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4333 - val_loss: 0.1463 - val_accuracy: 0.3454\n",
            "Epoch 78/100\n",
            "34/34 [==============================] - 0s 9ms/step - loss: 0.0610 - accuracy: 0.4647 - val_loss: 0.1463 - val_accuracy: 0.3732\n",
            "Epoch 79/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.4676 - val_loss: 0.1463 - val_accuracy: 0.3675\n",
            "Epoch 80/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.4550 - val_loss: 0.1463 - val_accuracy: 0.3477\n",
            "Epoch 81/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.4715 - val_loss: 0.1463 - val_accuracy: 0.3424\n",
            "Epoch 82/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.4717 - val_loss: 0.1463 - val_accuracy: 0.3142\n",
            "Epoch 83/100\n",
            "34/34 [==============================] - 0s 11ms/step - loss: 0.0610 - accuracy: 0.4657 - val_loss: 0.1463 - val_accuracy: 0.3420\n",
            "Epoch 84/100\n",
            "34/34 [==============================] - 0s 12ms/step - loss: 0.0610 - accuracy: 0.4659 - val_loss: 0.1463 - val_accuracy: 0.3849\n",
            "Epoch 85/100\n",
            "34/34 [==============================] - 0s 10ms/step - loss: 0.0610 - accuracy: 0.4825 - val_loss: 0.1463 - val_accuracy: 0.3079\n",
            "Epoch 86/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4640 - val_loss: 0.1463 - val_accuracy: 0.3032\n",
            "Epoch 87/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4384 - val_loss: 0.1463 - val_accuracy: 0.3444\n",
            "Epoch 88/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4527 - val_loss: 0.1463 - val_accuracy: 0.3367\n",
            "Epoch 89/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4644 - val_loss: 0.1463 - val_accuracy: 0.3374\n",
            "Epoch 90/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4506 - val_loss: 0.1463 - val_accuracy: 0.3072\n",
            "Epoch 91/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4559 - val_loss: 0.1463 - val_accuracy: 0.3069\n",
            "Epoch 92/100\n",
            "34/34 [==============================] - 0s 8ms/step - loss: 0.0610 - accuracy: 0.4492 - val_loss: 0.1463 - val_accuracy: 0.3608\n",
            "Epoch 93/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4682 - val_loss: 0.1463 - val_accuracy: 0.3829\n",
            "Epoch 94/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4808 - val_loss: 0.1463 - val_accuracy: 0.3645\n",
            "Epoch 95/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4511 - val_loss: 0.1463 - val_accuracy: 0.3283\n",
            "Epoch 96/100\n",
            "34/34 [==============================] - 0s 7ms/step - loss: 0.0610 - accuracy: 0.4585 - val_loss: 0.1463 - val_accuracy: 0.3266\n",
            "Epoch 97/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4483 - val_loss: 0.1463 - val_accuracy: 0.3263\n",
            "Epoch 98/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4615 - val_loss: 0.1463 - val_accuracy: 0.3444\n",
            "Epoch 99/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4557 - val_loss: 0.1463 - val_accuracy: 0.3538\n",
            "Epoch 100/100\n",
            "34/34 [==============================] - 0s 6ms/step - loss: 0.0610 - accuracy: 0.4749 - val_loss: 0.1463 - val_accuracy: 0.3189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(48, activation=\"sigmoid\")(i_layer)   \n",
        "#fvector = Dense(24, activation='tanh')(fvector)                 \n",
        "#doutput layer\n",
        "o_layer = Dense(1, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "049aabf8-369d-47ae-c403-e9222bc1951d",
        "id": "b-7bo2oQb3dI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n",
            "Model: \"model_46\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_47 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_110 (Dense)           (None, 48)                4320      \n",
            "                                                                 \n",
            " dense_111 (Dense)           (None, 1)                 49        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,369\n",
            "Trainable params: 4,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6877a6d7-abc1-4336-b08b-05ad84c572bf",
        "id": "sXj7MFl0b3dI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "4/4 [==============================] - 1s 65ms/step - loss: 0.2807 - accuracy: 0.5544 - val_loss: 0.2640 - val_accuracy: 0.5779\n",
            "Epoch 2/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2722 - accuracy: 0.5544 - val_loss: 0.2571 - val_accuracy: 0.5779\n",
            "Epoch 3/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2646 - accuracy: 0.5544 - val_loss: 0.2511 - val_accuracy: 0.5779\n",
            "Epoch 4/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2577 - accuracy: 0.5544 - val_loss: 0.2460 - val_accuracy: 0.5779\n",
            "Epoch 5/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2519 - accuracy: 0.5544 - val_loss: 0.2420 - val_accuracy: 0.5779\n",
            "Epoch 6/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2472 - accuracy: 0.5544 - val_loss: 0.2392 - val_accuracy: 0.5779\n",
            "Epoch 7/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2440 - accuracy: 0.5544 - val_loss: 0.2373 - val_accuracy: 0.5779\n",
            "Epoch 8/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2413 - accuracy: 0.5544 - val_loss: 0.2362 - val_accuracy: 0.5779\n",
            "Epoch 9/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2397 - accuracy: 0.5544 - val_loss: 0.2355 - val_accuracy: 0.5779\n",
            "Epoch 10/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2386 - accuracy: 0.5544 - val_loss: 0.2350 - val_accuracy: 0.5779\n",
            "Epoch 11/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2378 - accuracy: 0.5544 - val_loss: 0.2346 - val_accuracy: 0.5779\n",
            "Epoch 12/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2371 - accuracy: 0.5544 - val_loss: 0.2339 - val_accuracy: 0.5779\n",
            "Epoch 13/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2363 - accuracy: 0.5544 - val_loss: 0.2331 - val_accuracy: 0.5779\n",
            "Epoch 14/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2354 - accuracy: 0.5544 - val_loss: 0.2321 - val_accuracy: 0.5779\n",
            "Epoch 15/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2346 - accuracy: 0.5544 - val_loss: 0.2310 - val_accuracy: 0.5779\n",
            "Epoch 16/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2337 - accuracy: 0.5544 - val_loss: 0.2299 - val_accuracy: 0.5779\n",
            "Epoch 17/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2328 - accuracy: 0.5544 - val_loss: 0.2289 - val_accuracy: 0.5779\n",
            "Epoch 18/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2319 - accuracy: 0.5544 - val_loss: 0.2279 - val_accuracy: 0.5779\n",
            "Epoch 19/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2311 - accuracy: 0.5544 - val_loss: 0.2269 - val_accuracy: 0.5779\n",
            "Epoch 20/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2303 - accuracy: 0.5544 - val_loss: 0.2260 - val_accuracy: 0.5779\n",
            "Epoch 21/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2294 - accuracy: 0.5544 - val_loss: 0.2250 - val_accuracy: 0.5779\n",
            "Epoch 22/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.2286 - accuracy: 0.5544 - val_loss: 0.2242 - val_accuracy: 0.5779\n",
            "Epoch 23/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2277 - accuracy: 0.5544 - val_loss: 0.2232 - val_accuracy: 0.5779\n",
            "Epoch 24/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2268 - accuracy: 0.5544 - val_loss: 0.2223 - val_accuracy: 0.5779\n",
            "Epoch 25/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.2260 - accuracy: 0.5544 - val_loss: 0.2213 - val_accuracy: 0.5779\n",
            "Epoch 26/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.2251 - accuracy: 0.5544 - val_loss: 0.2204 - val_accuracy: 0.5779\n",
            "Epoch 27/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.2242 - accuracy: 0.5544 - val_loss: 0.2195 - val_accuracy: 0.5779\n",
            "Epoch 28/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2233 - accuracy: 0.5544 - val_loss: 0.2185 - val_accuracy: 0.5779\n",
            "Epoch 29/200\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.2224 - accuracy: 0.5549 - val_loss: 0.2176 - val_accuracy: 0.5796\n",
            "Epoch 30/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2215 - accuracy: 0.5553 - val_loss: 0.2166 - val_accuracy: 0.5796\n",
            "Epoch 31/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2206 - accuracy: 0.5712 - val_loss: 0.2157 - val_accuracy: 0.6767\n",
            "Epoch 32/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2196 - accuracy: 0.6298 - val_loss: 0.2146 - val_accuracy: 0.6767\n",
            "Epoch 33/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2187 - accuracy: 0.6319 - val_loss: 0.2136 - val_accuracy: 0.6767\n",
            "Epoch 34/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2177 - accuracy: 0.6499 - val_loss: 0.2126 - val_accuracy: 0.7002\n",
            "Epoch 35/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2168 - accuracy: 0.6608 - val_loss: 0.2115 - val_accuracy: 0.7002\n",
            "Epoch 36/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2158 - accuracy: 0.6713 - val_loss: 0.2104 - val_accuracy: 0.7705\n",
            "Epoch 37/200\n",
            "4/4 [==============================] - 0s 27ms/step - loss: 0.2148 - accuracy: 0.7291 - val_loss: 0.2094 - val_accuracy: 0.7839\n",
            "Epoch 38/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2138 - accuracy: 0.7353 - val_loss: 0.2084 - val_accuracy: 0.7889\n",
            "Epoch 39/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2128 - accuracy: 0.7399 - val_loss: 0.2073 - val_accuracy: 0.7906\n",
            "Epoch 40/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.2118 - accuracy: 0.7446 - val_loss: 0.2063 - val_accuracy: 0.7956\n",
            "Epoch 41/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2107 - accuracy: 0.7458 - val_loss: 0.2051 - val_accuracy: 0.7956\n",
            "Epoch 42/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2097 - accuracy: 0.7487 - val_loss: 0.2040 - val_accuracy: 0.7973\n",
            "Epoch 43/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.2086 - accuracy: 0.7496 - val_loss: 0.2027 - val_accuracy: 0.7973\n",
            "Epoch 44/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2075 - accuracy: 0.7496 - val_loss: 0.2015 - val_accuracy: 0.7973\n",
            "Epoch 45/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2064 - accuracy: 0.7496 - val_loss: 0.2003 - val_accuracy: 0.7973\n",
            "Epoch 46/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.2053 - accuracy: 0.7496 - val_loss: 0.1990 - val_accuracy: 0.7973\n",
            "Epoch 47/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.2042 - accuracy: 0.7500 - val_loss: 0.1978 - val_accuracy: 0.8007\n",
            "Epoch 48/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2030 - accuracy: 0.7508 - val_loss: 0.1966 - val_accuracy: 0.8074\n",
            "Epoch 49/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2018 - accuracy: 0.7575 - val_loss: 0.1954 - val_accuracy: 0.8208\n",
            "Epoch 50/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.2007 - accuracy: 0.7810 - val_loss: 0.1942 - val_accuracy: 0.8342\n",
            "Epoch 51/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1995 - accuracy: 0.7856 - val_loss: 0.1930 - val_accuracy: 0.8342\n",
            "Epoch 52/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1983 - accuracy: 0.7856 - val_loss: 0.1916 - val_accuracy: 0.8342\n",
            "Epoch 53/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1971 - accuracy: 0.7860 - val_loss: 0.1903 - val_accuracy: 0.8342\n",
            "Epoch 54/200\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1958 - accuracy: 0.7860 - val_loss: 0.1889 - val_accuracy: 0.8342\n",
            "Epoch 55/200\n",
            "4/4 [==============================] - 0s 30ms/step - loss: 0.1945 - accuracy: 0.7860 - val_loss: 0.1875 - val_accuracy: 0.8342\n",
            "Epoch 56/200\n",
            "4/4 [==============================] - 0s 26ms/step - loss: 0.1933 - accuracy: 0.7856 - val_loss: 0.1860 - val_accuracy: 0.8342\n",
            "Epoch 57/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1920 - accuracy: 0.7856 - val_loss: 0.1846 - val_accuracy: 0.8342\n",
            "Epoch 58/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1907 - accuracy: 0.7860 - val_loss: 0.1833 - val_accuracy: 0.8342\n",
            "Epoch 59/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1894 - accuracy: 0.7860 - val_loss: 0.1819 - val_accuracy: 0.8342\n",
            "Epoch 60/200\n",
            "4/4 [==============================] - 0s 28ms/step - loss: 0.1881 - accuracy: 0.7869 - val_loss: 0.1804 - val_accuracy: 0.8342\n",
            "Epoch 61/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1867 - accuracy: 0.7885 - val_loss: 0.1790 - val_accuracy: 0.8409\n",
            "Epoch 62/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1854 - accuracy: 0.7973 - val_loss: 0.1776 - val_accuracy: 0.8476\n",
            "Epoch 63/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1840 - accuracy: 0.8036 - val_loss: 0.1762 - val_accuracy: 0.8509\n",
            "Epoch 64/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1826 - accuracy: 0.8116 - val_loss: 0.1747 - val_accuracy: 0.8543\n",
            "Epoch 65/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1813 - accuracy: 0.8145 - val_loss: 0.1733 - val_accuracy: 0.8559\n",
            "Epoch 66/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1799 - accuracy: 0.8178 - val_loss: 0.1718 - val_accuracy: 0.8593\n",
            "Epoch 67/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1785 - accuracy: 0.8195 - val_loss: 0.1702 - val_accuracy: 0.8576\n",
            "Epoch 68/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1770 - accuracy: 0.8183 - val_loss: 0.1686 - val_accuracy: 0.8576\n",
            "Epoch 69/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1756 - accuracy: 0.8178 - val_loss: 0.1671 - val_accuracy: 0.8576\n",
            "Epoch 70/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1742 - accuracy: 0.8178 - val_loss: 0.1655 - val_accuracy: 0.8593\n",
            "Epoch 71/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1727 - accuracy: 0.8195 - val_loss: 0.1639 - val_accuracy: 0.8593\n",
            "Epoch 72/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1713 - accuracy: 0.8233 - val_loss: 0.1624 - val_accuracy: 0.8593\n",
            "Epoch 73/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1698 - accuracy: 0.8275 - val_loss: 0.1608 - val_accuracy: 0.8677\n",
            "Epoch 74/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1684 - accuracy: 0.8438 - val_loss: 0.1593 - val_accuracy: 0.8744\n",
            "Epoch 75/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1669 - accuracy: 0.8488 - val_loss: 0.1576 - val_accuracy: 0.8727\n",
            "Epoch 76/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1654 - accuracy: 0.8492 - val_loss: 0.1561 - val_accuracy: 0.8861\n",
            "Epoch 77/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.1639 - accuracy: 0.8748 - val_loss: 0.1545 - val_accuracy: 0.9179\n",
            "Epoch 78/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1624 - accuracy: 0.9192 - val_loss: 0.1530 - val_accuracy: 0.9481\n",
            "Epoch 79/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1610 - accuracy: 0.9485 - val_loss: 0.1515 - val_accuracy: 0.9749\n",
            "Epoch 80/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1595 - accuracy: 0.9640 - val_loss: 0.1500 - val_accuracy: 0.9749\n",
            "Epoch 81/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1581 - accuracy: 0.9640 - val_loss: 0.1484 - val_accuracy: 0.9749\n",
            "Epoch 82/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1565 - accuracy: 0.9640 - val_loss: 0.1467 - val_accuracy: 0.9749\n",
            "Epoch 83/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1550 - accuracy: 0.9640 - val_loss: 0.1451 - val_accuracy: 0.9749\n",
            "Epoch 84/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1535 - accuracy: 0.9640 - val_loss: 0.1434 - val_accuracy: 0.9749\n",
            "Epoch 85/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1521 - accuracy: 0.9640 - val_loss: 0.1418 - val_accuracy: 0.9749\n",
            "Epoch 86/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1506 - accuracy: 0.9640 - val_loss: 0.1402 - val_accuracy: 0.9749\n",
            "Epoch 87/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1491 - accuracy: 0.9640 - val_loss: 0.1387 - val_accuracy: 0.9749\n",
            "Epoch 88/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1477 - accuracy: 0.9640 - val_loss: 0.1372 - val_accuracy: 0.9749\n",
            "Epoch 89/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1462 - accuracy: 0.9640 - val_loss: 0.1356 - val_accuracy: 0.9749\n",
            "Epoch 90/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1448 - accuracy: 0.9640 - val_loss: 0.1341 - val_accuracy: 0.9749\n",
            "Epoch 91/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1433 - accuracy: 0.9640 - val_loss: 0.1326 - val_accuracy: 0.9749\n",
            "Epoch 92/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1419 - accuracy: 0.9640 - val_loss: 0.1310 - val_accuracy: 0.9749\n",
            "Epoch 93/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1405 - accuracy: 0.9640 - val_loss: 0.1295 - val_accuracy: 0.9749\n",
            "Epoch 94/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1391 - accuracy: 0.9640 - val_loss: 0.1280 - val_accuracy: 0.9749\n",
            "Epoch 95/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1377 - accuracy: 0.9640 - val_loss: 0.1266 - val_accuracy: 0.9749\n",
            "Epoch 96/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1363 - accuracy: 0.9640 - val_loss: 0.1251 - val_accuracy: 0.9749\n",
            "Epoch 97/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1349 - accuracy: 0.9640 - val_loss: 0.1237 - val_accuracy: 0.9749\n",
            "Epoch 98/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.1335 - accuracy: 0.9640 - val_loss: 0.1222 - val_accuracy: 0.9749\n",
            "Epoch 99/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1321 - accuracy: 0.9640 - val_loss: 0.1207 - val_accuracy: 0.9749\n",
            "Epoch 100/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1308 - accuracy: 0.9640 - val_loss: 0.1193 - val_accuracy: 0.9749\n",
            "Epoch 101/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.1294 - accuracy: 0.9640 - val_loss: 0.1178 - val_accuracy: 0.9749\n",
            "Epoch 102/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1281 - accuracy: 0.9640 - val_loss: 0.1165 - val_accuracy: 0.9749\n",
            "Epoch 103/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1268 - accuracy: 0.9640 - val_loss: 0.1151 - val_accuracy: 0.9749\n",
            "Epoch 104/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1254 - accuracy: 0.9640 - val_loss: 0.1138 - val_accuracy: 0.9749\n",
            "Epoch 105/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.1242 - accuracy: 0.9640 - val_loss: 0.1125 - val_accuracy: 0.9749\n",
            "Epoch 106/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1229 - accuracy: 0.9640 - val_loss: 0.1111 - val_accuracy: 0.9749\n",
            "Epoch 107/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1216 - accuracy: 0.9640 - val_loss: 0.1098 - val_accuracy: 0.9749\n",
            "Epoch 108/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.1203 - accuracy: 0.9640 - val_loss: 0.1084 - val_accuracy: 0.9749\n",
            "Epoch 109/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.1191 - accuracy: 0.9640 - val_loss: 0.1071 - val_accuracy: 0.9749\n",
            "Epoch 110/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1178 - accuracy: 0.9640 - val_loss: 0.1058 - val_accuracy: 0.9749\n",
            "Epoch 111/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1166 - accuracy: 0.9640 - val_loss: 0.1045 - val_accuracy: 0.9749\n",
            "Epoch 112/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1154 - accuracy: 0.9640 - val_loss: 0.1032 - val_accuracy: 0.9749\n",
            "Epoch 113/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1142 - accuracy: 0.9640 - val_loss: 0.1020 - val_accuracy: 0.9749\n",
            "Epoch 114/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.1131 - accuracy: 0.9640 - val_loss: 0.1008 - val_accuracy: 0.9749\n",
            "Epoch 115/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.1119 - accuracy: 0.9640 - val_loss: 0.0996 - val_accuracy: 0.9749\n",
            "Epoch 116/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1108 - accuracy: 0.9640 - val_loss: 0.0984 - val_accuracy: 0.9749\n",
            "Epoch 117/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.1096 - accuracy: 0.9640 - val_loss: 0.0973 - val_accuracy: 0.9749\n",
            "Epoch 118/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.1085 - accuracy: 0.9640 - val_loss: 0.0961 - val_accuracy: 0.9749\n",
            "Epoch 119/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1074 - accuracy: 0.9640 - val_loss: 0.0950 - val_accuracy: 0.9749\n",
            "Epoch 120/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1063 - accuracy: 0.9640 - val_loss: 0.0939 - val_accuracy: 0.9749\n",
            "Epoch 121/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1053 - accuracy: 0.9640 - val_loss: 0.0928 - val_accuracy: 0.9749\n",
            "Epoch 122/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1042 - accuracy: 0.9640 - val_loss: 0.0917 - val_accuracy: 0.9749\n",
            "Epoch 123/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1032 - accuracy: 0.9640 - val_loss: 0.0907 - val_accuracy: 0.9749\n",
            "Epoch 124/200\n",
            "4/4 [==============================] - 0s 21ms/step - loss: 0.1022 - accuracy: 0.9640 - val_loss: 0.0896 - val_accuracy: 0.9749\n",
            "Epoch 125/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1011 - accuracy: 0.9640 - val_loss: 0.0886 - val_accuracy: 0.9749\n",
            "Epoch 126/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.1002 - accuracy: 0.9640 - val_loss: 0.0876 - val_accuracy: 0.9749\n",
            "Epoch 127/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0992 - accuracy: 0.9640 - val_loss: 0.0866 - val_accuracy: 0.9749\n",
            "Epoch 128/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0982 - accuracy: 0.9640 - val_loss: 0.0856 - val_accuracy: 0.9749\n",
            "Epoch 129/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0972 - accuracy: 0.9640 - val_loss: 0.0846 - val_accuracy: 0.9749\n",
            "Epoch 130/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0963 - accuracy: 0.9640 - val_loss: 0.0837 - val_accuracy: 0.9749\n",
            "Epoch 131/200\n",
            "4/4 [==============================] - 0s 13ms/step - loss: 0.0954 - accuracy: 0.9640 - val_loss: 0.0827 - val_accuracy: 0.9749\n",
            "Epoch 132/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0945 - accuracy: 0.9640 - val_loss: 0.0818 - val_accuracy: 0.9749\n",
            "Epoch 133/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0936 - accuracy: 0.9640 - val_loss: 0.0809 - val_accuracy: 0.9749\n",
            "Epoch 134/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0927 - accuracy: 0.9640 - val_loss: 0.0800 - val_accuracy: 0.9749\n",
            "Epoch 135/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0918 - accuracy: 0.9640 - val_loss: 0.0791 - val_accuracy: 0.9749\n",
            "Epoch 136/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0910 - accuracy: 0.9640 - val_loss: 0.0783 - val_accuracy: 0.9749\n",
            "Epoch 137/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0901 - accuracy: 0.9640 - val_loss: 0.0774 - val_accuracy: 0.9749\n",
            "Epoch 138/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0893 - accuracy: 0.9640 - val_loss: 0.0766 - val_accuracy: 0.9749\n",
            "Epoch 139/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0885 - accuracy: 0.9640 - val_loss: 0.0758 - val_accuracy: 0.9749\n",
            "Epoch 140/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0877 - accuracy: 0.9640 - val_loss: 0.0750 - val_accuracy: 0.9749\n",
            "Epoch 141/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0869 - accuracy: 0.9640 - val_loss: 0.0742 - val_accuracy: 0.9749\n",
            "Epoch 142/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0861 - accuracy: 0.9640 - val_loss: 0.0735 - val_accuracy: 0.9749\n",
            "Epoch 143/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0853 - accuracy: 0.9640 - val_loss: 0.0727 - val_accuracy: 0.9749\n",
            "Epoch 144/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0846 - accuracy: 0.9640 - val_loss: 0.0719 - val_accuracy: 0.9749\n",
            "Epoch 145/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0838 - accuracy: 0.9640 - val_loss: 0.0711 - val_accuracy: 0.9749\n",
            "Epoch 146/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0831 - accuracy: 0.9640 - val_loss: 0.0704 - val_accuracy: 0.9749\n",
            "Epoch 147/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0824 - accuracy: 0.9640 - val_loss: 0.0697 - val_accuracy: 0.9749\n",
            "Epoch 148/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0817 - accuracy: 0.9640 - val_loss: 0.0690 - val_accuracy: 0.9749\n",
            "Epoch 149/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0810 - accuracy: 0.9640 - val_loss: 0.0683 - val_accuracy: 0.9749\n",
            "Epoch 150/200\n",
            "4/4 [==============================] - 0s 24ms/step - loss: 0.0803 - accuracy: 0.9640 - val_loss: 0.0676 - val_accuracy: 0.9749\n",
            "Epoch 151/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0797 - accuracy: 0.9640 - val_loss: 0.0669 - val_accuracy: 0.9749\n",
            "Epoch 152/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0790 - accuracy: 0.9640 - val_loss: 0.0663 - val_accuracy: 0.9749\n",
            "Epoch 153/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0783 - accuracy: 0.9640 - val_loss: 0.0657 - val_accuracy: 0.9749\n",
            "Epoch 154/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0777 - accuracy: 0.9640 - val_loss: 0.0651 - val_accuracy: 0.9749\n",
            "Epoch 155/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0770 - accuracy: 0.9640 - val_loss: 0.0644 - val_accuracy: 0.9749\n",
            "Epoch 156/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0764 - accuracy: 0.9640 - val_loss: 0.0638 - val_accuracy: 0.9749\n",
            "Epoch 157/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0758 - accuracy: 0.9640 - val_loss: 0.0632 - val_accuracy: 0.9749\n",
            "Epoch 158/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0752 - accuracy: 0.9640 - val_loss: 0.0626 - val_accuracy: 0.9749\n",
            "Epoch 159/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0746 - accuracy: 0.9640 - val_loss: 0.0620 - val_accuracy: 0.9749\n",
            "Epoch 160/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0740 - accuracy: 0.9640 - val_loss: 0.0615 - val_accuracy: 0.9749\n",
            "Epoch 161/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0734 - accuracy: 0.9640 - val_loss: 0.0609 - val_accuracy: 0.9749\n",
            "Epoch 162/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0729 - accuracy: 0.9640 - val_loss: 0.0603 - val_accuracy: 0.9749\n",
            "Epoch 163/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0723 - accuracy: 0.9640 - val_loss: 0.0598 - val_accuracy: 0.9749\n",
            "Epoch 164/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0718 - accuracy: 0.9640 - val_loss: 0.0593 - val_accuracy: 0.9749\n",
            "Epoch 165/200\n",
            "4/4 [==============================] - 0s 19ms/step - loss: 0.0712 - accuracy: 0.9640 - val_loss: 0.0587 - val_accuracy: 0.9749\n",
            "Epoch 166/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0707 - accuracy: 0.9640 - val_loss: 0.0582 - val_accuracy: 0.9749\n",
            "Epoch 167/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0702 - accuracy: 0.9640 - val_loss: 0.0577 - val_accuracy: 0.9749\n",
            "Epoch 168/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0697 - accuracy: 0.9640 - val_loss: 0.0572 - val_accuracy: 0.9749\n",
            "Epoch 169/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0692 - accuracy: 0.9640 - val_loss: 0.0567 - val_accuracy: 0.9749\n",
            "Epoch 170/200\n",
            "4/4 [==============================] - 0s 25ms/step - loss: 0.0687 - accuracy: 0.9640 - val_loss: 0.0562 - val_accuracy: 0.9749\n",
            "Epoch 171/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0682 - accuracy: 0.9640 - val_loss: 0.0558 - val_accuracy: 0.9749\n",
            "Epoch 172/200\n",
            "4/4 [==============================] - 0s 18ms/step - loss: 0.0677 - accuracy: 0.9640 - val_loss: 0.0553 - val_accuracy: 0.9749\n",
            "Epoch 173/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0672 - accuracy: 0.9640 - val_loss: 0.0548 - val_accuracy: 0.9749\n",
            "Epoch 174/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0668 - accuracy: 0.9640 - val_loss: 0.0544 - val_accuracy: 0.9749\n",
            "Epoch 175/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0663 - accuracy: 0.9640 - val_loss: 0.0539 - val_accuracy: 0.9749\n",
            "Epoch 176/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0659 - accuracy: 0.9640 - val_loss: 0.0535 - val_accuracy: 0.9749\n",
            "Epoch 177/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0654 - accuracy: 0.9640 - val_loss: 0.0531 - val_accuracy: 0.9749\n",
            "Epoch 178/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0650 - accuracy: 0.9640 - val_loss: 0.0526 - val_accuracy: 0.9749\n",
            "Epoch 179/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0646 - accuracy: 0.9640 - val_loss: 0.0522 - val_accuracy: 0.9749\n",
            "Epoch 180/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0642 - accuracy: 0.9640 - val_loss: 0.0518 - val_accuracy: 0.9749\n",
            "Epoch 181/200\n",
            "4/4 [==============================] - 0s 17ms/step - loss: 0.0638 - accuracy: 0.9640 - val_loss: 0.0514 - val_accuracy: 0.9749\n",
            "Epoch 182/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0633 - accuracy: 0.9640 - val_loss: 0.0510 - val_accuracy: 0.9749\n",
            "Epoch 183/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0630 - accuracy: 0.9640 - val_loss: 0.0506 - val_accuracy: 0.9749\n",
            "Epoch 184/200\n",
            "4/4 [==============================] - 0s 23ms/step - loss: 0.0626 - accuracy: 0.9640 - val_loss: 0.0503 - val_accuracy: 0.9749\n",
            "Epoch 185/200\n",
            "4/4 [==============================] - 0s 22ms/step - loss: 0.0622 - accuracy: 0.9640 - val_loss: 0.0499 - val_accuracy: 0.9749\n",
            "Epoch 186/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0618 - accuracy: 0.9640 - val_loss: 0.0495 - val_accuracy: 0.9749\n",
            "Epoch 187/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0614 - accuracy: 0.9640 - val_loss: 0.0492 - val_accuracy: 0.9749\n",
            "Epoch 188/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0611 - accuracy: 0.9640 - val_loss: 0.0488 - val_accuracy: 0.9749\n",
            "Epoch 189/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0607 - accuracy: 0.9640 - val_loss: 0.0485 - val_accuracy: 0.9749\n",
            "Epoch 190/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0604 - accuracy: 0.9640 - val_loss: 0.0481 - val_accuracy: 0.9749\n",
            "Epoch 191/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0600 - accuracy: 0.9640 - val_loss: 0.0478 - val_accuracy: 0.9749\n",
            "Epoch 192/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0597 - accuracy: 0.9640 - val_loss: 0.0475 - val_accuracy: 0.9749\n",
            "Epoch 193/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0593 - accuracy: 0.9640 - val_loss: 0.0471 - val_accuracy: 0.9749\n",
            "Epoch 194/200\n",
            "4/4 [==============================] - 0s 20ms/step - loss: 0.0590 - accuracy: 0.9640 - val_loss: 0.0468 - val_accuracy: 0.9749\n",
            "Epoch 195/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0587 - accuracy: 0.9640 - val_loss: 0.0465 - val_accuracy: 0.9749\n",
            "Epoch 196/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0584 - accuracy: 0.9640 - val_loss: 0.0462 - val_accuracy: 0.9749\n",
            "Epoch 197/200\n",
            "4/4 [==============================] - 0s 15ms/step - loss: 0.0581 - accuracy: 0.9640 - val_loss: 0.0459 - val_accuracy: 0.9749\n",
            "Epoch 198/200\n",
            "4/4 [==============================] - 0s 16ms/step - loss: 0.0578 - accuracy: 0.9640 - val_loss: 0.0456 - val_accuracy: 0.9749\n",
            "Epoch 199/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0575 - accuracy: 0.9640 - val_loss: 0.0453 - val_accuracy: 0.9749\n",
            "Epoch 200/200\n",
            "4/4 [==============================] - 0s 14ms/step - loss: 0.0572 - accuracy: 0.9640 - val_loss: 0.0450 - val_accuracy: 0.9749\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17805904-14af-46ad-b087-e78d9a506f73",
        "id": "YaK_-7HIb3dI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 2ms/step - loss: 0.0438 - accuracy: 0.9652\n",
            "Test results - Loss: 0.0438043437898159 - Accuracy: 96.51591181755066%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy3_1 = test_results[1]\n",
        "y_pred3_1 = np.where(ae_classifier.predict(X_test).ravel()>=0.5,1,0)\n",
        "y_test3 = y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y2NcAjF-b3dJ",
        "outputId": "520934d8-6419-429a-966e-7270439ede00"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 4"
      ],
      "metadata": {
        "id": "9YCb1RtGb3dJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train4.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test4.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)"
      ],
      "metadata": {
        "id": "yCbJBW77b3dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.label.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5a094cf-2cd7-4f18-e40a-c5e1cd514785",
        "id": "_Bhcuf71b3dJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "abnormal    9078\n",
              "normal      6201\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 362
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_count4 = len(test.index)"
      ],
      "metadata": {
        "id": "FHAt49yzb3dJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "y_train = train[['intrusion']]\n",
        "\n",
        "X_train = train.iloc[:,0:89]\n",
        "\n",
        "#y_test = X_test['intrusion'] # target attribute\n",
        "y_test = test[['intrusion']]\n",
        "\n",
        "# dataset excluding target attribute (encoded, one-hot-encoded,original)\n",
        "X_test = test.iloc[:,0:89]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "y_test = y_test.values\n",
        "input_dim = X_train.shape[1]\n",
        "encoding_dim = 50\n",
        "\n",
        "#input layer\n",
        "input_layer = Input(shape=(input_dim, ))\n",
        "#encoding layer with 50 neurons\n",
        "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)           \n",
        "#decoding and output layer\n",
        "output_layer = Dense(input_dim, activation='softmax')(encoder)\n",
        "\n",
        "autoencoder = Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "autoencoder.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "autoencoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "542cdf19-d2ed-432d-d7cd-bbc65fbf2a3b",
        "id": "qPNELE00b3dL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_47\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_48 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_112 (Dense)           (None, 50)                4500      \n",
            "                                                                 \n",
            " dense_113 (Dense)           (None, 89)                4539      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9,039\n",
            "Trainable params: 9,039\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = autoencoder.fit(X_train, X_train, epochs=100,batch_size=500,validation_data=(X_test, X_test)).history"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6244aaeb-5182-40a8-e525-149cc4a3221e",
        "id": "kIkpt20sb3dM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "31/31 [==============================] - 1s 12ms/step - loss: 0.1049 - accuracy: 0.2594 - val_loss: 0.1683 - val_accuracy: 0.2479\n",
            "Epoch 2/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.1024 - accuracy: 0.4409 - val_loss: 0.1605 - val_accuracy: 0.2742\n",
            "Epoch 3/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0953 - accuracy: 0.4221 - val_loss: 0.1485 - val_accuracy: 0.3270\n",
            "Epoch 4/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0913 - accuracy: 0.4349 - val_loss: 0.1373 - val_accuracy: 0.7905\n",
            "Epoch 5/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0896 - accuracy: 0.5114 - val_loss: 0.1361 - val_accuracy: 0.8079\n",
            "Epoch 6/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0887 - accuracy: 0.5344 - val_loss: 0.1354 - val_accuracy: 0.8317\n",
            "Epoch 7/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0882 - accuracy: 0.5562 - val_loss: 0.1348 - val_accuracy: 0.7899\n",
            "Epoch 8/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0880 - accuracy: 0.5193 - val_loss: 0.1344 - val_accuracy: 0.7468\n",
            "Epoch 9/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0878 - accuracy: 0.5266 - val_loss: 0.1341 - val_accuracy: 0.7143\n",
            "Epoch 10/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0876 - accuracy: 0.5141 - val_loss: 0.1340 - val_accuracy: 0.6775\n",
            "Epoch 11/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0875 - accuracy: 0.4836 - val_loss: 0.1338 - val_accuracy: 0.6657\n",
            "Epoch 12/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.4333 - val_loss: 0.1337 - val_accuracy: 0.6633\n",
            "Epoch 13/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.4418 - val_loss: 0.1337 - val_accuracy: 0.6785\n",
            "Epoch 14/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0873 - accuracy: 0.4572 - val_loss: 0.1337 - val_accuracy: 0.6981\n",
            "Epoch 15/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0873 - accuracy: 0.4568 - val_loss: 0.1336 - val_accuracy: 0.6770\n",
            "Epoch 16/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.4352 - val_loss: 0.1336 - val_accuracy: 0.7114\n",
            "Epoch 17/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0872 - accuracy: 0.4536 - val_loss: 0.1336 - val_accuracy: 0.6997\n",
            "Epoch 18/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0872 - accuracy: 0.4367 - val_loss: 0.1336 - val_accuracy: 0.7312\n",
            "Epoch 19/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0872 - accuracy: 0.4621 - val_loss: 0.1336 - val_accuracy: 0.7230\n",
            "Epoch 20/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0871 - accuracy: 0.4598 - val_loss: 0.1334 - val_accuracy: 0.7468\n",
            "Epoch 21/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0869 - accuracy: 0.4919 - val_loss: 0.1334 - val_accuracy: 0.7513\n",
            "Epoch 22/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0869 - accuracy: 0.5233 - val_loss: 0.1334 - val_accuracy: 0.7935\n",
            "Epoch 23/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0869 - accuracy: 0.5103 - val_loss: 0.1334 - val_accuracy: 0.7925\n",
            "Epoch 24/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0869 - accuracy: 0.5193 - val_loss: 0.1334 - val_accuracy: 0.7685\n",
            "Epoch 25/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.5111 - val_loss: 0.1334 - val_accuracy: 0.7517\n",
            "Epoch 26/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.5019 - val_loss: 0.1334 - val_accuracy: 0.8077\n",
            "Epoch 27/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.5087 - val_loss: 0.1333 - val_accuracy: 0.7925\n",
            "Epoch 28/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5136 - val_loss: 0.1333 - val_accuracy: 0.7733\n",
            "Epoch 29/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.4998 - val_loss: 0.1333 - val_accuracy: 0.7729\n",
            "Epoch 30/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.4976 - val_loss: 0.1333 - val_accuracy: 0.7935\n",
            "Epoch 31/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5147 - val_loss: 0.1333 - val_accuracy: 0.7877\n",
            "Epoch 32/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5146 - val_loss: 0.1333 - val_accuracy: 0.7887\n",
            "Epoch 33/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5064 - val_loss: 0.1333 - val_accuracy: 0.7798\n",
            "Epoch 34/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5116 - val_loss: 0.1333 - val_accuracy: 0.8162\n",
            "Epoch 35/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5085 - val_loss: 0.1333 - val_accuracy: 0.7939\n",
            "Epoch 36/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5155 - val_loss: 0.1333 - val_accuracy: 0.7515\n",
            "Epoch 37/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5176 - val_loss: 0.1333 - val_accuracy: 0.8044\n",
            "Epoch 38/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5145 - val_loss: 0.1333 - val_accuracy: 0.7982\n",
            "Epoch 39/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.5019 - val_loss: 0.1333 - val_accuracy: 0.8127\n",
            "Epoch 40/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5109 - val_loss: 0.1333 - val_accuracy: 0.8002\n",
            "Epoch 41/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5193 - val_loss: 0.1333 - val_accuracy: 0.7832\n",
            "Epoch 42/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.5256 - val_loss: 0.1333 - val_accuracy: 0.7982\n",
            "Epoch 43/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.5280 - val_loss: 0.1333 - val_accuracy: 0.7430\n",
            "Epoch 44/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5147 - val_loss: 0.1333 - val_accuracy: 0.7782\n",
            "Epoch 45/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5229 - val_loss: 0.1334 - val_accuracy: 0.7935\n",
            "Epoch 46/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5249 - val_loss: 0.1334 - val_accuracy: 0.7885\n",
            "Epoch 47/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5229 - val_loss: 0.1334 - val_accuracy: 0.7280\n",
            "Epoch 48/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5214 - val_loss: 0.1334 - val_accuracy: 0.7666\n",
            "Epoch 49/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5304 - val_loss: 0.1334 - val_accuracy: 0.7480\n",
            "Epoch 50/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.5365 - val_loss: 0.1334 - val_accuracy: 0.7812\n",
            "Epoch 51/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5330 - val_loss: 0.1334 - val_accuracy: 0.7213\n",
            "Epoch 52/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5277 - val_loss: 0.1334 - val_accuracy: 0.7670\n",
            "Epoch 53/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5410 - val_loss: 0.1334 - val_accuracy: 0.7555\n",
            "Epoch 54/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5431 - val_loss: 0.1334 - val_accuracy: 0.7302\n",
            "Epoch 55/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5227 - val_loss: 0.1334 - val_accuracy: 0.7945\n",
            "Epoch 56/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.5278 - val_loss: 0.1334 - val_accuracy: 0.7361\n",
            "Epoch 57/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5314 - val_loss: 0.1334 - val_accuracy: 0.7794\n",
            "Epoch 58/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5365 - val_loss: 0.1334 - val_accuracy: 0.7992\n",
            "Epoch 59/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5284 - val_loss: 0.1334 - val_accuracy: 0.8057\n",
            "Epoch 60/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5333 - val_loss: 0.1334 - val_accuracy: 0.7539\n",
            "Epoch 61/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5371 - val_loss: 0.1334 - val_accuracy: 0.7931\n",
            "Epoch 62/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.5450 - val_loss: 0.1334 - val_accuracy: 0.7501\n",
            "Epoch 63/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5219 - val_loss: 0.1334 - val_accuracy: 0.7405\n",
            "Epoch 64/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0868 - accuracy: 0.5253 - val_loss: 0.1334 - val_accuracy: 0.7614\n",
            "Epoch 65/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5432 - val_loss: 0.1334 - val_accuracy: 0.7701\n",
            "Epoch 66/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0868 - accuracy: 0.5375 - val_loss: 0.1334 - val_accuracy: 0.7634\n",
            "Epoch 67/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0868 - accuracy: 0.5264 - val_loss: 0.1334 - val_accuracy: 0.7401\n",
            "Epoch 68/100\n",
            "31/31 [==============================] - 0s 10ms/step - loss: 0.0868 - accuracy: 0.5258 - val_loss: 0.1334 - val_accuracy: 0.7515\n",
            "Epoch 69/100\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0868 - accuracy: 0.5582 - val_loss: 0.1334 - val_accuracy: 0.7784\n",
            "Epoch 70/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0868 - accuracy: 0.5534 - val_loss: 0.1334 - val_accuracy: 0.7879\n",
            "Epoch 71/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5460 - val_loss: 0.1334 - val_accuracy: 0.7836\n",
            "Epoch 72/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5459 - val_loss: 0.1334 - val_accuracy: 0.7921\n",
            "Epoch 73/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5459 - val_loss: 0.1334 - val_accuracy: 0.8324\n",
            "Epoch 74/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5445 - val_loss: 0.1334 - val_accuracy: 0.8162\n",
            "Epoch 75/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5468 - val_loss: 0.1334 - val_accuracy: 0.7933\n",
            "Epoch 76/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.5419 - val_loss: 0.1334 - val_accuracy: 0.7456\n",
            "Epoch 77/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.5364 - val_loss: 0.1334 - val_accuracy: 0.7124\n",
            "Epoch 78/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.5320 - val_loss: 0.1334 - val_accuracy: 0.8275\n",
            "Epoch 79/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.5358 - val_loss: 0.1334 - val_accuracy: 0.8200\n",
            "Epoch 80/100\n",
            "31/31 [==============================] - 0s 6ms/step - loss: 0.0867 - accuracy: 0.5452 - val_loss: 0.1334 - val_accuracy: 0.8516\n",
            "Epoch 81/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.5443 - val_loss: 0.1334 - val_accuracy: 0.7935\n",
            "Epoch 82/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.5466 - val_loss: 0.1334 - val_accuracy: 0.7610\n",
            "Epoch 83/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.5472 - val_loss: 0.1334 - val_accuracy: 0.8097\n",
            "Epoch 84/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.5447 - val_loss: 0.1334 - val_accuracy: 0.8045\n",
            "Epoch 85/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0867 - accuracy: 0.5490 - val_loss: 0.1334 - val_accuracy: 0.7300\n",
            "Epoch 86/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0867 - accuracy: 0.5371 - val_loss: 0.1334 - val_accuracy: 0.7810\n",
            "Epoch 87/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5414 - val_loss: 0.1334 - val_accuracy: 0.7434\n",
            "Epoch 88/100\n",
            "31/31 [==============================] - 0s 12ms/step - loss: 0.0867 - accuracy: 0.5341 - val_loss: 0.1335 - val_accuracy: 0.7448\n",
            "Epoch 89/100\n",
            "31/31 [==============================] - 0s 13ms/step - loss: 0.0867 - accuracy: 0.5346 - val_loss: 0.1335 - val_accuracy: 0.7913\n",
            "Epoch 90/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5349 - val_loss: 0.1334 - val_accuracy: 0.7636\n",
            "Epoch 91/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5504 - val_loss: 0.1335 - val_accuracy: 0.7956\n",
            "Epoch 92/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5463 - val_loss: 0.1335 - val_accuracy: 0.8125\n",
            "Epoch 93/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5460 - val_loss: 0.1335 - val_accuracy: 0.8057\n",
            "Epoch 94/100\n",
            "31/31 [==============================] - 0s 11ms/step - loss: 0.0867 - accuracy: 0.5479 - val_loss: 0.1335 - val_accuracy: 0.7094\n",
            "Epoch 95/100\n",
            "31/31 [==============================] - 0s 9ms/step - loss: 0.0867 - accuracy: 0.5312 - val_loss: 0.1335 - val_accuracy: 0.7490\n",
            "Epoch 96/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.5409 - val_loss: 0.1335 - val_accuracy: 0.7290\n",
            "Epoch 97/100\n",
            "31/31 [==============================] - 0s 8ms/step - loss: 0.0867 - accuracy: 0.5292 - val_loss: 0.1335 - val_accuracy: 0.7573\n",
            "Epoch 98/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.5282 - val_loss: 0.1335 - val_accuracy: 0.7561\n",
            "Epoch 99/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.5436 - val_loss: 0.1335 - val_accuracy: 0.8063\n",
            "Epoch 100/100\n",
            "31/31 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.5411 - val_loss: 0.1335 - val_accuracy: 0.7862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = autoencoder.predict(X_test)\n",
        "i_dim = predictions.shape[1]\n",
        "\n",
        "#input layer\n",
        "i_layer = Input(shape=(i_dim, ))\n",
        "#hidden layer with 48 neurons\n",
        "fvector = Dense(48, activation=\"sigmoid\")(i_layer)   \n",
        "#fvector = Dense(24, activation='tanh')(fvector)                 \n",
        "#doutput layer\n",
        "o_layer = Dense(1, activation='sigmoid')(fvector)\n",
        "\n",
        "# creating model with input, encoding, decoding, output layers\n",
        "ae_classifier = Model(inputs=i_layer, outputs=o_layer)\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "ae_classifier.compile(optimizer='adam', loss='mean_squared_error',metrics=['accuracy'])\n",
        "\n",
        "ae_classifier.summary()"
      ],
      "metadata": {
        "id": "0m89qoXOb3dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c817eb07-f2e1-4a60-ceed-5f1ec58f8e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 1ms/step\n",
            "Model: \"model_48\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_49 (InputLayer)       [(None, 89)]              0         \n",
            "                                                                 \n",
            " dense_114 (Dense)           (None, 48)                4320      \n",
            "                                                                 \n",
            " dense_115 (Dense)           (None, 1)                 49        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,369\n",
            "Trainable params: 4,369\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "his = ae_classifier.fit(predictions, y_test, epochs=200,batch_size=700, validation_split=0.2).history"
      ],
      "metadata": {
        "id": "Zw943Bncb3dM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f45bd5e7-5b06-4d9d-c2b3-1f3857969d8f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "6/6 [==============================] - 1s 60ms/step - loss: 0.1757 - accuracy: 0.8835 - val_loss: 0.1627 - val_accuracy: 0.8853\n",
            "Epoch 2/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1558 - accuracy: 0.8835 - val_loss: 0.1454 - val_accuracy: 0.8853\n",
            "Epoch 3/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1405 - accuracy: 0.8835 - val_loss: 0.1321 - val_accuracy: 0.8853\n",
            "Epoch 4/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1288 - accuracy: 0.8835 - val_loss: 0.1225 - val_accuracy: 0.8853\n",
            "Epoch 5/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1204 - accuracy: 0.8835 - val_loss: 0.1157 - val_accuracy: 0.8853\n",
            "Epoch 6/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1146 - accuracy: 0.8835 - val_loss: 0.1109 - val_accuracy: 0.8853\n",
            "Epoch 7/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1104 - accuracy: 0.8835 - val_loss: 0.1076 - val_accuracy: 0.8853\n",
            "Epoch 8/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.1076 - accuracy: 0.8835 - val_loss: 0.1053 - val_accuracy: 0.8853\n",
            "Epoch 9/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.1056 - accuracy: 0.8835 - val_loss: 0.1036 - val_accuracy: 0.8853\n",
            "Epoch 10/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1042 - accuracy: 0.8835 - val_loss: 0.1024 - val_accuracy: 0.8853\n",
            "Epoch 11/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1031 - accuracy: 0.8835 - val_loss: 0.1015 - val_accuracy: 0.8853\n",
            "Epoch 12/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1023 - accuracy: 0.8835 - val_loss: 0.1008 - val_accuracy: 0.8853\n",
            "Epoch 13/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.1017 - accuracy: 0.8835 - val_loss: 0.1002 - val_accuracy: 0.8853\n",
            "Epoch 14/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.1011 - accuracy: 0.8835 - val_loss: 0.0998 - val_accuracy: 0.8853\n",
            "Epoch 15/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.1007 - accuracy: 0.8835 - val_loss: 0.0994 - val_accuracy: 0.8853\n",
            "Epoch 16/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1003 - accuracy: 0.8835 - val_loss: 0.0990 - val_accuracy: 0.8853\n",
            "Epoch 17/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.1000 - accuracy: 0.8835 - val_loss: 0.0987 - val_accuracy: 0.8853\n",
            "Epoch 18/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0996 - accuracy: 0.8835 - val_loss: 0.0984 - val_accuracy: 0.8853\n",
            "Epoch 19/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0993 - accuracy: 0.8835 - val_loss: 0.0981 - val_accuracy: 0.8853\n",
            "Epoch 20/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0991 - accuracy: 0.8835 - val_loss: 0.0978 - val_accuracy: 0.8853\n",
            "Epoch 21/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0988 - accuracy: 0.8835 - val_loss: 0.0976 - val_accuracy: 0.8853\n",
            "Epoch 22/200\n",
            "6/6 [==============================] - 0s 20ms/step - loss: 0.0985 - accuracy: 0.8835 - val_loss: 0.0973 - val_accuracy: 0.8853\n",
            "Epoch 23/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0983 - accuracy: 0.8835 - val_loss: 0.0971 - val_accuracy: 0.8853\n",
            "Epoch 24/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0980 - accuracy: 0.8835 - val_loss: 0.0969 - val_accuracy: 0.8853\n",
            "Epoch 25/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0978 - accuracy: 0.8835 - val_loss: 0.0966 - val_accuracy: 0.8853\n",
            "Epoch 26/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0975 - accuracy: 0.8835 - val_loss: 0.0964 - val_accuracy: 0.8853\n",
            "Epoch 27/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0973 - accuracy: 0.8835 - val_loss: 0.0961 - val_accuracy: 0.8853\n",
            "Epoch 28/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0970 - accuracy: 0.8835 - val_loss: 0.0959 - val_accuracy: 0.8853\n",
            "Epoch 29/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0968 - accuracy: 0.8835 - val_loss: 0.0957 - val_accuracy: 0.8853\n",
            "Epoch 30/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0965 - accuracy: 0.8835 - val_loss: 0.0954 - val_accuracy: 0.8853\n",
            "Epoch 31/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0962 - accuracy: 0.8835 - val_loss: 0.0952 - val_accuracy: 0.8853\n",
            "Epoch 32/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0960 - accuracy: 0.8835 - val_loss: 0.0949 - val_accuracy: 0.8853\n",
            "Epoch 33/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0957 - accuracy: 0.8835 - val_loss: 0.0947 - val_accuracy: 0.8853\n",
            "Epoch 34/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0954 - accuracy: 0.8835 - val_loss: 0.0944 - val_accuracy: 0.8853\n",
            "Epoch 35/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0952 - accuracy: 0.8835 - val_loss: 0.0942 - val_accuracy: 0.8853\n",
            "Epoch 36/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0949 - accuracy: 0.8835 - val_loss: 0.0939 - val_accuracy: 0.8853\n",
            "Epoch 37/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0946 - accuracy: 0.8835 - val_loss: 0.0937 - val_accuracy: 0.8853\n",
            "Epoch 38/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0943 - accuracy: 0.8835 - val_loss: 0.0934 - val_accuracy: 0.8853\n",
            "Epoch 39/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0941 - accuracy: 0.8835 - val_loss: 0.0932 - val_accuracy: 0.8853\n",
            "Epoch 40/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0938 - accuracy: 0.8835 - val_loss: 0.0929 - val_accuracy: 0.8853\n",
            "Epoch 41/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0935 - accuracy: 0.8835 - val_loss: 0.0926 - val_accuracy: 0.8853\n",
            "Epoch 42/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0932 - accuracy: 0.8835 - val_loss: 0.0924 - val_accuracy: 0.8853\n",
            "Epoch 43/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0929 - accuracy: 0.8835 - val_loss: 0.0921 - val_accuracy: 0.8853\n",
            "Epoch 44/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0926 - accuracy: 0.8835 - val_loss: 0.0918 - val_accuracy: 0.8853\n",
            "Epoch 45/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0923 - accuracy: 0.8835 - val_loss: 0.0916 - val_accuracy: 0.8853\n",
            "Epoch 46/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0920 - accuracy: 0.8835 - val_loss: 0.0913 - val_accuracy: 0.8853\n",
            "Epoch 47/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0917 - accuracy: 0.8835 - val_loss: 0.0910 - val_accuracy: 0.8853\n",
            "Epoch 48/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0914 - accuracy: 0.8835 - val_loss: 0.0907 - val_accuracy: 0.8853\n",
            "Epoch 49/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0911 - accuracy: 0.8835 - val_loss: 0.0904 - val_accuracy: 0.8853\n",
            "Epoch 50/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0908 - accuracy: 0.8835 - val_loss: 0.0901 - val_accuracy: 0.8853\n",
            "Epoch 51/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0905 - accuracy: 0.8835 - val_loss: 0.0899 - val_accuracy: 0.8853\n",
            "Epoch 52/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0902 - accuracy: 0.8835 - val_loss: 0.0896 - val_accuracy: 0.8853\n",
            "Epoch 53/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0898 - accuracy: 0.8835 - val_loss: 0.0893 - val_accuracy: 0.8853\n",
            "Epoch 54/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0895 - accuracy: 0.8835 - val_loss: 0.0890 - val_accuracy: 0.8853\n",
            "Epoch 55/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0892 - accuracy: 0.8835 - val_loss: 0.0887 - val_accuracy: 0.8853\n",
            "Epoch 56/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0889 - accuracy: 0.8835 - val_loss: 0.0884 - val_accuracy: 0.8853\n",
            "Epoch 57/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0886 - accuracy: 0.8835 - val_loss: 0.0881 - val_accuracy: 0.8853\n",
            "Epoch 58/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0882 - accuracy: 0.8835 - val_loss: 0.0878 - val_accuracy: 0.8853\n",
            "Epoch 59/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0879 - accuracy: 0.8835 - val_loss: 0.0875 - val_accuracy: 0.8853\n",
            "Epoch 60/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0876 - accuracy: 0.8835 - val_loss: 0.0872 - val_accuracy: 0.8853\n",
            "Epoch 61/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0872 - accuracy: 0.8835 - val_loss: 0.0869 - val_accuracy: 0.8853\n",
            "Epoch 62/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0869 - accuracy: 0.8835 - val_loss: 0.0866 - val_accuracy: 0.8853\n",
            "Epoch 63/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0866 - accuracy: 0.8835 - val_loss: 0.0863 - val_accuracy: 0.8853\n",
            "Epoch 64/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0862 - accuracy: 0.8835 - val_loss: 0.0860 - val_accuracy: 0.8853\n",
            "Epoch 65/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0859 - accuracy: 0.8835 - val_loss: 0.0856 - val_accuracy: 0.8853\n",
            "Epoch 66/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0855 - accuracy: 0.8835 - val_loss: 0.0853 - val_accuracy: 0.8853\n",
            "Epoch 67/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0852 - accuracy: 0.8835 - val_loss: 0.0850 - val_accuracy: 0.8853\n",
            "Epoch 68/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0849 - accuracy: 0.8835 - val_loss: 0.0847 - val_accuracy: 0.8853\n",
            "Epoch 69/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0845 - accuracy: 0.8835 - val_loss: 0.0844 - val_accuracy: 0.8853\n",
            "Epoch 70/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0842 - accuracy: 0.8835 - val_loss: 0.0841 - val_accuracy: 0.8853\n",
            "Epoch 71/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0838 - accuracy: 0.8835 - val_loss: 0.0838 - val_accuracy: 0.8853\n",
            "Epoch 72/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0835 - accuracy: 0.8835 - val_loss: 0.0835 - val_accuracy: 0.8853\n",
            "Epoch 73/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0832 - accuracy: 0.8835 - val_loss: 0.0832 - val_accuracy: 0.8853\n",
            "Epoch 74/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0828 - accuracy: 0.8835 - val_loss: 0.0828 - val_accuracy: 0.8853\n",
            "Epoch 75/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0825 - accuracy: 0.8835 - val_loss: 0.0825 - val_accuracy: 0.8853\n",
            "Epoch 76/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0821 - accuracy: 0.8835 - val_loss: 0.0822 - val_accuracy: 0.8853\n",
            "Epoch 77/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0818 - accuracy: 0.8835 - val_loss: 0.0819 - val_accuracy: 0.8853\n",
            "Epoch 78/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0815 - accuracy: 0.8835 - val_loss: 0.0816 - val_accuracy: 0.8853\n",
            "Epoch 79/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0811 - accuracy: 0.8835 - val_loss: 0.0813 - val_accuracy: 0.8853\n",
            "Epoch 80/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0808 - accuracy: 0.8835 - val_loss: 0.0810 - val_accuracy: 0.8853\n",
            "Epoch 81/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0805 - accuracy: 0.8835 - val_loss: 0.0807 - val_accuracy: 0.8853\n",
            "Epoch 82/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0801 - accuracy: 0.8835 - val_loss: 0.0804 - val_accuracy: 0.8853\n",
            "Epoch 83/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0798 - accuracy: 0.8835 - val_loss: 0.0801 - val_accuracy: 0.8853\n",
            "Epoch 84/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0795 - accuracy: 0.8835 - val_loss: 0.0798 - val_accuracy: 0.8853\n",
            "Epoch 85/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0791 - accuracy: 0.8835 - val_loss: 0.0795 - val_accuracy: 0.8853\n",
            "Epoch 86/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0788 - accuracy: 0.8835 - val_loss: 0.0792 - val_accuracy: 0.8853\n",
            "Epoch 87/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0785 - accuracy: 0.8835 - val_loss: 0.0789 - val_accuracy: 0.8853\n",
            "Epoch 88/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0782 - accuracy: 0.8835 - val_loss: 0.0786 - val_accuracy: 0.8853\n",
            "Epoch 89/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0779 - accuracy: 0.8835 - val_loss: 0.0783 - val_accuracy: 0.8853\n",
            "Epoch 90/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0775 - accuracy: 0.8835 - val_loss: 0.0781 - val_accuracy: 0.8853\n",
            "Epoch 91/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0772 - accuracy: 0.8835 - val_loss: 0.0778 - val_accuracy: 0.8853\n",
            "Epoch 92/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0769 - accuracy: 0.8835 - val_loss: 0.0775 - val_accuracy: 0.8853\n",
            "Epoch 93/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0766 - accuracy: 0.8835 - val_loss: 0.0772 - val_accuracy: 0.8853\n",
            "Epoch 94/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0764 - accuracy: 0.8835 - val_loss: 0.0770 - val_accuracy: 0.8853\n",
            "Epoch 95/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0761 - accuracy: 0.8835 - val_loss: 0.0767 - val_accuracy: 0.8853\n",
            "Epoch 96/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0758 - accuracy: 0.8835 - val_loss: 0.0765 - val_accuracy: 0.8853\n",
            "Epoch 97/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0755 - accuracy: 0.8835 - val_loss: 0.0762 - val_accuracy: 0.8853\n",
            "Epoch 98/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0752 - accuracy: 0.8835 - val_loss: 0.0760 - val_accuracy: 0.8853\n",
            "Epoch 99/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0749 - accuracy: 0.8835 - val_loss: 0.0757 - val_accuracy: 0.8853\n",
            "Epoch 100/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0747 - accuracy: 0.8835 - val_loss: 0.0755 - val_accuracy: 0.8853\n",
            "Epoch 101/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0744 - accuracy: 0.8835 - val_loss: 0.0752 - val_accuracy: 0.8853\n",
            "Epoch 102/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0741 - accuracy: 0.8835 - val_loss: 0.0750 - val_accuracy: 0.8853\n",
            "Epoch 103/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0739 - accuracy: 0.8835 - val_loss: 0.0748 - val_accuracy: 0.8853\n",
            "Epoch 104/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0736 - accuracy: 0.8835 - val_loss: 0.0746 - val_accuracy: 0.8853\n",
            "Epoch 105/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0734 - accuracy: 0.8835 - val_loss: 0.0743 - val_accuracy: 0.8853\n",
            "Epoch 106/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0732 - accuracy: 0.8835 - val_loss: 0.0741 - val_accuracy: 0.8853\n",
            "Epoch 107/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0729 - accuracy: 0.8835 - val_loss: 0.0739 - val_accuracy: 0.8853\n",
            "Epoch 108/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0727 - accuracy: 0.8838 - val_loss: 0.0737 - val_accuracy: 0.8912\n",
            "Epoch 109/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0725 - accuracy: 0.8848 - val_loss: 0.0735 - val_accuracy: 0.8922\n",
            "Epoch 110/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0723 - accuracy: 0.8897 - val_loss: 0.0733 - val_accuracy: 0.8922\n",
            "Epoch 111/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0721 - accuracy: 0.8900 - val_loss: 0.0731 - val_accuracy: 0.8932\n",
            "Epoch 112/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0718 - accuracy: 0.8900 - val_loss: 0.0729 - val_accuracy: 0.8932\n",
            "Epoch 113/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0716 - accuracy: 0.8900 - val_loss: 0.0728 - val_accuracy: 0.8932\n",
            "Epoch 114/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0714 - accuracy: 0.8900 - val_loss: 0.0726 - val_accuracy: 0.8932\n",
            "Epoch 115/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0712 - accuracy: 0.8900 - val_loss: 0.0724 - val_accuracy: 0.8932\n",
            "Epoch 116/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0711 - accuracy: 0.8900 - val_loss: 0.0722 - val_accuracy: 0.8922\n",
            "Epoch 117/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0709 - accuracy: 0.8870 - val_loss: 0.0721 - val_accuracy: 0.8892\n",
            "Epoch 118/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0707 - accuracy: 0.8860 - val_loss: 0.0719 - val_accuracy: 0.8882\n",
            "Epoch 119/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0705 - accuracy: 0.8855 - val_loss: 0.0718 - val_accuracy: 0.8882\n",
            "Epoch 120/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0704 - accuracy: 0.8855 - val_loss: 0.0716 - val_accuracy: 0.8882\n",
            "Epoch 121/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0702 - accuracy: 0.8853 - val_loss: 0.0715 - val_accuracy: 0.8882\n",
            "Epoch 122/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0700 - accuracy: 0.8853 - val_loss: 0.0713 - val_accuracy: 0.8882\n",
            "Epoch 123/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0699 - accuracy: 0.8850 - val_loss: 0.0712 - val_accuracy: 0.8882\n",
            "Epoch 124/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0697 - accuracy: 0.8850 - val_loss: 0.0711 - val_accuracy: 0.8882\n",
            "Epoch 125/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0696 - accuracy: 0.8850 - val_loss: 0.0709 - val_accuracy: 0.8882\n",
            "Epoch 126/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0695 - accuracy: 0.8850 - val_loss: 0.0708 - val_accuracy: 0.8882\n",
            "Epoch 127/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0693 - accuracy: 0.8848 - val_loss: 0.0707 - val_accuracy: 0.8882\n",
            "Epoch 128/200\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0692 - accuracy: 0.8848 - val_loss: 0.0706 - val_accuracy: 0.8882\n",
            "Epoch 129/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0691 - accuracy: 0.8848 - val_loss: 0.0705 - val_accuracy: 0.8882\n",
            "Epoch 130/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0689 - accuracy: 0.8850 - val_loss: 0.0704 - val_accuracy: 0.8882\n",
            "Epoch 131/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0688 - accuracy: 0.8850 - val_loss: 0.0702 - val_accuracy: 0.8882\n",
            "Epoch 132/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0687 - accuracy: 0.8850 - val_loss: 0.0701 - val_accuracy: 0.8882\n",
            "Epoch 133/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0686 - accuracy: 0.8850 - val_loss: 0.0700 - val_accuracy: 0.8882\n",
            "Epoch 134/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0685 - accuracy: 0.8850 - val_loss: 0.0699 - val_accuracy: 0.8872\n",
            "Epoch 135/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0684 - accuracy: 0.8850 - val_loss: 0.0699 - val_accuracy: 0.8872\n",
            "Epoch 136/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0683 - accuracy: 0.8850 - val_loss: 0.0698 - val_accuracy: 0.8872\n",
            "Epoch 137/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0682 - accuracy: 0.8850 - val_loss: 0.0697 - val_accuracy: 0.8872\n",
            "Epoch 138/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0681 - accuracy: 0.8850 - val_loss: 0.0696 - val_accuracy: 0.8872\n",
            "Epoch 139/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0680 - accuracy: 0.8850 - val_loss: 0.0695 - val_accuracy: 0.8872\n",
            "Epoch 140/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0679 - accuracy: 0.8850 - val_loss: 0.0694 - val_accuracy: 0.8872\n",
            "Epoch 141/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0678 - accuracy: 0.8850 - val_loss: 0.0694 - val_accuracy: 0.8872\n",
            "Epoch 142/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0677 - accuracy: 0.8850 - val_loss: 0.0693 - val_accuracy: 0.8872\n",
            "Epoch 143/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0676 - accuracy: 0.8850 - val_loss: 0.0692 - val_accuracy: 0.8872\n",
            "Epoch 144/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0675 - accuracy: 0.8850 - val_loss: 0.0691 - val_accuracy: 0.8872\n",
            "Epoch 145/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0675 - accuracy: 0.8848 - val_loss: 0.0691 - val_accuracy: 0.8872\n",
            "Epoch 146/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0674 - accuracy: 0.8848 - val_loss: 0.0690 - val_accuracy: 0.8872\n",
            "Epoch 147/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0673 - accuracy: 0.8848 - val_loss: 0.0689 - val_accuracy: 0.8872\n",
            "Epoch 148/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0672 - accuracy: 0.8848 - val_loss: 0.0689 - val_accuracy: 0.8872\n",
            "Epoch 149/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0672 - accuracy: 0.8848 - val_loss: 0.0688 - val_accuracy: 0.8872\n",
            "Epoch 150/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0671 - accuracy: 0.8848 - val_loss: 0.0688 - val_accuracy: 0.8872\n",
            "Epoch 151/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0670 - accuracy: 0.8848 - val_loss: 0.0687 - val_accuracy: 0.8872\n",
            "Epoch 152/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0670 - accuracy: 0.8848 - val_loss: 0.0687 - val_accuracy: 0.8872\n",
            "Epoch 153/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0669 - accuracy: 0.8848 - val_loss: 0.0686 - val_accuracy: 0.8872\n",
            "Epoch 154/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0669 - accuracy: 0.8848 - val_loss: 0.0686 - val_accuracy: 0.8872\n",
            "Epoch 155/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0668 - accuracy: 0.8848 - val_loss: 0.0685 - val_accuracy: 0.8872\n",
            "Epoch 156/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0668 - accuracy: 0.8848 - val_loss: 0.0685 - val_accuracy: 0.8872\n",
            "Epoch 157/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0667 - accuracy: 0.8848 - val_loss: 0.0684 - val_accuracy: 0.8872\n",
            "Epoch 158/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0667 - accuracy: 0.8848 - val_loss: 0.0684 - val_accuracy: 0.8872\n",
            "Epoch 159/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0666 - accuracy: 0.8848 - val_loss: 0.0683 - val_accuracy: 0.8872\n",
            "Epoch 160/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0666 - accuracy: 0.8848 - val_loss: 0.0683 - val_accuracy: 0.8872\n",
            "Epoch 161/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0665 - accuracy: 0.8848 - val_loss: 0.0683 - val_accuracy: 0.8872\n",
            "Epoch 162/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0665 - accuracy: 0.8848 - val_loss: 0.0682 - val_accuracy: 0.8872\n",
            "Epoch 163/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0664 - accuracy: 0.8848 - val_loss: 0.0682 - val_accuracy: 0.8872\n",
            "Epoch 164/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0664 - accuracy: 0.8848 - val_loss: 0.0682 - val_accuracy: 0.8872\n",
            "Epoch 165/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0663 - accuracy: 0.8850 - val_loss: 0.0681 - val_accuracy: 0.8872\n",
            "Epoch 166/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0663 - accuracy: 0.8850 - val_loss: 0.0681 - val_accuracy: 0.8872\n",
            "Epoch 167/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0663 - accuracy: 0.8850 - val_loss: 0.0681 - val_accuracy: 0.8872\n",
            "Epoch 168/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0662 - accuracy: 0.8850 - val_loss: 0.0680 - val_accuracy: 0.8872\n",
            "Epoch 169/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0662 - accuracy: 0.8850 - val_loss: 0.0680 - val_accuracy: 0.8872\n",
            "Epoch 170/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0662 - accuracy: 0.8850 - val_loss: 0.0680 - val_accuracy: 0.8872\n",
            "Epoch 171/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0661 - accuracy: 0.8850 - val_loss: 0.0680 - val_accuracy: 0.8872\n",
            "Epoch 172/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0661 - accuracy: 0.8850 - val_loss: 0.0679 - val_accuracy: 0.8872\n",
            "Epoch 173/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0661 - accuracy: 0.8816 - val_loss: 0.0679 - val_accuracy: 0.8754\n",
            "Epoch 174/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0660 - accuracy: 0.8731 - val_loss: 0.0679 - val_accuracy: 0.8754\n",
            "Epoch 175/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0660 - accuracy: 0.8793 - val_loss: 0.0679 - val_accuracy: 0.8843\n",
            "Epoch 176/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0660 - accuracy: 0.8773 - val_loss: 0.0678 - val_accuracy: 0.8754\n",
            "Epoch 177/200\n",
            "6/6 [==============================] - 0s 19ms/step - loss: 0.0659 - accuracy: 0.8709 - val_loss: 0.0678 - val_accuracy: 0.8744\n",
            "Epoch 178/200\n",
            "6/6 [==============================] - 0s 18ms/step - loss: 0.0659 - accuracy: 0.8828 - val_loss: 0.0678 - val_accuracy: 0.8902\n",
            "Epoch 179/200\n",
            "6/6 [==============================] - 0s 21ms/step - loss: 0.0659 - accuracy: 0.8984 - val_loss: 0.0678 - val_accuracy: 0.8902\n",
            "Epoch 180/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0659 - accuracy: 0.8986 - val_loss: 0.0678 - val_accuracy: 0.8902\n",
            "Epoch 181/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0658 - accuracy: 0.8991 - val_loss: 0.0677 - val_accuracy: 0.8922\n",
            "Epoch 182/200\n",
            "6/6 [==============================] - 0s 17ms/step - loss: 0.0658 - accuracy: 0.8991 - val_loss: 0.0677 - val_accuracy: 0.8902\n",
            "Epoch 183/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0658 - accuracy: 0.8984 - val_loss: 0.0677 - val_accuracy: 0.8882\n",
            "Epoch 184/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0658 - accuracy: 0.8986 - val_loss: 0.0677 - val_accuracy: 0.8922\n",
            "Epoch 185/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0657 - accuracy: 0.8999 - val_loss: 0.0677 - val_accuracy: 0.8922\n",
            "Epoch 186/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0657 - accuracy: 0.9001 - val_loss: 0.0677 - val_accuracy: 0.8922\n",
            "Epoch 187/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0657 - accuracy: 0.9001 - val_loss: 0.0676 - val_accuracy: 0.8922\n",
            "Epoch 188/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0657 - accuracy: 0.9001 - val_loss: 0.0676 - val_accuracy: 0.8922\n",
            "Epoch 189/200\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0657 - accuracy: 0.9001 - val_loss: 0.0676 - val_accuracy: 0.8922\n",
            "Epoch 190/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0656 - accuracy: 0.9001 - val_loss: 0.0676 - val_accuracy: 0.8922\n",
            "Epoch 191/200\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0656 - accuracy: 0.9001 - val_loss: 0.0676 - val_accuracy: 0.8922\n",
            "Epoch 192/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0656 - accuracy: 0.9001 - val_loss: 0.0676 - val_accuracy: 0.8922\n",
            "Epoch 193/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0656 - accuracy: 0.9001 - val_loss: 0.0676 - val_accuracy: 0.8922\n",
            "Epoch 194/200\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0656 - accuracy: 0.9001 - val_loss: 0.0675 - val_accuracy: 0.8922\n",
            "Epoch 195/200\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0655 - accuracy: 0.9001 - val_loss: 0.0675 - val_accuracy: 0.8922\n",
            "Epoch 196/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9001 - val_loss: 0.0675 - val_accuracy: 0.8922\n",
            "Epoch 197/200\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0655 - accuracy: 0.9001 - val_loss: 0.0675 - val_accuracy: 0.8922\n",
            "Epoch 198/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0655 - accuracy: 0.9001 - val_loss: 0.0675 - val_accuracy: 0.8922\n",
            "Epoch 199/200\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0655 - accuracy: 0.9001 - val_loss: 0.0675 - val_accuracy: 0.8922\n",
            "Epoch 200/200\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0655 - accuracy: 0.9001 - val_loss: 0.0675 - val_accuracy: 0.8922\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = ae_classifier.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "id": "jHuThnD_b3dN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7da2ec34-e926-4cdc-af19-263a5d11883e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 1ms/step - loss: 0.1178 - accuracy: 0.8413\n",
            "Test results - Loss: 0.11775433272123337 - Accuracy: 84.13451910018921%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy4_1 = test_results[1]\n",
        "y_pred4_1 = np.where(ae_classifier.predict(X_test).ravel()>=0.5,1,0)\n",
        "y_test4 = y_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KR2KDhebb3dN",
        "outputId": "0f0a7bfa-0e28-413a-c6c3-0102d8254087"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "ts1FK_OE3BAi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "y_test = [*y_test1,*y_test2,*y_test3,*y_test4]\n",
        "y_pred1 = [*y_pred1_1,*y_pred2_1,*y_pred3_1,*y_pred4_1]\n",
        "accuracy = (test_count1*accuracy1_1 + test_count2*accuracy2_1 + test_count3*accuracy3_1 + test_count4*accuracy4_1)/(test_count1 + test_count2 + test_count3 + test_count4)\n",
        "presion = precision_score(y_test,y_pred1)\n",
        "recall = recall_score(y_test,y_pred1)"
      ],
      "metadata": {
        "id": "wpLuu5Yx3BAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {}\\t Precision:{}\\t Recall: {}\".format(accuracy,presion,recall))"
      ],
      "metadata": {
        "id": "29aNf6DZ3BAj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fdebefc-df47-43fd-e2db-47961b28096d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.893153000040837\t Precision:0.860252202452928\t Recall: 0.8767605633802817\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LSTM"
      ],
      "metadata": {
        "id": "pV9EjBasb3dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 1"
      ],
      "metadata": {
        "id": "Pul729BBb3dO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train1.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test1.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count1 = len(test.index)"
      ],
      "metadata": {
        "id": "t9O_NzMlb3dO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "Y_train = train[['intrusion']]\n",
        "X_test = test.iloc[:,0:89]\n",
        "Y_test = test[['intrusion']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "Y_test = Y_test.values\n",
        "Y_train = Y_train.values\n",
        "\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "lst = Sequential()\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "# summary of model layers\n",
        "lst.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqAZqJyxzOm_",
        "outputId": "f27068c3-4158-443b-bbde-dff3119115e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_18 (LSTM)              (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_116 (Dense)           (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,051\n",
            "Trainable params: 28,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "history = lst.fit(X_train, Y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BpVRXse10qMZ",
        "outputId": "bf54c7fa-a3e2-4c8c-daa0-974887de24ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 [==============================] - 4s 389ms/step - loss: 0.6656 - accuracy: 0.8635 - precision: 0.0174 - recall: 0.6429 - val_loss: 0.6052 - val_accuracy: 0.9952 - val_precision: 0.4500 - val_recall: 0.5625\n",
            "Epoch 2/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.5867 - accuracy: 0.9957 - precision: 0.4328 - recall: 0.5179 - val_loss: 0.5318 - val_accuracy: 0.9976 - val_precision: 1.0000 - val_recall: 0.4375\n",
            "Epoch 3/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.5148 - accuracy: 0.9973 - precision: 0.9000 - recall: 0.3214 - val_loss: 0.4646 - val_accuracy: 0.9960 - val_precision: 1.0000 - val_recall: 0.0625\n",
            "Epoch 4/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.4489 - accuracy: 0.9967 - precision: 1.0000 - recall: 0.1250 - val_loss: 0.4029 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 5/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.3883 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.3465 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 6/100\n",
            "4/4 [==============================] - 0s 69ms/step - loss: 0.3331 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2955 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 7/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.2834 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2500 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 8/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.2393 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.2104 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 9/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.2010 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1764 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 10/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.1684 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1480 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 11/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.1411 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1245 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 12/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.1187 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.1053 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 13/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.1004 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0897 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 14/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0856 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0772 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 15/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0737 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0672 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 16/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0643 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0593 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 17/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0567 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0528 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 18/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0505 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0475 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 19/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0454 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0431 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 20/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0412 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0395 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 21/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0377 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0364 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 22/100\n",
            "4/4 [==============================] - 0s 47ms/step - loss: 0.0348 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0339 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 23/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0323 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0317 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 24/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0302 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0299 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 25/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0284 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0283 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 26/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0269 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0269 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 27/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0255 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0257 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 28/100\n",
            "4/4 [==============================] - 0s 53ms/step - loss: 0.0243 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0247 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 29/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0233 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0237 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 30/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0224 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0229 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 31/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0215 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0222 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 32/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0208 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0215 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 33/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0201 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0209 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 34/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0195 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0204 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 35/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0190 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0199 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 36/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0185 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0194 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 37/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0180 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0190 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 38/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0176 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0186 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 39/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0172 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0183 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 40/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0169 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0180 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 41/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0166 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0177 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 42/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0163 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0174 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 43/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0160 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0171 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 44/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0157 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0169 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 45/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0155 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0167 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 46/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0152 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0164 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 47/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0150 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0162 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 48/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0148 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0160 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 49/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0146 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0159 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 50/100\n",
            "4/4 [==============================] - 0s 45ms/step - loss: 0.0144 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0157 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 51/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0142 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0155 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 52/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0141 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0154 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 53/100\n",
            "4/4 [==============================] - 0s 48ms/step - loss: 0.0139 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0153 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 54/100\n",
            "4/4 [==============================] - 0s 46ms/step - loss: 0.0138 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0151 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 55/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0136 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0150 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 56/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0135 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0149 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 57/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0134 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0147 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 58/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0132 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0146 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 59/100\n",
            "4/4 [==============================] - 0s 44ms/step - loss: 0.0131 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0145 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 60/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0130 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0144 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 61/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0129 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0143 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 62/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0128 - accuracy: 0.9963 - precision: 0.0000e+00 - recall: 0.0000e+00 - val_loss: 0.0142 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 63/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0127 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0141 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 64/100\n",
            "4/4 [==============================] - 0s 42ms/step - loss: 0.0126 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0140 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 65/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0125 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 66/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0124 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0139 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 67/100\n",
            "4/4 [==============================] - 0s 74ms/step - loss: 0.0123 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0138 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 68/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.0122 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0137 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 69/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.0121 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0136 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 70/100\n",
            "4/4 [==============================] - 0s 64ms/step - loss: 0.0120 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0135 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 71/100\n",
            "4/4 [==============================] - 0s 59ms/step - loss: 0.0120 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0134 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 72/100\n",
            "4/4 [==============================] - 0s 78ms/step - loss: 0.0119 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0134 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 73/100\n",
            "4/4 [==============================] - 0s 60ms/step - loss: 0.0118 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0133 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 74/100\n",
            "4/4 [==============================] - 0s 61ms/step - loss: 0.0117 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0132 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 75/100\n",
            "4/4 [==============================] - 0s 57ms/step - loss: 0.0116 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0131 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 76/100\n",
            "4/4 [==============================] - 0s 75ms/step - loss: 0.0116 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0131 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 77/100\n",
            "4/4 [==============================] - 0s 62ms/step - loss: 0.0115 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0130 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 78/100\n",
            "4/4 [==============================] - 0s 49ms/step - loss: 0.0114 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0129 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 79/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0113 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0128 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 80/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0113 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0128 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 81/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0112 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0127 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 82/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0111 - accuracy: 0.9963 - precision: 1.0000 - recall: 0.0179 - val_loss: 0.0126 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 83/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0111 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0126 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 84/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0110 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0125 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 85/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0109 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0124 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 86/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0108 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0123 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 87/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0108 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0123 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 88/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0107 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0122 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 89/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0106 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0121 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 90/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0106 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0121 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 91/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0105 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0120 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 92/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0104 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0119 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 93/100\n",
            "4/4 [==============================] - 0s 38ms/step - loss: 0.0104 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0118 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 94/100\n",
            "4/4 [==============================] - 0s 39ms/step - loss: 0.0103 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0118 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 95/100\n",
            "4/4 [==============================] - 0s 37ms/step - loss: 0.0102 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0117 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 96/100\n",
            "4/4 [==============================] - 0s 40ms/step - loss: 0.0102 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0116 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 97/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0100 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0113 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 98/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0099 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0111 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 99/100\n",
            "4/4 [==============================] - 0s 43ms/step - loss: 0.0097 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0110 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n",
            "Epoch 100/100\n",
            "4/4 [==============================] - 0s 41ms/step - loss: 0.0096 - accuracy: 0.9964 - precision: 1.0000 - recall: 0.0357 - val_loss: 0.0109 - val_accuracy: 0.9957 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = lst.evaluate(X_test, Y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "id": "3qnT7ura0v6H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f16f154-bbaa-412e-ef49-b7b8d4dc0825"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 0s 2ms/step - loss: 0.0055 - accuracy: 0.9994 - precision: 0.0000e+00 - recall: 0.0000e+00\n",
            "Test results - Loss: 0.0054565733298659325 - Accuracy: 99.93975758552551%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy1_2 = test_results[1]\n",
        "y_pred1_2 = np.where(lst.predict(X_test)>=0.5,1,0)"
      ],
      "metadata": {
        "id": "vYyFIcv91crt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4f8c3c3-2083-4646-e1fb-6b7a0cf3107a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "52/52 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 2"
      ],
      "metadata": {
        "id": "9jZ0XWRu1qqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train2.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test2.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count2 = len(test.index)"
      ],
      "metadata": {
        "id": "opJRQti91qqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "Y_train = train[['intrusion']]\n",
        "X_test = test.iloc[:,0:89]\n",
        "Y_test = test[['intrusion']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "Y_test = Y_test.values\n",
        "Y_train = Y_train.values\n",
        "\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "lst = Sequential()\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "# summary of model layers\n",
        "lst.summary()"
      ],
      "metadata": {
        "id": "cDWAXJ-D1qqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6925e262-9bc1-4cb7-825b-3539ccf467b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_19 (LSTM)              (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_117 (Dense)           (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,051\n",
            "Trainable params: 28,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "history = lst.fit(X_train, Y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "id": "3rgp88Y-1qqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "258d031a-5e89-4015-ebe9-c352d3250505"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 3s 167ms/step - loss: 0.6922 - accuracy: 0.4967 - precision: 0.9821 - recall: 0.4990 - val_loss: 0.6527 - val_accuracy: 0.9866 - val_precision: 0.9882 - val_recall: 0.9984\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.6259 - accuracy: 0.9857 - precision: 0.9865 - recall: 0.9992 - val_loss: 0.5879 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.5619 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9998 - val_loss: 0.5247 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9999\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.4994 - accuracy: 0.9864 - precision: 0.9865 - recall: 0.9999 - val_loss: 0.4627 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 48ms/step - loss: 0.4382 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.3792 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 77ms/step - loss: 0.3237 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.2919 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.2734 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.2449 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.2295 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.2048 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.1925 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.1717 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.1625 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.1451 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.1386 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.1243 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.1200 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.1082 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.1057 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0957 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0946 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0860 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0860 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0785 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0793 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0726 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0740 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0678 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0697 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0640 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0662 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0608 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0633 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0582 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0609 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0560 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0588 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0541 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 41ms/step - loss: 0.0570 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0524 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0555 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0510 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0541 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0497 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0528 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0485 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0517 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0474 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0507 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0465 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0497 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0456 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0488 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0448 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0480 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0440 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0472 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0433 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0465 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0426 - val_accuracy: 0.9882 - val_precision: 0.9882 - val_recall: 1.0000\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0458 - accuracy: 0.9865 - precision: 0.9865 - recall: 1.0000 - val_loss: 0.0420 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9999\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0451 - accuracy: 0.9865 - precision: 0.9865 - recall: 0.9999 - val_loss: 0.0414 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9999\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0444 - accuracy: 0.9864 - precision: 0.9865 - recall: 0.9998 - val_loss: 0.0408 - val_accuracy: 0.9881 - val_precision: 0.9882 - val_recall: 0.9999\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0438 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9998 - val_loss: 0.0403 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0432 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9998 - val_loss: 0.0397 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0427 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9997 - val_loss: 0.0392 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0421 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9997 - val_loss: 0.0388 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0416 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9997 - val_loss: 0.0383 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0411 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9997 - val_loss: 0.0378 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0406 - accuracy: 0.9863 - precision: 0.9865 - recall: 0.9997 - val_loss: 0.0374 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0401 - accuracy: 0.9862 - precision: 0.9865 - recall: 0.9997 - val_loss: 0.0370 - val_accuracy: 0.9878 - val_precision: 0.9882 - val_recall: 0.9996\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0396 - accuracy: 0.9861 - precision: 0.9865 - recall: 0.9996 - val_loss: 0.0366 - val_accuracy: 0.9878 - val_precision: 0.9882 - val_recall: 0.9996\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0392 - accuracy: 0.9861 - precision: 0.9865 - recall: 0.9995 - val_loss: 0.0362 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0388 - accuracy: 0.9860 - precision: 0.9865 - recall: 0.9995 - val_loss: 0.0358 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0383 - accuracy: 0.9860 - precision: 0.9865 - recall: 0.9995 - val_loss: 0.0355 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 59ms/step - loss: 0.0379 - accuracy: 0.9860 - precision: 0.9865 - recall: 0.9995 - val_loss: 0.0351 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 67ms/step - loss: 0.0375 - accuracy: 0.9860 - precision: 0.9865 - recall: 0.9994 - val_loss: 0.0348 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 72ms/step - loss: 0.0371 - accuracy: 0.9859 - precision: 0.9865 - recall: 0.9993 - val_loss: 0.0345 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0367 - accuracy: 0.9859 - precision: 0.9865 - recall: 0.9993 - val_loss: 0.0342 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 63ms/step - loss: 0.0364 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9993 - val_loss: 0.0339 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 70ms/step - loss: 0.0360 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9993 - val_loss: 0.0336 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0357 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9993 - val_loss: 0.0333 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 57ms/step - loss: 0.0353 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9993 - val_loss: 0.0330 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 45ms/step - loss: 0.0350 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9993 - val_loss: 0.0327 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0347 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9992 - val_loss: 0.0324 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0344 - accuracy: 0.9858 - precision: 0.9865 - recall: 0.9992 - val_loss: 0.0322 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0341 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0319 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0338 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0316 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0335 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0314 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0332 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0311 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0329 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0309 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0326 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0306 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0324 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0304 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0321 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0301 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 54ms/step - loss: 0.0318 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0299 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0315 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0297 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0313 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0294 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0310 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0292 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0307 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0289 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0305 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0287 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 42ms/step - loss: 0.0302 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0284 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0299 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0282 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 49ms/step - loss: 0.0297 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0280 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0294 - accuracy: 0.9857 - precision: 0.9866 - recall: 0.9991 - val_loss: 0.0277 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0292 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0275 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0289 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0273 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 53ms/step - loss: 0.0287 - accuracy: 0.9858 - precision: 0.9866 - recall: 0.9992 - val_loss: 0.0270 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0284 - accuracy: 0.9859 - precision: 0.9866 - recall: 0.9993 - val_loss: 0.0268 - val_accuracy: 0.9875 - val_precision: 0.9882 - val_recall: 0.9993\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0281 - accuracy: 0.9859 - precision: 0.9866 - recall: 0.9993 - val_loss: 0.0266 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 55ms/step - loss: 0.0279 - accuracy: 0.9860 - precision: 0.9866 - recall: 0.9994 - val_loss: 0.0263 - val_accuracy: 0.9877 - val_precision: 0.9882 - val_recall: 0.9995\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0276 - accuracy: 0.9860 - precision: 0.9866 - recall: 0.9994 - val_loss: 0.0261 - val_accuracy: 0.9878 - val_precision: 0.9882 - val_recall: 0.9996\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 47ms/step - loss: 0.0274 - accuracy: 0.9860 - precision: 0.9866 - recall: 0.9994 - val_loss: 0.0259 - val_accuracy: 0.9878 - val_precision: 0.9882 - val_recall: 0.9996\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 46ms/step - loss: 0.0271 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9995 - val_loss: 0.0257 - val_accuracy: 0.9878 - val_precision: 0.9882 - val_recall: 0.9996\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 51ms/step - loss: 0.0269 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9995 - val_loss: 0.0254 - val_accuracy: 0.9878 - val_precision: 0.9882 - val_recall: 0.9996\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 52ms/step - loss: 0.0267 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9995 - val_loss: 0.0252 - val_accuracy: 0.9878 - val_precision: 0.9882 - val_recall: 0.9996\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 44ms/step - loss: 0.0264 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9995 - val_loss: 0.0250 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 50ms/step - loss: 0.0262 - accuracy: 0.9861 - precision: 0.9866 - recall: 0.9995 - val_loss: 0.0248 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 56ms/step - loss: 0.0260 - accuracy: 0.9863 - precision: 0.9866 - recall: 0.9997 - val_loss: 0.0246 - val_accuracy: 0.9879 - val_precision: 0.9882 - val_recall: 0.9997\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 84ms/step - loss: 0.0257 - accuracy: 0.9862 - precision: 0.9866 - recall: 0.9996 - val_loss: 0.0244 - val_accuracy: 0.9881 - val_precision: 0.9883 - val_recall: 0.9997\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 78ms/step - loss: 0.0255 - accuracy: 0.9863 - precision: 0.9868 - recall: 0.9995 - val_loss: 0.0242 - val_accuracy: 0.9886 - val_precision: 0.9890 - val_recall: 0.9996\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 71ms/step - loss: 0.0253 - accuracy: 0.9866 - precision: 0.9872 - recall: 0.9994 - val_loss: 0.0240 - val_accuracy: 0.9889 - val_precision: 0.9894 - val_recall: 0.9995\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 74ms/step - loss: 0.0250 - accuracy: 0.9870 - precision: 0.9876 - recall: 0.9993 - val_loss: 0.0238 - val_accuracy: 0.9895 - val_precision: 0.9901 - val_recall: 0.9995\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 69ms/step - loss: 0.0248 - accuracy: 0.9874 - precision: 0.9880 - recall: 0.9993 - val_loss: 0.0236 - val_accuracy: 0.9897 - val_precision: 0.9902 - val_recall: 0.9995\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0246 - accuracy: 0.9879 - precision: 0.9886 - recall: 0.9993 - val_loss: 0.0234 - val_accuracy: 0.9902 - val_precision: 0.9909 - val_recall: 0.9993\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 75ms/step - loss: 0.0244 - accuracy: 0.9883 - precision: 0.9890 - recall: 0.9992 - val_loss: 0.0232 - val_accuracy: 0.9906 - val_precision: 0.9914 - val_recall: 0.9992\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 43ms/step - loss: 0.0242 - accuracy: 0.9887 - precision: 0.9896 - recall: 0.9991 - val_loss: 0.0230 - val_accuracy: 0.9908 - val_precision: 0.9915 - val_recall: 0.9992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = lst.evaluate(X_test, Y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "id": "Mf6ketQW1qqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b51374f4-08e9-45dd-c20f-c5d7488ef7a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 0s 2ms/step - loss: 1.2752 - accuracy: 0.7744 - precision: 0.7743 - recall: 1.0000\n",
            "Test results - Loss: 1.2751686573028564 - Accuracy: 77.43613123893738%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy2_2 = test_results[1]\n",
        "y_pred2_2 = np.where(lst.predict(X_test)>=0.5,1,0)"
      ],
      "metadata": {
        "id": "-nYxNM3h1qqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04639eb-1b45-46f0-b5b0-6ec8b279d658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "139/139 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 3"
      ],
      "metadata": {
        "id": "0bvfGtt_11RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train3.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test3.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count3 = len(test.index)"
      ],
      "metadata": {
        "id": "J9NZ6QZk11RN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "Y_train = train[['intrusion']]\n",
        "X_test = test.iloc[:,0:89]\n",
        "Y_test = test[['intrusion']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "Y_test = Y_test.values\n",
        "Y_train = Y_train.values\n",
        "\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "lst = Sequential()\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "# summary of model layers\n",
        "lst.summary()"
      ],
      "metadata": {
        "id": "IT4vRTVp11RN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e9465a2-7d11-4f72-8db3-dba0fb7ef481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_20 (LSTM)              (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_118 (Dense)           (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,051\n",
            "Trainable params: 28,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "history = lst.fit(X_train, Y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "id": "d1zs0VA111RN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d10f460-0e30-45ab-9ed3-84aadff1e6f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 3s 401ms/step - loss: 0.7052 - accuracy: 0.3690 - precision: 0.5574 - recall: 0.4893 - val_loss: 0.6924 - val_accuracy: 0.6791 - val_precision: 0.6864 - val_recall: 0.9844\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6860 - accuracy: 0.6973 - precision: 0.7006 - recall: 0.9932 - val_loss: 0.6746 - val_accuracy: 0.6875 - val_precision: 0.6890 - val_recall: 0.9965\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.6678 - accuracy: 0.7005 - precision: 0.7015 - recall: 0.9977 - val_loss: 0.6576 - val_accuracy: 0.6890 - val_precision: 0.6895 - val_recall: 0.9987\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6506 - accuracy: 0.7011 - precision: 0.7017 - recall: 0.9986 - val_loss: 0.6416 - val_accuracy: 0.6890 - val_precision: 0.6895 - val_recall: 0.9987\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6340 - accuracy: 0.7014 - precision: 0.7018 - recall: 0.9989 - val_loss: 0.6264 - val_accuracy: 0.6896 - val_precision: 0.6897 - val_recall: 0.9996\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.6184 - accuracy: 0.7018 - precision: 0.7019 - recall: 0.9996 - val_loss: 0.6118 - val_accuracy: 0.6896 - val_precision: 0.6897 - val_recall: 0.9996\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.6034 - accuracy: 0.7018 - precision: 0.7019 - recall: 0.9997 - val_loss: 0.5978 - val_accuracy: 0.6896 - val_precision: 0.6897 - val_recall: 0.9996\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5891 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5844 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.5754 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5715 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5621 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5591 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.5493 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5470 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.5370 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5352 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5250 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5236 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.5132 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.5015 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4899 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.4782 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.4665 - accuracy: 0.7020 - precision: 0.7019 - recall: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.6899 - val_precision: 0.6898 - val_recall: 1.0000\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.4546 - accuracy: 0.7021 - precision: 0.7020 - recall: 0.9999 - val_loss: 0.4531 - val_accuracy: 0.6901 - val_precision: 0.6900 - val_recall: 1.0000\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.4425 - accuracy: 0.7025 - precision: 0.7023 - recall: 0.9999 - val_loss: 0.4407 - val_accuracy: 0.6928 - val_precision: 0.6919 - val_recall: 0.9996\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.4302 - accuracy: 0.7175 - precision: 0.7136 - recall: 0.9978 - val_loss: 0.4281 - val_accuracy: 0.7537 - val_precision: 0.7374 - val_recall: 0.9983\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4179 - accuracy: 0.7651 - precision: 0.7506 - recall: 0.9962 - val_loss: 0.4154 - val_accuracy: 0.8143 - val_precision: 0.7890 - val_recall: 0.9974\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.4054 - accuracy: 0.8200 - precision: 0.7991 - recall: 0.9932 - val_loss: 0.4026 - val_accuracy: 0.8567 - val_precision: 0.8322 - val_recall: 0.9922\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.3929 - accuracy: 0.8565 - precision: 0.8377 - recall: 0.9866 - val_loss: 0.3897 - val_accuracy: 0.8785 - val_precision: 0.8606 - val_recall: 0.9831\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.3804 - accuracy: 0.8800 - precision: 0.8666 - recall: 0.9798 - val_loss: 0.3770 - val_accuracy: 0.8919 - val_precision: 0.8778 - val_recall: 0.9797\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.3680 - accuracy: 0.8960 - precision: 0.8863 - recall: 0.9772 - val_loss: 0.3643 - val_accuracy: 0.9021 - val_precision: 0.8920 - val_recall: 0.9762\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 93ms/step - loss: 0.3557 - accuracy: 0.9045 - precision: 0.8997 - recall: 0.9723 - val_loss: 0.3519 - val_accuracy: 0.9084 - val_precision: 0.9020 - val_recall: 0.9727\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.3437 - accuracy: 0.9101 - precision: 0.9096 - recall: 0.9681 - val_loss: 0.3397 - val_accuracy: 0.9119 - val_precision: 0.9104 - val_recall: 0.9675\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 100ms/step - loss: 0.3320 - accuracy: 0.9201 - precision: 0.9246 - recall: 0.9648 - val_loss: 0.3278 - val_accuracy: 0.9221 - val_precision: 0.9239 - val_recall: 0.9667\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 90ms/step - loss: 0.3205 - accuracy: 0.9247 - precision: 0.9306 - recall: 0.9646 - val_loss: 0.3163 - val_accuracy: 0.9227 - val_precision: 0.9250 - val_recall: 0.9662\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.3094 - accuracy: 0.9251 - precision: 0.9314 - recall: 0.9644 - val_loss: 0.3053 - val_accuracy: 0.9236 - val_precision: 0.9265 - val_recall: 0.9658\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.2987 - accuracy: 0.9241 - precision: 0.9317 - recall: 0.9623 - val_loss: 0.2946 - val_accuracy: 0.9221 - val_precision: 0.9278 - val_recall: 0.9619\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 0.2885 - accuracy: 0.9211 - precision: 0.9325 - recall: 0.9568 - val_loss: 0.2845 - val_accuracy: 0.9200 - val_precision: 0.9279 - val_recall: 0.9584\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.2788 - accuracy: 0.9204 - precision: 0.9337 - recall: 0.9543 - val_loss: 0.2749 - val_accuracy: 0.9206 - val_precision: 0.9298 - val_recall: 0.9571\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 0.2696 - accuracy: 0.9202 - precision: 0.9350 - recall: 0.9526 - val_loss: 0.2659 - val_accuracy: 0.9215 - val_precision: 0.9324 - val_recall: 0.9554\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 99ms/step - loss: 0.2609 - accuracy: 0.9202 - precision: 0.9356 - recall: 0.9518 - val_loss: 0.2574 - val_accuracy: 0.9212 - val_precision: 0.9327 - val_recall: 0.9545\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 101ms/step - loss: 0.2528 - accuracy: 0.9205 - precision: 0.9363 - recall: 0.9515 - val_loss: 0.2494 - val_accuracy: 0.9218 - val_precision: 0.9335 - val_recall: 0.9545\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.2452 - accuracy: 0.9209 - precision: 0.9370 - recall: 0.9512 - val_loss: 0.2420 - val_accuracy: 0.9209 - val_precision: 0.9334 - val_recall: 0.9532\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.2381 - accuracy: 0.9213 - precision: 0.9380 - recall: 0.9506 - val_loss: 0.2351 - val_accuracy: 0.9206 - val_precision: 0.9334 - val_recall: 0.9528\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.2316 - accuracy: 0.9219 - precision: 0.9390 - recall: 0.9504 - val_loss: 0.2287 - val_accuracy: 0.9206 - val_precision: 0.9338 - val_recall: 0.9524\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.2255 - accuracy: 0.9224 - precision: 0.9399 - recall: 0.9502 - val_loss: 0.2228 - val_accuracy: 0.9206 - val_precision: 0.9338 - val_recall: 0.9524\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.2198 - accuracy: 0.9229 - precision: 0.9410 - recall: 0.9497 - val_loss: 0.2173 - val_accuracy: 0.9206 - val_precision: 0.9338 - val_recall: 0.9524\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.2146 - accuracy: 0.9235 - precision: 0.9421 - recall: 0.9494 - val_loss: 0.2122 - val_accuracy: 0.9215 - val_precision: 0.9350 - val_recall: 0.9524\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.2097 - accuracy: 0.9239 - precision: 0.9427 - recall: 0.9492 - val_loss: 0.2075 - val_accuracy: 0.9212 - val_precision: 0.9353 - val_recall: 0.9515\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.2053 - accuracy: 0.9242 - precision: 0.9433 - recall: 0.9489 - val_loss: 0.2032 - val_accuracy: 0.9218 - val_precision: 0.9365 - val_recall: 0.9511\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.2012 - accuracy: 0.9243 - precision: 0.9438 - recall: 0.9486 - val_loss: 0.1992 - val_accuracy: 0.9221 - val_precision: 0.9369 - val_recall: 0.9511\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1974 - accuracy: 0.9248 - precision: 0.9448 - recall: 0.9483 - val_loss: 0.1954 - val_accuracy: 0.9230 - val_precision: 0.9381 - val_recall: 0.9511\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1938 - accuracy: 0.9251 - precision: 0.9453 - recall: 0.9482 - val_loss: 0.1919 - val_accuracy: 0.9239 - val_precision: 0.9393 - val_recall: 0.9511\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 57ms/step - loss: 0.1905 - accuracy: 0.9256 - precision: 0.9462 - recall: 0.9479 - val_loss: 0.1886 - val_accuracy: 0.9242 - val_precision: 0.9397 - val_recall: 0.9511\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1874 - accuracy: 0.9258 - precision: 0.9466 - recall: 0.9478 - val_loss: 0.1856 - val_accuracy: 0.9245 - val_precision: 0.9401 - val_recall: 0.9511\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1844 - accuracy: 0.9268 - precision: 0.9479 - recall: 0.9478 - val_loss: 0.1827 - val_accuracy: 0.9248 - val_precision: 0.9405 - val_recall: 0.9511\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1817 - accuracy: 0.9272 - precision: 0.9485 - recall: 0.9478 - val_loss: 0.1800 - val_accuracy: 0.9251 - val_precision: 0.9413 - val_recall: 0.9506\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1791 - accuracy: 0.9277 - precision: 0.9493 - recall: 0.9476 - val_loss: 0.1774 - val_accuracy: 0.9257 - val_precision: 0.9421 - val_recall: 0.9506\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1767 - accuracy: 0.9280 - precision: 0.9499 - recall: 0.9473 - val_loss: 0.1750 - val_accuracy: 0.9263 - val_precision: 0.9433 - val_recall: 0.9502\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1744 - accuracy: 0.9284 - precision: 0.9508 - recall: 0.9470 - val_loss: 0.1728 - val_accuracy: 0.9269 - val_precision: 0.9441 - val_recall: 0.9502\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1722 - accuracy: 0.9287 - precision: 0.9512 - recall: 0.9470 - val_loss: 0.1706 - val_accuracy: 0.9272 - val_precision: 0.9445 - val_recall: 0.9502\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1701 - accuracy: 0.9293 - precision: 0.9521 - recall: 0.9469 - val_loss: 0.1685 - val_accuracy: 0.9287 - val_precision: 0.9465 - val_recall: 0.9502\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1681 - accuracy: 0.9306 - precision: 0.9539 - recall: 0.9468 - val_loss: 0.1665 - val_accuracy: 0.9301 - val_precision: 0.9486 - val_recall: 0.9502\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1662 - accuracy: 0.9327 - precision: 0.9568 - recall: 0.9468 - val_loss: 0.1646 - val_accuracy: 0.9319 - val_precision: 0.9510 - val_recall: 0.9502\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.1644 - accuracy: 0.9345 - precision: 0.9595 - recall: 0.9467 - val_loss: 0.1628 - val_accuracy: 0.9343 - val_precision: 0.9543 - val_recall: 0.9502\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1627 - accuracy: 0.9363 - precision: 0.9620 - recall: 0.9467 - val_loss: 0.1610 - val_accuracy: 0.9364 - val_precision: 0.9573 - val_recall: 0.9502\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1610 - accuracy: 0.9382 - precision: 0.9646 - recall: 0.9467 - val_loss: 0.1593 - val_accuracy: 0.9379 - val_precision: 0.9594 - val_recall: 0.9502\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1594 - accuracy: 0.9399 - precision: 0.9670 - recall: 0.9467 - val_loss: 0.1577 - val_accuracy: 0.9394 - val_precision: 0.9611 - val_recall: 0.9506\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.1578 - accuracy: 0.9405 - precision: 0.9678 - recall: 0.9467 - val_loss: 0.1561 - val_accuracy: 0.9403 - val_precision: 0.9623 - val_recall: 0.9506\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1563 - accuracy: 0.9407 - precision: 0.9682 - recall: 0.9466 - val_loss: 0.1546 - val_accuracy: 0.9406 - val_precision: 0.9627 - val_recall: 0.9506\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1549 - accuracy: 0.9410 - precision: 0.9685 - recall: 0.9466 - val_loss: 0.1532 - val_accuracy: 0.9406 - val_precision: 0.9627 - val_recall: 0.9506\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.1535 - accuracy: 0.9411 - precision: 0.9688 - recall: 0.9466 - val_loss: 0.1518 - val_accuracy: 0.9406 - val_precision: 0.9627 - val_recall: 0.9506\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1521 - accuracy: 0.9411 - precision: 0.9687 - recall: 0.9467 - val_loss: 0.1505 - val_accuracy: 0.9409 - val_precision: 0.9632 - val_recall: 0.9506\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1508 - accuracy: 0.9411 - precision: 0.9686 - recall: 0.9468 - val_loss: 0.1492 - val_accuracy: 0.9412 - val_precision: 0.9636 - val_recall: 0.9506\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1495 - accuracy: 0.9415 - precision: 0.9688 - recall: 0.9471 - val_loss: 0.1479 - val_accuracy: 0.9409 - val_precision: 0.9632 - val_recall: 0.9506\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1483 - accuracy: 0.9416 - precision: 0.9689 - recall: 0.9472 - val_loss: 0.1467 - val_accuracy: 0.9412 - val_precision: 0.9632 - val_recall: 0.9511\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1471 - accuracy: 0.9420 - precision: 0.9690 - recall: 0.9477 - val_loss: 0.1455 - val_accuracy: 0.9412 - val_precision: 0.9636 - val_recall: 0.9506\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1459 - accuracy: 0.9422 - precision: 0.9691 - recall: 0.9478 - val_loss: 0.1444 - val_accuracy: 0.9412 - val_precision: 0.9636 - val_recall: 0.9506\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1448 - accuracy: 0.9424 - precision: 0.9694 - recall: 0.9478 - val_loss: 0.1432 - val_accuracy: 0.9412 - val_precision: 0.9636 - val_recall: 0.9506\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1437 - accuracy: 0.9426 - precision: 0.9697 - recall: 0.9478 - val_loss: 0.1421 - val_accuracy: 0.9412 - val_precision: 0.9636 - val_recall: 0.9506\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1426 - accuracy: 0.9427 - precision: 0.9698 - recall: 0.9478 - val_loss: 0.1411 - val_accuracy: 0.9415 - val_precision: 0.9640 - val_recall: 0.9506\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1416 - accuracy: 0.9429 - precision: 0.9702 - recall: 0.9478 - val_loss: 0.1401 - val_accuracy: 0.9418 - val_precision: 0.9644 - val_recall: 0.9506\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1406 - accuracy: 0.9433 - precision: 0.9707 - recall: 0.9478 - val_loss: 0.1391 - val_accuracy: 0.9427 - val_precision: 0.9657 - val_recall: 0.9506\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1396 - accuracy: 0.9432 - precision: 0.9706 - recall: 0.9478 - val_loss: 0.1382 - val_accuracy: 0.9433 - val_precision: 0.9665 - val_recall: 0.9506\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1387 - accuracy: 0.9444 - precision: 0.9721 - recall: 0.9480 - val_loss: 0.1373 - val_accuracy: 0.9436 - val_precision: 0.9670 - val_recall: 0.9506\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1377 - accuracy: 0.9463 - precision: 0.9748 - recall: 0.9480 - val_loss: 0.1364 - val_accuracy: 0.9478 - val_precision: 0.9730 - val_recall: 0.9506\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1369 - accuracy: 0.9479 - precision: 0.9771 - recall: 0.9480 - val_loss: 0.1355 - val_accuracy: 0.9496 - val_precision: 0.9751 - val_recall: 0.9511\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1360 - accuracy: 0.9487 - precision: 0.9781 - recall: 0.9482 - val_loss: 0.1347 - val_accuracy: 0.9507 - val_precision: 0.9765 - val_recall: 0.9515\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1351 - accuracy: 0.9491 - precision: 0.9783 - recall: 0.9485 - val_loss: 0.1338 - val_accuracy: 0.9513 - val_precision: 0.9769 - val_recall: 0.9519\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1343 - accuracy: 0.9494 - precision: 0.9782 - recall: 0.9490 - val_loss: 0.1331 - val_accuracy: 0.9513 - val_precision: 0.9769 - val_recall: 0.9519\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1335 - accuracy: 0.9495 - precision: 0.9781 - recall: 0.9494 - val_loss: 0.1323 - val_accuracy: 0.9513 - val_precision: 0.9765 - val_recall: 0.9524\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1327 - accuracy: 0.9497 - precision: 0.9781 - recall: 0.9496 - val_loss: 0.1315 - val_accuracy: 0.9522 - val_precision: 0.9778 - val_recall: 0.9524\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1320 - accuracy: 0.9499 - precision: 0.9782 - recall: 0.9498 - val_loss: 0.1308 - val_accuracy: 0.9528 - val_precision: 0.9782 - val_recall: 0.9528\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1313 - accuracy: 0.9507 - precision: 0.9791 - recall: 0.9501 - val_loss: 0.1301 - val_accuracy: 0.9528 - val_precision: 0.9782 - val_recall: 0.9528\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 58ms/step - loss: 0.1305 - accuracy: 0.9513 - precision: 0.9794 - recall: 0.9505 - val_loss: 0.1295 - val_accuracy: 0.9540 - val_precision: 0.9791 - val_recall: 0.9537\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 55ms/step - loss: 0.1299 - accuracy: 0.9519 - precision: 0.9800 - recall: 0.9509 - val_loss: 0.1288 - val_accuracy: 0.9549 - val_precision: 0.9796 - val_recall: 0.9545\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1292 - accuracy: 0.9524 - precision: 0.9805 - recall: 0.9511 - val_loss: 0.1282 - val_accuracy: 0.9543 - val_precision: 0.9783 - val_recall: 0.9550\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1285 - accuracy: 0.9525 - precision: 0.9801 - recall: 0.9516 - val_loss: 0.1276 - val_accuracy: 0.9537 - val_precision: 0.9770 - val_recall: 0.9554\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1279 - accuracy: 0.9524 - precision: 0.9793 - recall: 0.9522 - val_loss: 0.1270 - val_accuracy: 0.9537 - val_precision: 0.9766 - val_recall: 0.9558\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1273 - accuracy: 0.9525 - precision: 0.9791 - recall: 0.9527 - val_loss: 0.1264 - val_accuracy: 0.9531 - val_precision: 0.9757 - val_recall: 0.9558\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1267 - accuracy: 0.9525 - precision: 0.9788 - recall: 0.9530 - val_loss: 0.1259 - val_accuracy: 0.9522 - val_precision: 0.9744 - val_recall: 0.9558\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1262 - accuracy: 0.9528 - precision: 0.9786 - recall: 0.9535 - val_loss: 0.1253 - val_accuracy: 0.9525 - val_precision: 0.9744 - val_recall: 0.9563\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1256 - accuracy: 0.9526 - precision: 0.9780 - recall: 0.9539 - val_loss: 0.1248 - val_accuracy: 0.9522 - val_precision: 0.9736 - val_recall: 0.9567\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.1250 - accuracy: 0.9533 - precision: 0.9778 - recall: 0.9551 - val_loss: 0.1243 - val_accuracy: 0.9525 - val_precision: 0.9736 - val_recall: 0.9571\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 60ms/step - loss: 0.1245 - accuracy: 0.9536 - precision: 0.9776 - recall: 0.9559 - val_loss: 0.1238 - val_accuracy: 0.9525 - val_precision: 0.9736 - val_recall: 0.9571\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = lst.evaluate(X_test, Y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "id": "jWHQjdBe11RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56aaaeae-81d5-46e6-bf26-3a09aab7936c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 0s 2ms/step - loss: 0.7212 - accuracy: 0.6757 - precision: 0.7085 - recall: 0.7136\n",
            "Test results - Loss: 0.721232533454895 - Accuracy: 67.57118701934814%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy3_2 = test_results[1]\n",
        "y_pred3_2 = np.where(lst.predict(X_test)>=0.5,1,0)"
      ],
      "metadata": {
        "id": "yw3osM3s11RO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b19cd31-71e5-4ffb-8b98-849cf573e192"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "94/94 [==============================] - 1s 3ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Cluster 4"
      ],
      "metadata": {
        "id": "Xu6odIX317UM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train = pd.read_csv('bin_clusters/train4.csv')\n",
        "train = train.drop(['Unnamed: 0'],axis=1)\n",
        "test = pd.read_csv('bin_clusters/test4.csv')\n",
        "test = test.drop(['Unnamed: 0'],axis=1)\n",
        "\n",
        "test_count4 = len(test.index)"
      ],
      "metadata": {
        "id": "Nt4whbnV17UN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train.iloc[:,0:89]\n",
        "Y_train = train[['intrusion']]\n",
        "X_test = test.iloc[:,0:89]\n",
        "Y_test = test[['intrusion']]\n",
        "\n",
        "X_train = X_train.values\n",
        "X_test = X_test.values\n",
        "Y_test = Y_test.values\n",
        "Y_train = Y_train.values\n",
        "\n",
        "\n",
        "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
        "\n",
        "lst = Sequential()\n",
        "# input layer and LSTM layer with 50 neurons\n",
        "lst.add(LSTM(50,input_dim=89))\n",
        "# outpute layer with sigmoid activation\n",
        "lst.add(Dense(1,activation='sigmoid'))\n",
        "\n",
        "# defining loss function, optimizer, metrics and then compiling model\n",
        "lst.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy','Precision','Recall'])\n",
        "\n",
        "# summary of model layers\n",
        "lst.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c176279-f974-49f4-e53d-1a0e4d5958e4",
        "id": "yTQdSm8F17UN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_21 (LSTM)              (None, 50)                28000     \n",
            "                                                                 \n",
            " dense_119 (Dense)           (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 28,051\n",
            "Trainable params: 28,051\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# training the model on training dataset\n",
        "history = lst.fit(X_train, Y_train, epochs=100, batch_size=5000,validation_split=0.2)"
      ],
      "metadata": {
        "id": "Zc50BBfO17UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8ce78f9-b533-4d4c-bcdb-daa721946668"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "3/3 [==============================] - 4s 363ms/step - loss: 0.6721 - accuracy: 0.7744 - precision: 0.6760 - recall: 0.8612 - val_loss: 0.6613 - val_accuracy: 0.7955 - val_precision: 0.8077 - val_recall: 0.6295\n",
            "Epoch 2/100\n",
            "3/3 [==============================] - 0s 61ms/step - loss: 0.6571 - accuracy: 0.8177 - precision: 0.8812 - recall: 0.6408 - val_loss: 0.6460 - val_accuracy: 0.8236 - val_precision: 0.9547 - val_recall: 0.5787\n",
            "Epoch 3/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.6425 - accuracy: 0.8237 - precision: 0.9599 - recall: 0.5938 - val_loss: 0.6311 - val_accuracy: 0.8040 - val_precision: 0.9659 - val_recall: 0.5196\n",
            "Epoch 4/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.6283 - accuracy: 0.7991 - precision: 0.9704 - recall: 0.5248 - val_loss: 0.6166 - val_accuracy: 0.7588 - val_precision: 0.9715 - val_recall: 0.3980\n",
            "Epoch 5/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.6145 - accuracy: 0.7483 - precision: 0.9706 - recall: 0.3968 - val_loss: 0.6025 - val_accuracy: 0.7359 - val_precision: 0.9736 - val_recall: 0.3372\n",
            "Epoch 6/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.6010 - accuracy: 0.7358 - precision: 0.9748 - recall: 0.3636 - val_loss: 0.5887 - val_accuracy: 0.7307 - val_precision: 0.9749 - val_recall: 0.3231\n",
            "Epoch 7/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.5878 - accuracy: 0.7189 - precision: 0.9792 - recall: 0.3196 - val_loss: 0.5751 - val_accuracy: 0.7026 - val_precision: 0.9803 - val_recall: 0.2481\n",
            "Epoch 8/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.5747 - accuracy: 0.7052 - precision: 0.9821 - recall: 0.2846 - val_loss: 0.5617 - val_accuracy: 0.7045 - val_precision: 0.9806 - val_recall: 0.2531\n",
            "Epoch 9/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.5617 - accuracy: 0.7086 - precision: 0.9826 - recall: 0.2928 - val_loss: 0.5484 - val_accuracy: 0.7173 - val_precision: 0.9801 - val_recall: 0.2864\n",
            "Epoch 10/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.5488 - accuracy: 0.7234 - precision: 0.9833 - recall: 0.3294 - val_loss: 0.5351 - val_accuracy: 0.7258 - val_precision: 0.9814 - val_recall: 0.3081\n",
            "Epoch 11/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.5358 - accuracy: 0.7304 - precision: 0.9830 - recall: 0.3470 - val_loss: 0.5218 - val_accuracy: 0.7310 - val_precision: 0.9822 - val_recall: 0.3214\n",
            "Epoch 12/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.5226 - accuracy: 0.7789 - precision: 0.9764 - recall: 0.4708 - val_loss: 0.5083 - val_accuracy: 0.8141 - val_precision: 0.9745 - val_recall: 0.5412\n",
            "Epoch 13/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.5092 - accuracy: 0.8233 - precision: 0.9733 - recall: 0.5840 - val_loss: 0.4946 - val_accuracy: 0.8527 - val_precision: 0.9711 - val_recall: 0.6445\n",
            "Epoch 14/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.4955 - accuracy: 0.8529 - precision: 0.9698 - recall: 0.6610 - val_loss: 0.4808 - val_accuracy: 0.8704 - val_precision: 0.9730 - val_recall: 0.6894\n",
            "Epoch 15/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.4817 - accuracy: 0.8743 - precision: 0.9719 - recall: 0.7134 - val_loss: 0.4668 - val_accuracy: 0.8940 - val_precision: 0.9751 - val_recall: 0.7494\n",
            "Epoch 16/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.4676 - accuracy: 0.8969 - precision: 0.9737 - recall: 0.7688 - val_loss: 0.4527 - val_accuracy: 0.9211 - val_precision: 0.9771 - val_recall: 0.8185\n",
            "Epoch 17/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.4534 - accuracy: 0.9193 - precision: 0.9733 - recall: 0.8252 - val_loss: 0.4386 - val_accuracy: 0.9395 - val_precision: 0.9757 - val_recall: 0.8676\n",
            "Epoch 18/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.4392 - accuracy: 0.9375 - precision: 0.9719 - recall: 0.8724 - val_loss: 0.4245 - val_accuracy: 0.9480 - val_precision: 0.9719 - val_recall: 0.8934\n",
            "Epoch 19/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.4249 - accuracy: 0.9532 - precision: 0.9709 - recall: 0.9130 - val_loss: 0.4104 - val_accuracy: 0.9666 - val_precision: 0.9725 - val_recall: 0.9417\n",
            "Epoch 20/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.4109 - accuracy: 0.9643 - precision: 0.9659 - recall: 0.9462 - val_loss: 0.3966 - val_accuracy: 0.9653 - val_precision: 0.9612 - val_recall: 0.9500\n",
            "Epoch 21/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.3970 - accuracy: 0.9629 - precision: 0.9553 - recall: 0.9540 - val_loss: 0.3829 - val_accuracy: 0.9601 - val_precision: 0.9397 - val_recall: 0.9600\n",
            "Epoch 22/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.3833 - accuracy: 0.9564 - precision: 0.9344 - recall: 0.9608 - val_loss: 0.3694 - val_accuracy: 0.9571 - val_precision: 0.9273 - val_recall: 0.9667\n",
            "Epoch 23/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.3698 - accuracy: 0.9507 - precision: 0.9192 - recall: 0.9642 - val_loss: 0.3562 - val_accuracy: 0.9532 - val_precision: 0.9185 - val_recall: 0.9667\n",
            "Epoch 24/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.3567 - accuracy: 0.9478 - precision: 0.9123 - recall: 0.9652 - val_loss: 0.3432 - val_accuracy: 0.9519 - val_precision: 0.9156 - val_recall: 0.9667\n",
            "Epoch 25/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.3438 - accuracy: 0.9465 - precision: 0.9094 - recall: 0.9654 - val_loss: 0.3305 - val_accuracy: 0.9519 - val_precision: 0.9150 - val_recall: 0.9675\n",
            "Epoch 26/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.3314 - accuracy: 0.9464 - precision: 0.9089 - recall: 0.9658 - val_loss: 0.3182 - val_accuracy: 0.9516 - val_precision: 0.9142 - val_recall: 0.9675\n",
            "Epoch 27/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.3192 - accuracy: 0.9471 - precision: 0.9097 - recall: 0.9668 - val_loss: 0.3063 - val_accuracy: 0.9522 - val_precision: 0.9150 - val_recall: 0.9684\n",
            "Epoch 28/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.3075 - accuracy: 0.9482 - precision: 0.9117 - recall: 0.9670 - val_loss: 0.2949 - val_accuracy: 0.9539 - val_precision: 0.9180 - val_recall: 0.9692\n",
            "Epoch 29/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.2962 - accuracy: 0.9494 - precision: 0.9138 - recall: 0.9674 - val_loss: 0.2838 - val_accuracy: 0.9555 - val_precision: 0.9209 - val_recall: 0.9700\n",
            "Epoch 30/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.2853 - accuracy: 0.9504 - precision: 0.9158 - recall: 0.9678 - val_loss: 0.2732 - val_accuracy: 0.9562 - val_precision: 0.9224 - val_recall: 0.9700\n",
            "Epoch 31/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.2748 - accuracy: 0.9517 - precision: 0.9179 - recall: 0.9686 - val_loss: 0.2630 - val_accuracy: 0.9571 - val_precision: 0.9239 - val_recall: 0.9709\n",
            "Epoch 32/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.2648 - accuracy: 0.9531 - precision: 0.9204 - recall: 0.9692 - val_loss: 0.2532 - val_accuracy: 0.9581 - val_precision: 0.9261 - val_recall: 0.9709\n",
            "Epoch 33/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.2552 - accuracy: 0.9539 - precision: 0.9218 - recall: 0.9694 - val_loss: 0.2439 - val_accuracy: 0.9584 - val_precision: 0.9269 - val_recall: 0.9709\n",
            "Epoch 34/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.2459 - accuracy: 0.9573 - precision: 0.9291 - recall: 0.9696 - val_loss: 0.2349 - val_accuracy: 0.9614 - val_precision: 0.9342 - val_recall: 0.9700\n",
            "Epoch 35/100\n",
            "3/3 [==============================] - 0s 44ms/step - loss: 0.2372 - accuracy: 0.9607 - precision: 0.9370 - recall: 0.9692 - val_loss: 0.2264 - val_accuracy: 0.9656 - val_precision: 0.9434 - val_recall: 0.9709\n",
            "Epoch 36/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.2288 - accuracy: 0.9635 - precision: 0.9437 - recall: 0.9686 - val_loss: 0.2182 - val_accuracy: 0.9670 - val_precision: 0.9472 - val_recall: 0.9700\n",
            "Epoch 37/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.2208 - accuracy: 0.9643 - precision: 0.9452 - recall: 0.9690 - val_loss: 0.2105 - val_accuracy: 0.9666 - val_precision: 0.9471 - val_recall: 0.9692\n",
            "Epoch 38/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.2133 - accuracy: 0.9645 - precision: 0.9462 - recall: 0.9682 - val_loss: 0.2032 - val_accuracy: 0.9673 - val_precision: 0.9487 - val_recall: 0.9692\n",
            "Epoch 39/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.2061 - accuracy: 0.9644 - precision: 0.9466 - recall: 0.9676 - val_loss: 0.1962 - val_accuracy: 0.9673 - val_precision: 0.9487 - val_recall: 0.9692\n",
            "Epoch 40/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.1994 - accuracy: 0.9645 - precision: 0.9466 - recall: 0.9678 - val_loss: 0.1897 - val_accuracy: 0.9679 - val_precision: 0.9487 - val_recall: 0.9709\n",
            "Epoch 41/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1929 - accuracy: 0.9649 - precision: 0.9470 - recall: 0.9684 - val_loss: 0.1835 - val_accuracy: 0.9679 - val_precision: 0.9487 - val_recall: 0.9709\n",
            "Epoch 42/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1869 - accuracy: 0.9647 - precision: 0.9464 - recall: 0.9684 - val_loss: 0.1777 - val_accuracy: 0.9673 - val_precision: 0.9472 - val_recall: 0.9709\n",
            "Epoch 43/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1812 - accuracy: 0.9645 - precision: 0.9459 - recall: 0.9686 - val_loss: 0.1722 - val_accuracy: 0.9673 - val_precision: 0.9472 - val_recall: 0.9709\n",
            "Epoch 44/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.1759 - accuracy: 0.9646 - precision: 0.9459 - recall: 0.9688 - val_loss: 0.1670 - val_accuracy: 0.9673 - val_precision: 0.9472 - val_recall: 0.9709\n",
            "Epoch 45/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1708 - accuracy: 0.9648 - precision: 0.9459 - recall: 0.9694 - val_loss: 0.1621 - val_accuracy: 0.9673 - val_precision: 0.9472 - val_recall: 0.9709\n",
            "Epoch 46/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1661 - accuracy: 0.9649 - precision: 0.9460 - recall: 0.9696 - val_loss: 0.1575 - val_accuracy: 0.9673 - val_precision: 0.9472 - val_recall: 0.9709\n",
            "Epoch 47/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.1616 - accuracy: 0.9651 - precision: 0.9460 - recall: 0.9700 - val_loss: 0.1532 - val_accuracy: 0.9673 - val_precision: 0.9472 - val_recall: 0.9709\n",
            "Epoch 48/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1575 - accuracy: 0.9651 - precision: 0.9460 - recall: 0.9702 - val_loss: 0.1492 - val_accuracy: 0.9673 - val_precision: 0.9472 - val_recall: 0.9709\n",
            "Epoch 49/100\n",
            "3/3 [==============================] - 0s 51ms/step - loss: 0.1535 - accuracy: 0.9660 - precision: 0.9461 - recall: 0.9724 - val_loss: 0.1455 - val_accuracy: 0.9676 - val_precision: 0.9472 - val_recall: 0.9717\n",
            "Epoch 50/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.1498 - accuracy: 0.9674 - precision: 0.9461 - recall: 0.9758 - val_loss: 0.1419 - val_accuracy: 0.9683 - val_precision: 0.9473 - val_recall: 0.9734\n",
            "Epoch 51/100\n",
            "3/3 [==============================] - 0s 91ms/step - loss: 0.1464 - accuracy: 0.9676 - precision: 0.9458 - recall: 0.9768 - val_loss: 0.1386 - val_accuracy: 0.9683 - val_precision: 0.9473 - val_recall: 0.9734\n",
            "Epoch 52/100\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.1431 - accuracy: 0.9677 - precision: 0.9458 - recall: 0.9770 - val_loss: 0.1354 - val_accuracy: 0.9683 - val_precision: 0.9473 - val_recall: 0.9734\n",
            "Epoch 53/100\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.1401 - accuracy: 0.9676 - precision: 0.9456 - recall: 0.9770 - val_loss: 0.1325 - val_accuracy: 0.9683 - val_precision: 0.9473 - val_recall: 0.9734\n",
            "Epoch 54/100\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.1372 - accuracy: 0.9677 - precision: 0.9456 - recall: 0.9772 - val_loss: 0.1297 - val_accuracy: 0.9686 - val_precision: 0.9474 - val_recall: 0.9742\n",
            "Epoch 55/100\n",
            "3/3 [==============================] - 0s 70ms/step - loss: 0.1345 - accuracy: 0.9677 - precision: 0.9454 - recall: 0.9774 - val_loss: 0.1271 - val_accuracy: 0.9689 - val_precision: 0.9474 - val_recall: 0.9750\n",
            "Epoch 56/100\n",
            "3/3 [==============================] - 0s 76ms/step - loss: 0.1320 - accuracy: 0.9677 - precision: 0.9454 - recall: 0.9774 - val_loss: 0.1247 - val_accuracy: 0.9692 - val_precision: 0.9475 - val_recall: 0.9759\n",
            "Epoch 57/100\n",
            "3/3 [==============================] - 0s 66ms/step - loss: 0.1297 - accuracy: 0.9678 - precision: 0.9455 - recall: 0.9776 - val_loss: 0.1224 - val_accuracy: 0.9692 - val_precision: 0.9475 - val_recall: 0.9759\n",
            "Epoch 58/100\n",
            "3/3 [==============================] - 0s 77ms/step - loss: 0.1274 - accuracy: 0.9678 - precision: 0.9455 - recall: 0.9778 - val_loss: 0.1202 - val_accuracy: 0.9696 - val_precision: 0.9475 - val_recall: 0.9767\n",
            "Epoch 59/100\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1253 - accuracy: 0.9681 - precision: 0.9453 - recall: 0.9786 - val_loss: 0.1182 - val_accuracy: 0.9699 - val_precision: 0.9475 - val_recall: 0.9775\n",
            "Epoch 60/100\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1233 - accuracy: 0.9682 - precision: 0.9448 - recall: 0.9794 - val_loss: 0.1163 - val_accuracy: 0.9692 - val_precision: 0.9460 - val_recall: 0.9775\n",
            "Epoch 61/100\n",
            "3/3 [==============================] - 0s 69ms/step - loss: 0.1215 - accuracy: 0.9683 - precision: 0.9442 - recall: 0.9806 - val_loss: 0.1145 - val_accuracy: 0.9692 - val_precision: 0.9460 - val_recall: 0.9775\n",
            "Epoch 62/100\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.1197 - accuracy: 0.9684 - precision: 0.9442 - recall: 0.9808 - val_loss: 0.1128 - val_accuracy: 0.9689 - val_precision: 0.9452 - val_recall: 0.9775\n",
            "Epoch 63/100\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.1180 - accuracy: 0.9687 - precision: 0.9442 - recall: 0.9816 - val_loss: 0.1112 - val_accuracy: 0.9692 - val_precision: 0.9460 - val_recall: 0.9775\n",
            "Epoch 64/100\n",
            "3/3 [==============================] - 0s 73ms/step - loss: 0.1165 - accuracy: 0.9688 - precision: 0.9442 - recall: 0.9818 - val_loss: 0.1097 - val_accuracy: 0.9696 - val_precision: 0.9461 - val_recall: 0.9784\n",
            "Epoch 65/100\n",
            "3/3 [==============================] - 0s 72ms/step - loss: 0.1150 - accuracy: 0.9688 - precision: 0.9442 - recall: 0.9818 - val_loss: 0.1082 - val_accuracy: 0.9702 - val_precision: 0.9461 - val_recall: 0.9800\n",
            "Epoch 66/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1136 - accuracy: 0.9691 - precision: 0.9441 - recall: 0.9826 - val_loss: 0.1069 - val_accuracy: 0.9705 - val_precision: 0.9455 - val_recall: 0.9817\n",
            "Epoch 67/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1123 - accuracy: 0.9692 - precision: 0.9441 - recall: 0.9828 - val_loss: 0.1057 - val_accuracy: 0.9709 - val_precision: 0.9448 - val_recall: 0.9833\n",
            "Epoch 68/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1111 - accuracy: 0.9692 - precision: 0.9439 - recall: 0.9830 - val_loss: 0.1044 - val_accuracy: 0.9709 - val_precision: 0.9448 - val_recall: 0.9833\n",
            "Epoch 69/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1099 - accuracy: 0.9692 - precision: 0.9439 - recall: 0.9830 - val_loss: 0.1032 - val_accuracy: 0.9715 - val_precision: 0.9463 - val_recall: 0.9833\n",
            "Epoch 70/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1087 - accuracy: 0.9691 - precision: 0.9439 - recall: 0.9828 - val_loss: 0.1021 - val_accuracy: 0.9715 - val_precision: 0.9463 - val_recall: 0.9833\n",
            "Epoch 71/100\n",
            "3/3 [==============================] - 0s 52ms/step - loss: 0.1076 - accuracy: 0.9693 - precision: 0.9445 - recall: 0.9828 - val_loss: 0.1010 - val_accuracy: 0.9715 - val_precision: 0.9463 - val_recall: 0.9833\n",
            "Epoch 72/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1066 - accuracy: 0.9693 - precision: 0.9443 - recall: 0.9830 - val_loss: 0.1000 - val_accuracy: 0.9715 - val_precision: 0.9463 - val_recall: 0.9833\n",
            "Epoch 73/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.1057 - accuracy: 0.9693 - precision: 0.9443 - recall: 0.9830 - val_loss: 0.0991 - val_accuracy: 0.9705 - val_precision: 0.9440 - val_recall: 0.9833\n",
            "Epoch 74/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1047 - accuracy: 0.9693 - precision: 0.9438 - recall: 0.9836 - val_loss: 0.0982 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 75/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1038 - accuracy: 0.9693 - precision: 0.9438 - recall: 0.9836 - val_loss: 0.0973 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 76/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.1030 - accuracy: 0.9694 - precision: 0.9440 - recall: 0.9836 - val_loss: 0.0965 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 77/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1022 - accuracy: 0.9694 - precision: 0.9440 - recall: 0.9836 - val_loss: 0.0957 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 78/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1014 - accuracy: 0.9695 - precision: 0.9440 - recall: 0.9838 - val_loss: 0.0950 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 79/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.1007 - accuracy: 0.9695 - precision: 0.9440 - recall: 0.9838 - val_loss: 0.0943 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 80/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.1000 - accuracy: 0.9699 - precision: 0.9440 - recall: 0.9848 - val_loss: 0.0936 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 81/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0993 - accuracy: 0.9701 - precision: 0.9442 - recall: 0.9850 - val_loss: 0.0929 - val_accuracy: 0.9709 - val_precision: 0.9441 - val_recall: 0.9842\n",
            "Epoch 82/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0987 - accuracy: 0.9701 - precision: 0.9441 - recall: 0.9854 - val_loss: 0.0923 - val_accuracy: 0.9712 - val_precision: 0.9441 - val_recall: 0.9850\n",
            "Epoch 83/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0981 - accuracy: 0.9702 - precision: 0.9441 - recall: 0.9856 - val_loss: 0.0917 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 84/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0975 - accuracy: 0.9704 - precision: 0.9441 - recall: 0.9860 - val_loss: 0.0912 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 85/100\n",
            "3/3 [==============================] - 0s 53ms/step - loss: 0.0969 - accuracy: 0.9706 - precision: 0.9441 - recall: 0.9866 - val_loss: 0.0906 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 86/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0964 - accuracy: 0.9708 - precision: 0.9441 - recall: 0.9870 - val_loss: 0.0901 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 87/100\n",
            "3/3 [==============================] - 0s 48ms/step - loss: 0.0958 - accuracy: 0.9710 - precision: 0.9445 - recall: 0.9870 - val_loss: 0.0896 - val_accuracy: 0.9715 - val_precision: 0.9435 - val_recall: 0.9867\n",
            "Epoch 88/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0953 - accuracy: 0.9710 - precision: 0.9445 - recall: 0.9872 - val_loss: 0.0892 - val_accuracy: 0.9715 - val_precision: 0.9435 - val_recall: 0.9867\n",
            "Epoch 89/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0948 - accuracy: 0.9712 - precision: 0.9449 - recall: 0.9872 - val_loss: 0.0887 - val_accuracy: 0.9715 - val_precision: 0.9435 - val_recall: 0.9867\n",
            "Epoch 90/100\n",
            "3/3 [==============================] - 0s 49ms/step - loss: 0.0944 - accuracy: 0.9712 - precision: 0.9450 - recall: 0.9870 - val_loss: 0.0883 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 91/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0939 - accuracy: 0.9712 - precision: 0.9450 - recall: 0.9870 - val_loss: 0.0879 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 92/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0935 - accuracy: 0.9713 - precision: 0.9451 - recall: 0.9872 - val_loss: 0.0875 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 93/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0931 - accuracy: 0.9713 - precision: 0.9452 - recall: 0.9870 - val_loss: 0.0871 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 94/100\n",
            "3/3 [==============================] - 0s 46ms/step - loss: 0.0927 - accuracy: 0.9713 - precision: 0.9452 - recall: 0.9870 - val_loss: 0.0868 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 95/100\n",
            "3/3 [==============================] - 0s 54ms/step - loss: 0.0923 - accuracy: 0.9713 - precision: 0.9454 - recall: 0.9868 - val_loss: 0.0864 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 96/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0919 - accuracy: 0.9714 - precision: 0.9456 - recall: 0.9868 - val_loss: 0.0860 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 97/100\n",
            "3/3 [==============================] - 0s 47ms/step - loss: 0.0916 - accuracy: 0.9713 - precision: 0.9456 - recall: 0.9866 - val_loss: 0.0857 - val_accuracy: 0.9719 - val_precision: 0.9442 - val_recall: 0.9867\n",
            "Epoch 98/100\n",
            "3/3 [==============================] - 0s 50ms/step - loss: 0.0912 - accuracy: 0.9714 - precision: 0.9454 - recall: 0.9872 - val_loss: 0.0855 - val_accuracy: 0.9722 - val_precision: 0.9450 - val_recall: 0.9867\n",
            "Epoch 99/100\n",
            "3/3 [==============================] - 0s 56ms/step - loss: 0.0909 - accuracy: 0.9715 - precision: 0.9453 - recall: 0.9876 - val_loss: 0.0851 - val_accuracy: 0.9722 - val_precision: 0.9450 - val_recall: 0.9867\n",
            "Epoch 100/100\n",
            "3/3 [==============================] - 0s 45ms/step - loss: 0.0906 - accuracy: 0.9716 - precision: 0.9456 - recall: 0.9874 - val_loss: 0.0848 - val_accuracy: 0.9725 - val_precision: 0.9457 - val_recall: 0.9867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# predicting target attribute on testing dataset\n",
        "test_results = lst.evaluate(X_test, Y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "id": "JruzxPfF17UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8c42a61-3aeb-4718-f484-6d5a8066307e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 0s 2ms/step - loss: 0.4907 - accuracy: 0.8653 - precision: 0.4457 - recall: 0.6576\n",
            "Test results - Loss: 0.4907398521900177 - Accuracy: 86.5281879901886%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy4_2 = test_results[1]\n",
        "y_pred4_2 = np.where(lst.predict(X_test)>=0.5,1,0)"
      ],
      "metadata": {
        "id": "2eAxLuPp17UN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a5672da-a4fd-4bc2-f16f-20cefeaf1ed6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "158/158 [==============================] - 1s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Result"
      ],
      "metadata": {
        "id": "L2ev-sFZVh-k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "y_test = [*y_test1,*y_test2,*y_test3,*y_test4]\n",
        "y_pred2 = [*y_pred1_2,*y_pred2_2,*y_pred3_2,*y_pred4_2]\n",
        "accuracy = (test_count1*accuracy1_2 + test_count2*accuracy2_2 + test_count3*accuracy3_2 + test_count4*accuracy4_2)/(test_count1 + test_count2 + test_count3 + test_count4)\n",
        "presion = precision_score(y_test,y_pred2)\n",
        "recall = recall_score(y_test,y_pred2)"
      ],
      "metadata": {
        "id": "3FVcHSEjVh-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {}\\t Precision:{}\\t Recall: {}\".format(accuracy,presion,recall))"
      ],
      "metadata": {
        "id": "goOAub4SVh-m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e1849f-15a6-4e89-8377-f9e725b4a46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8125044180449975\t Precision:0.7175660160734788\t Recall: 0.8802816901408451\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Best Model"
      ],
      "metadata": {
        "id": "hq63nUHhVXDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Finding Best"
      ],
      "metadata": {
        "id": "nQJazz0VVXDl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = []\n",
        "if accuracy1_1 > accuracy1_2:\n",
        "  y_pred.extend(y_pred1_1)\n",
        "  accuracy1 = accuracy1_1\n",
        "else:\n",
        "  y_pred.extend(y_pred1_2)\n",
        "  accuracy1 = accuracy1_2\n",
        "\n",
        "if accuracy2_1 > accuracy2_2:\n",
        "  y_pred.extend(y_pred2_1)\n",
        "  accuracy2 = accuracy2_1\n",
        "else:\n",
        "  y_pred.extend(y_pred2_2)\n",
        "  accuracy2 = accuracy2_2\n",
        "\n",
        "if accuracy3_1 > accuracy3_2:\n",
        "  y_pred.extend(y_pred3_1)\n",
        "  accuracy3 = accuracy3_1\n",
        "else:\n",
        "  y_pred.extend(y_pred3_2)\n",
        "  accuracy3 = accuracy3_2\n",
        "\n",
        "if accuracy4_1 > accuracy4_2:\n",
        "  y_pred.extend(y_pred4_1)\n",
        "  accuracy4 = accuracy4_1\n",
        "else:\n",
        "  y_pred.extend(y_pred4_2)\n",
        "  accuracy4 = accuracy4_2\n",
        "\n",
        "y_test = [*y_test1,*y_test2,*y_test3,*y_test4]"
      ],
      "metadata": {
        "id": "vIHfD01cVXDl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Result"
      ],
      "metadata": {
        "id": "kiKzxkmiVXDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score,recall_score\n",
        "y_pred = np.array(y_pred) \n",
        "y_pred = y_pred.astype(int)\n",
        "accuracy = (test_count1*accuracy1 + test_count2*accuracy2 + test_count3*accuracy3 + test_count4*accuracy4)/(test_count1 + test_count2 + test_count3 + test_count4)\n",
        "presion = precision_score(y_test,y_pred)\n",
        "recall = recall_score(y_test,y_pred)"
      ],
      "metadata": {
        "id": "T9Rd361MVXDm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0fef366-da1c-471a-d1de-ed3c87faed74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-395-b7d24d7492d5>:2: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  y_pred = np.array(y_pred)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Accuracy: {}\\t Precision:{}\\t Recall: {}\".format(accuracy,presion,recall))"
      ],
      "metadata": {
        "id": "lzOpqlO3VXDn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c476fa1-2d2d-45ee-bc91-a9fca9c464fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9017205821685342\t Precision:0.90067214339059\t Recall: 0.8492957746478873\n"
          ]
        }
      ]
    }
  ]
}